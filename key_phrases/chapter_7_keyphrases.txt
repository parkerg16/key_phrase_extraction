forecasts uses: 0.4692
traversing rnn: 0.3363
handling sequences: 0.2626
consumption trajectories: 0.2609
cnns predicting: 0.2126
recurrent continuous: 0.1857
hourly temperature: 0.1764
speech recognition: 0.1711
running gpu: 0.157
does lstm: 0.1554
implementing wavenet: 0.1521
future values: 0.1423
smell coffee: 0.1382
useful natural: 0.134
deepmind researchers: 0.1213
able carry: 0.1207
states returns: 0.1146
start autoregressive: 0.1101
path parse_dates: 0.1025
home: 0.1013
series difference: 0.0977
lnsimplernncell tf: 0.0971
patterns roughly: 0.0969
active users: 0.0959
using map: 0.0917
fundamental concepts: 0.0913
explains growing: 0.0898
inference time: 0.0897
reading clue: 0.0894
use huber: 0.088
bus chicago: 0.0827
learn api: 0.0822
architectures large: 0.0804
imagine dory: 0.0802
batch_size use: 0.0779
parts stored: 0.072
types cells: 0.0719
10 times: 0.0691
integers integer: 0.0685
outputs gradients: 0.0673
second dimension: 0.0639
flowing model: 0.0612
slides kernels: 0.0612
fish finished: 0.0611
networks versatility: 0.0607
ensures convolutional: 0.0564
alex graves: 0.0554
like bn: 0.0519
concatenation function: 0.0518
controller controls: 0.0481
combination current: 0.048
models baselines: 0.0461
contains tensors: 0.0461
06450 2016: 0.0459
paper actually: 0.045
pointing backward: 0.0433
including text: 0.0425
14 filters: 0.0417
computations xz: 0.0415
improve performance: 0.0392
use logistic: 0.037
saturdays sundays: 0.0363
strategy called: 0.0361
hyperparameters sarima: 0.0359
encoder convert: 0.0357
constructor takes: 0.0339
27 703: 0.0319
check google: 0.0318
layernormalization self: 0.0311
composed neuron: 0.0292
shuffle true: 0.0289
creates dataset: 0.0279
sentiment score: 0.0263
skip connections: 0.0212
numpy array: 0.0207
split windows: 0.0187
riders 42: 0.0134
sak wojciech: 0.0126
arma family: 0.0123
international conference: 0.0112
recall input_shape: 0.0105
1qÎ¸i equation: 0.0102
approximation order: 0.0094
column names: 0.0078
unzip: 0.0053
rates act: 0.004
impacted errors: 0.0002
worrying preprocessing: -0.0027
proposed kyunghyun: -0.0072
need define: -0.0087
margin average: -0.0127
instance reshapes: -0.0134
pd get_dummies: -0.0141
works exactly: -0.0177
seq_length 112: -0.0239
johann sebastian: -0.0248
empirical methods: -0.0254
notebook https: -0.0261
figsize df_monthly: -0.043
subplots sharex: -0.0901
