# PDF Book Chapter Chunker

A simple Python tool that extracts text from a PDF book, splits it into individual chapters, and evaluates key phrase extraction using F1 scores. This project leverages [pdfminer.six](https://github.com/pdfminer/pdfminer.six) for PDF text extraction, [Colorama](https://pypi.org/project/colorama/) for colorful terminal output, regular expressions for text chunking, and [fuzzywuzzy](https://github.com/seatgeek/fuzzywuzzy) for fuzzy matching during evaluation.

## Features

- **PDF Extraction:** Automatically extracts the entire text from a PDF file.
- **Chapter Chunking:** Splits the extracted text into individual chapters based on form feed and chapter markers (e.g., `\fChapter {1}`, `\fChapter {2}`, etc.).
- **Organized Output:** Saves each chapter as a separate `.txt` file in a folder named after the book (with `_chunks` appended).
- **Configurable:** Easily modify file paths and settings via configuration constants in the scripts.
- **Key Phrase Evaluation:** 
  - **Index Term Extraction:** Extracts index terms from the book (between "Index" and "About the Author") and saves them to a file.
  - **Ground Truth Creation:** Matches index terms to each chapter to create ground truth files.
  - **F1 Score Computation:** Evaluates key phrase extraction by comparing predicted key phrases (from your extraction method) with the ground truth using fuzzy partial matching, computing precision, recall, and F1 scores.

## Prerequisites

- Python 3.6 or higher

## Installation

1. **Clone the repository:**

   ```bash
   git clone https://github.com/parkerg16/key_phrase_extraction/
   cd key_phrase_extraction
Install dependencies:

**This project includes a requirements.txt file. Install the required packages with:**

  ```bash
  pip install -r requirements.txt
  ```
Note: Ensure that fuzzywuzzy[speedup] is included in the requirements. If not, install it manually with:

``` bash
Copy
pip install fuzzywuzzy[speedup]
```

# Prepare Your PDF:
Place your PDF file (e.g., book.pdf) in the project directory.

Configure Settings:

You can adjust the configuration values at the top of the script (chunking.py) if needed:

BOOK_PATH: Path to your PDF file.
TEXT_OUTPUT: Path where the extracted text will be saved.
Run the Script:

Execute the script to extract text and split it into chapters:

```bash
python chunking.py
```

The script will:

Extract text from your PDF and save it as extracted_text.txt (if it doesn't already exist).
Split the text into chapters based on the pattern \fChapter {number}.
Create a folder (e.g., book_chunks) and output each chapter into its own file (e.g., chapter_1_chunk.txt, chapter_2_chunk.txt, etc.).
Skip any files or folders that already exist.
What Does chunking.py Do?
The chunking.py script is the core of this project. It performs the following tasks:

# PDF Extraction:
Uses pdfminer.six to extract text from the specified PDF file. The extracted text is saved to a file (default: extracted_text.txt).

# Text Chunking:
Reads the extracted text and applies a regular expression to split the text into chapters. Chapters are identified by a form feed (\f) followed by the word "Chapter" (with an optional chapter number in braces).

# File Output:
Creates a directory named after the PDF (with _chunks appended) and writes each chapter's content into separate text files named in the format chapter_X_chunk.txt. If a chapter file already exists, the script skips writing that file.

# Visual Feedback:
Uses Colorama to print colored messages to the console, indicating the progress of PDF extraction and chapter creation, along with a preview of the first 300 characters of each chapter.

Example Terminal Output
After running the script, you might see output like this:

```bash
extracted_text.txt already exists. Skipping PDF extraction.
Folder book_chunks already exists.
Written Chapter 1 to book_chunks/chapter_1_chunk.txt

--- Chapter 1 Preview ---
[First 300 characters of chapter 1...]

Written Chapter 2 to book_chunks/chapter_2_chunk.txt

--- Chapter 2 Preview ---
[First 300 characters of chapter 2...]
...
```
---------------------------- Obtaining F1 Score--------------------------------------------
# Extract Index Terms
Run the extract_index_terms.py script to extract the book's index terms. These terms are used to create ground truth for evaluation.

```bash
python extract_index_terms.py
```
What it does:
Reads extracted_text.txt (generated by chunking.py).
Extracts terms from the index section (between "Index" and "About the Author").
Saves the extracted terms to index_terms.txt, one term per line.

Expected Output:

```bash
Extracted 1234 index terms.
```
Note: Ensure that extracted_text.txt exists before running this script.

# Create Ground Truth Files
Run the create_ground_truth.py script to generate ground truth files for each chapter based on the extracted index terms.

```bash
python create_ground_truth.py
```
What it does:
Reads index_terms.txt and the chapter texts from the book_chunks folder (e.g., chapter_1_chunk.txt).
Uses regex with word boundaries to check which index terms appear in each chapter's text.
Creates a ground_truth folder and saves each chapter's ground truth terms to files like chapter_1_ground_truth.txt, one term per line.

Expected Output:
```bash
Created ground truth for chapter 1 with 50 terms
Created ground truth for chapter 2 with 45 terms
...
Ground truth creation complete.
```
Note: Ensure that the book_chunks folder exists with chapter files before running this script.

# Compute F1 Score with Fuzzy Matching
Run the compute_f1_fuzzy_partial.py script to evaluate key phrase extraction using fuzzy partial matching.
```bash
python compute_f1_fuzzy_partial.py
```
What it does:
Reads predicted key phrases from the key_phrases folder (e.g., chapter_1_keyphrases.txt with entries in the format "phrase: score") and the corresponding ground truth from the ground_truth folder (e.g., chapter_1_ground_truth.txt).
Computes precision, recall, and F1 score for each chapter using fuzzywuzzy's partial ratio matching with a threshold (default is 60).
Prints per-chapter metrics and overall averages

Expected Output:
```bash
Chapter 1: Precision=0.6400, Recall=0.2530, F1=0.3626
Chapter 2: Precision=0.8500, Recall=0.2335, F1=0.3664
...
Average Precision: 0.7990
Average Recall: 0.2307
Average F1: 0.3510
```
Note: Ensure that both key_phrases and ground_truth folders exist with the appropriate files before running this script. The key_phrases folder should contain files generated by your key phrase extraction method (e.g., using KeyBERT or another tool).
