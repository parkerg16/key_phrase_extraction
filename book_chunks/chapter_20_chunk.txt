. Training and Deploying
TensorFlow Models at Scale

Once you have a beautiful model that makes amazing predictions, what do
you do with it? Well, you need to put it in production! This could be as
simple as running the model on a batch of data, and perhaps writing a script
that runs this model every night. However, it is often much more involved.
Various parts of your infrastructure may need to use this model on live data,
in which case you will probably want to wrap your model in a web service:
this way, any part of your infrastructure can query the model at any time
using a simple REST API (or some other protocol), as we discussed in
Chapter 2. But as time passes, you’ll need to regularly retrain your model on
fresh data and push the updated version to production. You must handle
model versioning, gracefully transition from one model to the next, possibly
roll back to the previous model in case of problems, and perhaps run multiple
different models in parallel to perform A/B experiments.⁠
becomes successful, your service may start to get a large number of of
queries per second (QPS), and it must scale up to support the load. A great
solution to scale up your service, as you will see in this chapter, is to use TF
Serving, either on your own hardware infrastructure or via a cloud service
such as Google Vertex AI.⁠
 It will take care of efficiently serving your
model, handle graceful model transitions, and more. If you use the cloud
platform you will also get many extra features, such as powerful monitoring
tools.

 If your product

1

2

Moreover, if you have a lot of training data and compute-intensive models,
then training time may be prohibitively long. If your product needs to adapt
to changes quickly, then a long training time can be a showstopper (e.g.,
think of a news recommendation system promoting news from last week).
Perhaps even more importantly, a long training time will prevent you from
experimenting with new ideas. In machine learning (as in many other fields),

it is hard to know in advance which ideas will work, so you should try out as
many as possible, as fast as possible. One way to speed up training is to use
hardware accelerators such as GPUs or TPUs. To go even faster, you can
train a model across multiple machines, each equipped with multiple
hardware accelerators. TensorFlow’s simple yet powerful distribution
strategies API makes this easy, as you will see.

In this chapter we will look at how to deploy models, first using TF Serving,
then using Vertex AI. We will also take a quick look at deploying models to
mobile apps, embedded devices, and web apps. Then we will discuss how to
speed up computations using GPUs and how to train models across multiple
devices and servers using the distribution strategies API. Lastly, we will
explore how to train models and fine-tune their hyperparameters at scale
using Vertex AI. That’s a lot of topics to discuss, so let’s dive in!

Serving a TensorFlow Model

Once you have trained a TensorFlow model, you can easily use it in any
Python code: if it’s a Keras model, just call its predict() method! But as your
infrastructure grows, there comes a point where it is preferable to wrap your
model in a small service whose sole role is to make predictions and have the
rest of the infrastructure query it (e.g., via a REST or gRPC API).⁠
decouples your model from the rest of the infrastructure, making it possible
to easily switch model versions or scale the service up as needed
(independently from the rest of your infrastructure), perform A/B
experiments, and ensure that all your software components rely on the same
model versions. It also simplifies testing and development, and more. You
could create your own microservice using any technology you want (e.g.,
using the Flask library), but why reinvent the wheel when you can just use TF
Serving?

 This

3

Using TensorFlow Serving

TF Serving is a very efficient, battle-tested model server, written in C++. It
can sustain a high load, serve multiple versions of your models and watch a
model repository to automatically deploy the latest versions, and more (see
Figure 19-1).

Figure 19-1. TF Serving can serve multiple models and automatically deploy the latest version of each
model

So let’s suppose you have trained an MNIST model using Keras, and you
want to deploy it to TF Serving. The first thing you have to do is export this
model to the SavedModel format, introduced in Chapter 10.

Exporting SavedModels

You already know how to save the model: just call model.save(). Now to
version the model, you just need to create a subdirectory for each model
version. Easy!

from pathlib import Path
import tensorflow as tf

X_train, X_valid, X_test = [...]  # load and split the MNIST dataset
model = [...]  # build & train an MNIST model (also handles image preprocessing)

model_name = "my_mnist_model"
model_version = "0001"
model_path = Path(model_name) / model_version
model.save(model_path, save_format="tf")

It’s usually a good idea to include all the preprocessing layers in the final
model you export so that it can ingest data in its natural form once it is
deployed to production. This avoids having to take care of preprocessing
separately within the application that uses the model. Bundling the
preprocessing steps within the model also makes it simpler to update them
later on and limits the risk of mismatch between a model and the
preprocessing steps it requires.

WARNING

Since a SavedModel saves the computation graph, it can only be used with models that are
based exclusively on TensorFlow operations, excluding the tf.py_function() operation,
which wraps arbitrary Python code.

TensorFlow comes with a small saved_model_cli command-line interface to
inspect SavedModels. Let use it to inspect our exported model:

$ saved_model_cli show --dir my_mnist_model/0001
The given SavedModel contains the following tag-sets:
'serve'

What does this output mean? Well, a SavedModel contains one or more
metagraphs. A metagraph is a computation graph plus some function
signature definitions, including their input and output names, types, and
shapes. Each metagraph is identified by a set of tags. For example, you may
want to have a metagraph containing the full computation graph, including

the training operations: you would typically tag this one as "train". And you
might have another metagraph containing a pruned computation graph with
only the prediction operations, including some GPU-specific operations: this
one might be tagged as "serve", "gpu". You might want to have other
metagraphs as well. This can be done using TensorFlow’s low-level
SavedModel API. However, when you save a Keras model using its save()
method, it saves a single metagraph tagged as "serve". Let’s inspect this
"serve" tag set:

$ saved_model_cli show --dir 0001/my_mnist_model --tag_set serve
The given SavedModel MetaGraphDef contains SignatureDefs with these keys:
SignatureDef key: "__saved_model_init_op"
SignatureDef key: "serving_default"

This metagraph contains two signature definitions: an initialization function
called "__saved_model_init_op", which you do not need to worry about, and
a default serving function called "serving_default". When saving a Keras
model, the default serving function is the model’s call() method, which
makes predictions, as you already know. Let’s get more details about this
serving function:

$ saved_model_cli show --dir 0001/my_mnist_model --tag_set serve \
                       --signature_def serving_default
The given SavedModel SignatureDef contains the following input(s):
  inputs['flatten_input'] tensor_info:
      dtype: DT_UINT8
      shape: (-1, 28, 28)
      name: serving_default_flatten_input:0
The given SavedModel SignatureDef contains the following output(s):
  outputs['dense_1'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 10)
      name: StatefulPartitionedCall:0
Method name is: tensorflow/serving/predict

Note that the function’s input is named "flatten_input", and the output is
named "dense_1". These correspond to the Keras model’s input and output
layer names. You can also see the type and shape of the input and output
data. Looks good!

Now that you have a SavedModel, the next step is to install TF Serving.

Installing and starting TensorFlow Serving

There are many ways to install TF Serving: using the system’s package
4
manager, using a Docker image,⁠
 installing from source, and more. Since
Colab runs on Ubuntu, we can use Ubuntu’s apt package manager like this:

url = "https://storage.googleapis.com/tensorflow-serving-apt"
src = "stable tensorflow-model-server tensorflow-model-server-universal"
!echo 'deb {url} {src}' > /etc/apt/sources.list.d/tensorflow-serving.list
!curl '{url}/tensorflow-serving.release.pub.gpg' | apt-key add -
!apt update -q && apt-get install -y tensorflow-model-server
%pip install -q -U tensorflow-serving-api

This code starts by adding TensorFlow’s package repository to Ubuntu’s list
of package sources. Then it downloads TensorFlow’s public GPG key and
adds it to the package manager’s key list so it can verify TensorFlow’s
package signatures. Next, it uses apt to install the tensorflow-model-server
package. Lastly, it installs the tensorflow-serving-api library, which we will
need to communicate with the server.

Now we want to start the server. The command will require the absolute path
of the base model directory (i.e., the path to my_mnist_model, not 0001), so
let’s save that to the MODEL_DIR environment variable:

import os

os.environ["MODEL_DIR"] = str(model_path.parent.absolute())

We can then start the server:

%%bash --bg
tensorflow_model_server \
     --port=8500 \
     --rest_api_port=8501 \
     --model_name=my_mnist_model \
     --model_base_path="${MODEL_DIR}" >my_server.log 2>&1

In Jupyter or Colab, the %%bash --bg magic command executes the cell as a

bash script, running it in the background. The >my_server.log 2>&1 part
redirects the standard output and standard error to the my_server.log file. And
that’s it! TF Serving is now running in the background, and its logs are saved
to my_server.log. It loaded our MNIST model (version 1), and it is now
waiting for gRPC and REST requests, respectively, on ports 8500 and 8501.

RUNNING TF SERVING IN A DOCKER CONTAINER

If you are running the notebook on your own machine and you have
installed Docker, you can run docker pull tensorflow/serving in a
terminal to download the TF Serving image. The TensorFlow team
highly recommends this installation method because it is simple, it will
not mess with your system, and it offers high performance.⁠
server inside a Docker container, you can run the following command in
a terminal:

5
 To start the

$ docker run -it --rm -v "/path/to/my_mnist_model:/models/my_mnist_model" \
    -p 8500:8500 -p 8501:8501 -e MODEL_NAME=my_mnist_model tensorflow/serving

Here is what all these command-line options mean:

-it

Makes the container interactive (so you can press Ctrl-C to stop it)
and displays the server’s output.

--rm

Deletes the container when you stop it: no need to clutter your
machine with interrupted containers. However, it does not delete the
image.

-v "/path/to/my_mnist_model:/models/my_mnist_model"

Makes the host’s my_mnist_model directory available to the container
at the path /models/mnist_model. You must replace
/path/to/my_mnist_model with the absolute path of this directory. On
Windows, remember to use \ instead of / in the host path, but not in

the container path (since the container runs on Linux).

-p 8500:8500

Makes the Docker engine forward the host’s TCP port 8500 to the
container’s TCP port 8500. By default, TF Serving uses this port to
serve the gRPC API.

-p 8501:8501

Forwards the host’s TCP port 8501 to the container’s TCP port 8501.
The Docker image is configured to use this port by default to serve
the REST API.

-e MODEL_NAME=my_mnist_model

Sets the container’s MODEL_NAME environment variable, so TF
Serving knows which model to serve. By default, it will look for
models in the /models directory, and it will automatically serve the
latest version it finds.

tensorflow/serving

This is the name of the image to run.

Now that the server is up and running, let’s query it, first using the REST
API, then the gRPC API.

Querying TF Serving through the REST API

Let’s start by creating the query. It must contain the name of the function
signature you want to call, and of course the input data. Since the request
must use the JSON format, we have to convert the input images from a
NumPy array to a Python list:

import json

X_new = X_test[:3]  # pretend we have 3 new digit images to classify

request_json = json.dumps({
    "signature_name": "serving_default",
    "instances": X_new.tolist(),
})

Note that the JSON format is 100% text-based. The request string looks like
this:

>>> request_json
'{"signature_name": "serving_default", "instances": [[[0, 0, 0, 0, ... ]]]}'

Now let’s send this request to TF Serving via an HTTP POST request. This
can be done using the requests library (it is not part of Python’s standard
library, but it is preinstalled on Colab):

import requests

server_url = "http://localhost:8501/v1/models/my_mnist_model:predict"
response = requests.post(server_url, data=request_json)
response.raise_for_status()  # raise an exception in case of error
response = response.json()

If all goes well, the response should be a dictionary containing a single
"predictions" key. The corresponding value is the list of predictions. This list
is a Python list, so let’s convert it to a NumPy array and round the floats it
contains to the second decimal:

>>> import numpy as np
>>> y_proba = np.array(response["predictions"])
>>> y_proba.round(2)
array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],
       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],
       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])

Hurray, we have the predictions! The model is close to 100% confident that
the first image is a 7, 99% confident that the second image is a 2, and 97%
confident that the third image is a 1. That’s correct.

The REST API is nice and simple, and it works well when the input and
output data are not too large. Moreover, just about any client application can

make REST queries without additional dependencies, whereas other
protocols are not always so readily available. However, it is based on JSON,
which is text-based and fairly verbose. For example, we had to convert the
NumPy array to a Python list, and every float ended up represented as a
string. This is very inefficient, both in terms of serialization/deserialization
time—we have to convert all the floats to strings and back—and in terms of
payload size: many floats end up being represented using over 15 characters,
which translates to over 120 bits for 32-bit floats! This will result in high
latency and bandwidth usage when transferring large NumPy arrays.⁠
let’s see how to use gRPC instead.

6
 So,

TIP

When transferring large amounts of data, or when latency is important, it is much better to
use the gRPC API, if the client supports it, as it uses a compact binary format and an
efficient communication protocol based on HTTP/2 framing.

Querying TF Serving through the gRPC API

The gRPC API expects a serialized PredictRequest protocol buffer as input,
and it outputs a serialized PredictResponse protocol buffer. These protobufs
are part of the tensorflow-serving-api library, which we installed earlier.
First, let’s create the request:

from tensorflow_serving.apis.predict_pb2 import PredictRequest

request = PredictRequest()
request.model_spec.name = model_name
request.model_spec.signature_name = "serving_default"
input_name = model.input_names[0]  # == "flatten_input"
request.inputs[input_name].CopyFrom(tf.make_tensor_proto(X_new))

This code creates a PredictRequest protocol buffer and fills in the required
fields, including the model name (defined earlier), the signature name of the
function we want to call, and finally the input data, in the form of a Tensor
protocol buffer. The tf.make_tensor_proto() function creates a Tensor

protocol buffer based on the given tensor or NumPy array, in this case
X_new.

Next, we’ll send the request to the server and get its response. For this, we
will need the grpcio library, which is preinstalled in Colab:

import grpc
from tensorflow_serving.apis import prediction_service_pb2_grpc

channel = grpc.insecure_channel('localhost:8500')
predict_service = prediction_service_pb2_grpc.PredictionServiceStub(channel)
response = predict_service.Predict(request, timeout=10.0)

The code is quite straightforward: after the imports, we create a gRPC
communication channel to localhost on TCP port 8500, then we create a
gRPC service over this channel and use it to send a request, with a 10-second
timeout. Note that the call is synchronous: it will block until it receives the
response or when the timeout period expires. In this example the channel is
insecure (no encryption, no authentication), but gRPC and TF Serving also
support secure channels over SSL/TLS.

Next, let’s convert the PredictResponse protocol buffer to a tensor:

output_name = model.output_names[0]  # == "dense_1"
outputs_proto = response.outputs[output_name]
y_proba = tf.make_ndarray(outputs_proto)

If you run this code and print y_proba.round(2), you will get the exact same
estimated class probabilities as earlier. And that’s all there is to it: in just a
few lines of code, you can now access your TensorFlow model remotely,
using either REST or gRPC.

Deploying a new model version

Now let’s create a new model version and export a SavedModel, this time to
the my_mnist_model/0002 directory:

model = [...]  # build and train a new MNIST model version

model_version = "0002"
model_path = Path(model_name) / model_version
model.save(model_path, save_format="tf")

At regular intervals (the delay is configurable), TF Serving checks the model
directory for new model versions. If it finds one, it automatically handles the
transition gracefully: by default, it answers pending requests (if any) with the
previous model version, while handling new requests with the new version.
As soon as every pending request has been answered, the previous model
version is unloaded. You can see this at work in the TF Serving logs (in
my_server.log):

[...]
Reading SavedModel from: /models/my_mnist_model/0002
Reading meta graph with tags { serve }
[...]
Successfully loaded servable version {name: my_mnist_model version: 2}
Quiescing servable version {name: my_mnist_model version: 1}
Done quiescing servable version {name: my_mnist_model version: 1}
Unloading servable version {name: my_mnist_model version: 1}

TIP

If the SavedModel contains some example instances in the assets/extra directory, you can
configure TF Serving to run the new model on these instances before starting to use it to
serve requests. This is called model warmup: it will ensure that everything is properly
loaded, avoiding long response times for the first requests.

This approach offers a smooth transition, but it may use too much RAM—
especially GPU RAM, which is generally the most limited. In this case, you
can configure TF Serving so that it handles all pending requests with the
previous model version and unloads it before loading and using the new
model version. This configuration will avoid having two model versions
loaded at the same time, but the service will be unavailable for a short period.

As you can see, TF Serving makes it straightforward to deploy new models.
Moreover, if you discover that version 2 does not work as well as you
expected, then rolling back to version 1 is as simple as removing the

my_mnist_model/0002 directory.

TIP

Another great feature of TF Serving is its automatic batching capability, which you can
activate using the --enable_batching option upon startup. When TF Serving receives
multiple requests within a short period of time (the delay is configurable), it will
automatically batch them together before using the model. This offers a significant
performance boost by leveraging the power of the GPU. Once the model returns the
predictions, TF Serving dispatches each prediction to the right client. You can trade a bit
of latency for a greater throughput by increasing the batching delay (see the --
batching_parameters_file option).

If you expect to get many queries per second, you will want to deploy TF
Serving on multiple servers and load-balance the queries (see Figure 19-2).
This will require deploying and managing many TF Serving containers across
these servers. One way to handle that is to use a tool such as Kubernetes,
which is an open source system for simplifying container orchestration across
many servers. If you do not want to purchase, maintain, and upgrade all the
hardware infrastructure, you will want to use virtual machines on a cloud
platform such as Amazon AWS, Microsoft Azure, Google Cloud Platform,
IBM Cloud, Alibaba Cloud, Oracle Cloud, or some other platform as a
service (PaaS) offering. Managing all the virtual machines, handling
container orchestration (even with the help of Kubernetes), taking care of TF
Serving configuration, tuning and monitoring—all of this can be a full-time
job. Fortunately, some service providers can take care of all this for you. In
this chapter we will use Vertex AI: it’s the only platform with TPUs today; it
supports TensorFlow 2, Scikit-Learn, and XGBoost; and it offers a nice suite
of AI services. There are several other providers in this space that are capable
of serving TensorFlow models as well, though, such as Amazon AWS
SageMaker and Microsoft AI Platform, so make sure to check them out too.

Figure 19-2. Scaling up TF Serving with load balancing

Now let’s see how to serve our wonderful MNIST model on the cloud!

Creating a Prediction Service on Vertex AI

Vertex AI is a platform within Google Cloud Platform (GCP) that offers a
wide range of AI-related tools and services. You can upload datasets, get
humans to label them, store commonly used features in a feature store and
use them for training or in production, and train models across many GPU or
TPU servers with automatic hyperparameter tuning or model architecture
search (AutoML). You can also manage your trained models, use them to
make batch predictions on large amounts of data, schedule multiple jobs for
your data workflows, serve your models via REST or gRPC at scale, and
experiment with your data and models within a hosted Jupyter environment
called the Workbench. There’s even a Matching Engine service that lets you
compare vectors very efficiently (i.e., approximate nearest neighbors). GCP
also includes other AI services, such as APIs for computer vision, translation,
speech-to-text, and more.

Before we start, there’s a little bit of setup to take care of:

1.  Log in to your Google account, and then go to the Google Cloud

Platform console (see Figure 19-3). If you don’t have a Google account,
you’ll have to create one.

2.  If it’s your first time using GCP, you’ll have to read and accept the

terms and conditions. New users are offered a free trial, including $300
worth of GCP credit that you can use over the course of 90 days (as of
May 2022). You’ll only need a small portion of that to pay for the
services you’ll use in this chapter. Upon signing up for a free trial, you’ll
still need to create a payment profile and enter your credit card number:
it’s used for verification purposes—probably to avoid people using the
free trial multiple times—but you won’t be billed for the first $300, and
after that you’ll only be charged if you opt in by upgrading to a paid
account.

Figure 19-3. Google Cloud Platform console

3.  If you have used GCP before and your free trial has expired, then the
services you will use in this chapter will cost you some money. It
shouldn’t be too much, especially if you remember to turn off the
services when you don’t need them anymore. Make sure you understand
and agree to the pricing conditions before you run any service. I hereby
decline any responsibility if services end up costing more than you
expected! Also make sure your billing account is active. To check, open
the ☰ navigation menu at the top left and click Billing, then make sure
you have set up a payment method and that the billing account is active.

4.  Every resource in GCP belongs to a project. This includes all the virtual
machines you may use, the files you store, and the training jobs you run.
When you create an account, GCP automatically creates a project for
you, called “My First Project”. If you want, you can change its display
name by going to the project settings: in the ☰ navigation menu, select
“IAM and admin → Settings”, change the project’s display name, and
click SAVE. Note that the project also has a unique ID and number. You
can choose the project ID when you create a project, but you cannot
change it later. The project number is automatically generated and
cannot be changed. If you want to create a new project, click the project
name at the top of the page, then click NEW PROJECT and enter the
project name. You can also click EDIT to set the project ID. Make sure
billing is active for this new project so that service fees can be billed (to

your free credits, if any).

WARNING

Always set an alarm to remind yourself to turn services off when you know you will
only need them for a few hours, or else you might leave them running for days or
months, incurring potentially significant costs.

5.  Now that you have a GCP account and a project, and billing is activated,
you must activate the APIs you need. In the ☰ navigation menu, select
“APIs and services”, and make sure the Cloud Storage API is enabled. If
needed, click + ENABLE APIS AND SERVICES, find Cloud Storage,
and enable it. Also enable the Vertex AI API.

You could continue to do everything via the GCP console, but I recommend
using Python instead: this way you can write scripts to automate just about
anything you want with GCP, and it’s often more convenient than clicking
your way through menus and forms, especially for common tasks.

GOOGLE CLOUD CLI AND SHELL

Google Cloud’s command-line interface (CLI) includes the gcloud
command, which lets you control almost everything in GCP, and gsutil,
which lets you interact with Google Cloud Storage. This CLI is
preinstalled in Colab: all you need to do is authenticate using
google.auth.authenticate_user(), and you’re good to go. For example,
!gcloud config list will display the configuration.

GCP also offers a preconfigured shell environment called the Google
Cloud Shell, which you can use directly in your web browser; it runs on a
free Linux VM (Debian) with the Google Cloud SDK already preinstalled
and configured for you, so there’s no need to authenticate. The Cloud
Shell is available anywhere in GCP: just click the Activate Cloud Shell
icon at the top right of the page (see Figure 19-4).

Figure 19-4. Activating the Google Cloud Shell

If you prefer to install the CLI on your machine, then after installation
you need to initialize it by running gcloud init: follow the instructions to
log in to GCP and grant access to your GCP resources, then select the
default GCP project you want to use (if you have more than one) and the
default region where you want your jobs to run.

The first thing you need to do before you can use any GCP service is to
authenticate. The simplest solution when using Colab is to execute the
following code:

from google.colab import auth

auth.authenticate_user()

The authentication process is based on OAuth 2.0: a pop-up window will ask
you to confirm that you want the Colab notebook to access your Google
credentials. If you accept, you must select the same Google account you used
for GCP. Then you will be asked to confirm that you agree to give Colab full
access to all your data on Google Drive and in GCP. If you allow access, only
the current notebook will have access, and only until the Colab runtime
expires. Obviously, you should only accept this if you trust the code in the
notebook.

WARNING

If you are not working with the official notebooks from
https://github.com/ageron/handson-ml3, then you should be extra careful: if the
notebook’s author is mischievous, they could include code to do whatever they want with
your data.

AUTHENTICATION AND AUTHORIZATION ON GCP

In general, using OAuth 2.0 authentication is only recommended when an
application must access the user’s personal data or resources from
another application, on the user’s behalf. For example, some applications
allow the user to save data to their Google Drive, but for that the
application first needs the user to authenticate with Google and allow
access to Google Drive. In general, the application will only ask for the
level of access it needs; it won’t be an unlimited access: for example, the
application will only request access to Google Drive, not Gmail or any
other Google service. Moreover, the authorization usually expires after a
while, and it can always be revoked.

When an application needs to access a service on GCP on its own behalf,
not on behalf of the user, then it should generally use a service account.
For example, if you build a website that needs to send prediction requests
to a Vertex AI endpoint, then the website will be accessing the service on
its own behalf. There’s no data or resource that it needs to access in the
user’s Google account. In fact, many users of the website will not even
have a Google account. For this scenario, you first need to create a
service account. Select “IAM and admin → Service accounts” in the GCP
console’s ☰ navigation menu (or use the search box), then click +
CREATE SERVICE ACCOUNT, fill in the first page of the form
(service account name, ID, description), and click CREATE AND
CONTINUE. Next, you must give this account some access rights. Select
the “Vertex AI user” role: this will allow the service account to make
predictions and use other Vertex AI services, but nothing else. Click
CONTINUE. You can now optionally grant some users access to the
service account: this is useful when your GCP user account is part of an
organization and you wish to authorize other users in the organization to
deploy applications that will be based on this service account, or to
manage the service account itself. Next, click DONE.

Once you have created a service account, your application must
authenticate as that service account. There are several ways to do that. If

your application is hosted on GCP—for example, if you are coding a
website hosted on Google Compute Engine—then the simplest and safest
solution is to attach the service account to the GCP resource that hosts
your website, such as a VM instance or a Google App Engine service.
This can be done when creating the GCP resource, by selecting the
service account in the “Identity and API access” section. Some resources,
such as VM instances, also let you attach the service account after the
VM instance is created: you must stop it and edit its settings. In any case,
once a service account is attached to a VM instance, or any other GCP
resource running your code, GCP’s client libraries (discussed shortly)
will automatically authenticate as the chosen service account, with no
extra step needed.

If your application is hosted using Kubernetes, then you should use
Google’s Workload Identity service to map the right service account to
each Kubernetes service account. If your application is not hosted on
GCP—for example, if you are just running the Jupyter notebook on your
own machine—then you can either use the Workload Identity Federation
service (that’s the safest but hardest option), or just generate an access
key for your service account, save it to a JSON file, and point the
GOOGLE_APPLICATION_CREDENTIALS environment variable to it
so your client application can access it. You can manage access keys by
clicking the service account you just created, and then opening the KEYS
tab. Make sure to keep the key file secret: it’s like a password for the
service account.

For more details on setting up authentication and authorization so your
application can access GCP services, check out the documentation.

Now let’s create a Google Cloud Storage bucket to store our SavedModels (a
GCS bucket is a container for your data). For this we will use the google-
cloud-storage library, which is preinstalled in Colab. We first create a Client
object, which will serve as the interface with GCS, then we use it to create
the bucket:

from google.cloud import storage

project_id = "my_project"  # change this to your project ID
bucket_name = "my_bucket"  # change this to a unique bucket name
location = "us-central1"

storage_client = storage.Client(project=project_id)
bucket = storage_client.create_bucket(bucket_name, location=location)

If you want to reuse an existing bucket, replace the last line with bucket =
storage_client.bucket(bucket_name). Make sure location is set to the bucket’s region.

TIP

GCS uses a single worldwide namespace for buckets, so simple names like
“machine-learning” will most likely not be available. Make sure the bucket
name conforms to DNS naming conventions, as it may be used in DNS
records. Moreover, bucket names are public, so do not put anything private in
the name. It is common to use your domain name, your company name, or
your project ID as a prefix to ensure uniqueness, or simply use a random
number as part of the name.

You can change the region if you want, but be sure to choose one that
supports GPUs. Also, you may want to consider the fact that prices vary
greatly between regions, some regions produce much more CO₂ than others,
some regions do not support all services, and using a single-region bucket
improves performance. See Google Cloud’s list of regions and Vertex AI’s
documentation on locations for more details. If you are unsure, it might be
best to stick with "us-central1".

Next, let’s upload the my_mnist_model directory to the new bucket. Files in
GCS are called blobs (or objects), and under the hood they are all just placed
in the bucket without any directory structure. Blob names can be arbitrary
Unicode strings, and they can even contain forward slashes (/). The GCP
console and other tools use these slashes to give the illusion that there are
directories. So, when we upload the my_mnist_model directory, we only care
about the files, not the directories:

def upload_directory(bucket, dirpath):
    dirpath = Path(dirpath)
    for filepath in dirpath.glob("**/*"):
        if filepath.is_file():
            blob = bucket.blob(filepath.relative_to(dirpath.parent).as_posix())
            blob.upload_from_filename(filepath)

upload_directory(bucket, "my_mnist_model")

This function works fine now, but it would be very slow if there were many
files to upload. It’s not too hard to speed it up tremendously by
multithreading it (see the notebook for an implementation). Alternatively, if
you have the Google Cloud CLI, then you can use following command
instead:

!gsutil -m cp -r my_mnist_model gs://{bucket_name}/

Next, let’s tell Vertex AI about our MNIST model. To communicate with
Vertex AI, we can use the google-cloud-aiplatform library (it still uses the old
AI Platform name instead of Vertex AI). It’s not preinstalled in Colab, so we
need to install it. After that, we can import the library and initialize it—just to
specify some default values for the project ID and the location—then we can
create a new Vertex AI model: we specify a display name, the GCS path to
our model (in this case the version 0001), and the URL of the Docker
container we want Vertex AI to use to run this model. If you visit that URL
and navigate up one level, you will find other containers you can use. This
one supports TensorFlow 2.8 with a GPU:

from google.cloud import aiplatform

server_image = "gcr.io/cloud-aiplatform/prediction/tf2-gpu.2-8:latest"

aiplatform.init(project=project_id, location=location)
mnist_model = aiplatform.Model.upload(
    display_name="mnist",
    artifact_uri=f"gs://{bucket_name}/my_mnist_model/0001",
    serving_container_image_uri=server_image,
)

Now let’s deploy this model so we can query it via a gRPC or REST API to
make predictions. For this we first need to create an endpoint. This is what
client applications connect to when they want to access a service. Then we
need to deploy our model to this endpoint:

endpoint = aiplatform.Endpoint.create(display_name="mnist-endpoint")

endpoint.deploy(
    mnist_model,
    min_replica_count=1,
    max_replica_count=5,
    machine_type="n1-standard-4",
    accelerator_type="NVIDIA_TESLA_K80",
    accelerator_count=1
)

This code may take a few minutes to run, because Vertex AI needs to set up a
virtual machine. In this example, we use a fairly basic machine of type n1-
standard-4 (see https://homl.info/machinetypes for other types). We also use a
basic GPU of type NVIDIA_TESLA_K80 (see https://homl.info/accelerators
for other types). If you selected another region than "us-central1", then you
may need to change the machine type or the accelerator type to values that
are supported in that region (e.g., not all regions have Nvidia Tesla K80
GPUs).

NOTE

Google Cloud Platform enforces various GPU quotas, both worldwide and per region: you
cannot create thousands of GPU nodes without prior authorization from Google. To check
your quotas, open “IAM and admin → Quotas” in the GCP console. If some quotas are too
low (e.g., if you need more GPUs in a particular region), you can ask for them to be
increased; it often takes about 48 hours.

Vertex AI will initially spawn the minimum number of compute nodes (just
one in this case), and whenever the number of queries per second becomes
too high, it will spawn more nodes (up to the maximum number you defined,
five in this case) and will load-balance the queries between them. If the QPS

rate goes down for a while, Vertex AI will stop the extra compute nodes
automatically. The cost is therefore directly linked to the load, as well as the
machine and accelerator types you selected and the amount of data you store
on GCS. This pricing model is great for occasional users and for services
with important usage spikes. It’s also ideal for startups: the price remains low
until the startup actually starts up.

Congratulations, you have deployed your first model to the cloud! Now let’s
query this prediction service:

response = endpoint.predict(instances=X_new.tolist())

We first need to convert the images we want to classify to a Python list, as we
did earlier when we sent requests to TF Serving using the REST API. The
response object contains the predictions, represented as a Python list of lists
of floats. Let’s round them to two decimal places and convert them to a
NumPy array:

>>> import numpy as np
>>> np.round(response.predictions, 2)
array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],
       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],
       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])

Yes! We get the exact same predictions as earlier. We now have a nice
prediction service running on the cloud that we can query from anywhere
securely, and which can automatically scale up or down depending on the
number of QPS. When you are done using the endpoint, don’t forget to delete
it, to avoid paying for nothing:

endpoint.undeploy_all()  # undeploy all models from the endpoint
endpoint.delete()

Now let’s see how to run a job on Vertex AI to make predictions on a
potentially very large batch of data.

Running Batch Prediction Jobs on Vertex AI

If we have a large number of predictions to make, then instead of calling our
prediction service repeatedly, we can ask Vertex AI to run a prediction job
for us. This does not require an endpoint, only a model. For example, let’s
run a prediction job on the first 100 images of the test set, using our MNIST
model. For this, we first need to prepare the batch and upload it to GCS. One
way to do this is to create a file containing one instance per line, each
formatted as a JSON value—this format is called JSON Lines—then pass this
file to Vertex AI. So let’s create a JSON Lines file in a new directory, then
upload this directory to GCS:

batch_path = Path("my_mnist_batch")
batch_path.mkdir(exist_ok=True)
with open(batch_path / "my_mnist_batch.jsonl", "w") as jsonl_file:
    for image in X_test[:100].tolist():
        jsonl_file.write(json.dumps(image))
        jsonl_file.write("\n")

upload_directory(bucket, batch_path)

Now we’re ready to launch the prediction job, specifying the job’s name, the
type and number of machines and accelerators to use, the GCS path to the
JSON Lines file we just created, and the path to the GCS directory where
Vertex AI will save the model’s predictions:

batch_prediction_job = mnist_model.batch_predict(
    job_display_name="my_batch_prediction_job",
    machine_type="n1-standard-4",
    starting_replica_count=1,
    max_replica_count=5,
    accelerator_type="NVIDIA_TESLA_K80",
    accelerator_count=1,
    gcs_source=[f"gs://{bucket_name}/{batch_path.name}/my_mnist_batch.jsonl"],
    gcs_destination_prefix=f"gs://{bucket_name}/my_mnist_predictions/",
    sync=True  # set to False if you don't want to wait for completion
)

For large batches, you can split the inputs into multiple JSON Lines files and list them all
via the gcs_source argument.

TIP

This will take a few minutes, mostly to spawn the compute nodes on Vertex
AI. Once this command completes, the predictions will be available in a set
of files named something like prediction.results-00001-of-00002. These files
use the JSON Lines format by default, and each value is a dictionary
containing an instance and its corresponding prediction (i.e., 10
probabilities). The instances are listed in the same order as the inputs. The job
also outputs prediction-errors* files, which can be useful for debugging if
something goes wrong. We can iterate through all these output files using
batch_prediction_job.iter_outputs(), so let’s go through all the predictions
and store them in a y_probas array:

y_probas = []
for blob in batch_prediction_job.iter_outputs():
    if "prediction.results" in blob.name:
        for line in blob.download_as_text().splitlines():
            y_proba = json.loads(line)["prediction"]
            y_probas.append(y_proba)

Now let’s see how good these predictions are:

>>> y_pred = np.argmax(y_probas, axis=1)
>>> accuracy = np.sum(y_pred == y_test[:100]) / 100
0.98

Nice, 98% accuracy!

The JSON Lines format is the default, but when dealing with large instances
such as images, it is too verbose. Luckily, the batch_predict() method accepts
an instances_format argument that lets you choose another format if you
want. It defaults to "jsonl", but you can change it to "csv", "tf-record", "tf-
record-gzip", "bigquery", or "file-list". If you set it to "file-list", then the
gcs_source argument should point to a text file containing one input filepath

per line; for instance, pointing to PNG image files. Vertex AI will read these
files as binary, encode them using Base64, and pass the resulting byte strings
to the model. This means that you must add a preprocessing layer in your
model to parse the Base64 strings, using tf.io.decode_base64(). If the files are
images, you must then parse the result using a function like
tf.io.decode_image() or tf.io.decode_png(), as discussed in Chapter 13.

When you’re finished using the model, you can delete it if you want, by
running mnist_model.delete(). You can also delete the directories you created
in your GCS bucket, optionally the bucket itself (if it’s empty), and the batch
prediction job:

for prefix in ["my_mnist_model/", "my_mnist_batch/", "my_mnist_predictions/"]:
    blobs = bucket.list_blobs(prefix=prefix)
    for blob in blobs:
        blob.delete()

bucket.delete()  # if the bucket is empty
batch_prediction_job.delete()

You now know how to deploy a model to Vertex AI, create a prediction
service, and run batch prediction jobs. But what if you want to deploy your
model to a mobile app instead? Or to an embedded device, such as a heating
control system, a fitness tracker, or a self-driving car?

Deploying a Model to a Mobile or Embedded Device

Machine learning models are not limited to running on big centralized servers
with multiple GPUs: they can run closer to the source of data (this is called
edge computing), for example in the user’s mobile device or in an embedded
device. There are many benefits to decentralizing the computations and
moving them toward the edge: it allows the device to be smart even when it’s
not connected to the internet, it reduces latency by not having to send data to
a remote server and reduces the load on the servers, and it may improve
privacy, since the user’s data can stay on the device.

However, deploying models to the edge has its downsides too. The device’s
computing resources are generally tiny compared to a beefy multi-GPU
server. A large model may not fit in the device, it may use too much RAM
and CPU, and it may take too long to download. As a result, the application
may become unresponsive, and the device may heat up and quickly run out of
battery. To avoid all this, you need to make a lightweight and efficient model,
without sacrificing too much of its accuracy. The TFLite library provides
several tools⁠
objectives:

 to help you deploy your models to the edge, with three main

7

Reduce the model size, to shorten download time and reduce RAM
usage.

Reduce the amount of computations needed for each prediction, to
reduce latency, battery usage, and heating.

Adapt the model to device-specific constraints.

To reduce the model size, TFLite’s model converter can take a SavedModel
and compress it to a much lighter format based on FlatBuffers. This is an
efficient cross-platform serialization library (a bit like protocol buffers)
initially created by Google for gaming. It is designed so you can load
FlatBuffers straight to RAM without any preprocessing: this reduces the
loading time and memory footprint. Once the model is loaded into a mobile

or embedded device, the TFLite interpreter will execute it to make
predictions. Here is how you can convert a SavedModel to a FlatBuffer and
save it to a .tflite file:

converter = tf.lite.TFLiteConverter.from_saved_model(str(model_path))
tflite_model = converter.convert()
with open("my_converted_savedmodel.tflite", "wb") as f:
    f.write(tflite_model)

You can also save a Keras model directly to a FlatBuffer using
tf.lite.TFLiteConverter.from_keras_model(model).

TIP

The converter also optimizes the model, both to shrink it and to reduce its
latency. It prunes all the operations that are not needed to make predictions
(such as training operations), and it optimizes computations whenever
possible; for example, 3 × a + 4 ×_ a_ + 5 × a will be converted to 12 × a.
Addtionally, it tries to fuse operations whenever possible. For example, if
possible, batch normalization layers end up folded into the previous layer’s
addition and multiplication operations. To get a good idea of how much
TFLite can optimize a model, download one of the pretrained TFLite models,
such as Inception_V1_quant (click tflite&pb), unzip the archive, then open
the excellent Netron graph visualization tool and upload the .pb file to view
the original model. It’s a big, complex graph, right? Next, open the optimized
.tflite model and marvel at its beauty!

Another way you can reduce the model size—other than simply using smaller
neural network architectures—is by using smaller bit-widths: for example, if
you use half-floats (16 bits) rather than regular floats (32 bits), the model size
will shrink by a factor of 2, at the cost of a (generally small) accuracy drop.
Moreover, training will be faster, and you will use roughly half the amount of
GPU RAM.

TFLite’s converter can go further than that, by quantizing the model weights
down to fixed-point, 8-bit integers! This leads to a fourfold size reduction

compared to using 32-bit floats. The simplest approach is called post-training
quantization: it just quantizes the weights after training, using a fairly basic
but efficient symmetrical quantization technique. It finds the maximum
absolute weight value, m, then it maps the floating-point range –m to +m to
the fixed-point (integer) range –127 to +127. For example, if the weights
range from –1.5 to +0.8, then the bytes –127, 0, and +127 will correspond to
the floats –1.5, 0.0, and +1.5, respectively (see Figure 19-5). Note that 0.0
always maps to 0 when using symmetrical quantization. Also note that the
byte values +68 to +127 will not be used in this example, since they map to
floats greater than +0.8.

Figure 19-5. From 32-bit floats to 8-bit integers, using symmetrical quantization

To perform this post-training quantization, simply add DEFAULT to the list
of converter optimizations before calling the convert() method:

converter.optimizations = [tf.lite.Optimize.DEFAULT]

This technique dramatically reduces the model’s size, which makes it much
faster to download, and uses less storage space. At runtime the quantized
weights get converted back to floats before they are used. These recovered
floats are not perfectly identical to the original floats, but they’re not too far
off, so the accuracy loss is usually acceptable. To avoid recomputing the float
values all the time, which would severely slow down the model, TFLite
caches them: unfortunately, this means that this technique does not reduce
RAM usage, and it doesn’t speed up the model either. It’s mostly useful to
reduce the application’s size.

The most effective way to reduce latency and power consumption is to also

quantize the activations so that the computations can be done entirely with
integers, without the need for any floating-point operations. Even when using
the same bit-width (e.g., 32-bit integers instead of 32-bit floats), integer
computations use less CPU cycles, consume less energy, and produce less
heat. And if you also reduce the bit-width (e.g., down to 8-bit integers), you
can get huge speedups. Moreover, some neural network accelerator devices—
such as Google’s Edge TPU—can only process integers, so full quantization
of both weights and activations is compulsory. This can be done post-
training; it requires a calibration step to find the maximum absolute value of
the activations, so you need to provide a representative sample of training
data to TFLite (it does not need to be huge), and it will process the data
through the model and measure the activation statistics required for
quantization. This step is typically fast.

The main problem with quantization is that it loses a bit of accuracy: it is
similar to adding noise to the weights and activations. If the accuracy drop is
too severe, then you may need to use quantization-aware training. This
means adding fake quantization operations to the model so it can learn to
ignore the quantization noise during training; the final weights will then be
more robust to quantization. Moreover, the calibration step can be taken care
of automatically during training, which simplifies the whole process.

I have explained the core concepts of TFLite, but going all the way to coding
a mobile or embedded application woud require a dedicated book.
Fortunately, some exist: if you want to learn more about building TensorFlow
applications for mobile and embedded devices, check out the O’Reilly books
TinyML: Machine Learning with TensorFlow on Arduino and Ultra-Low
Power Micro-Controllers, by Pete Warden (former lead of the TFLite team)
and Daniel Situnayake and AI and Machine Learning for On-Device
Development, by Laurence Moroney.

Now what if you want to use your model in a website, running directly in the
user’s browser?

Running a Model in a Web Page

Running your machine learning model on the client side, in the user’s
browser, rather than on the server side can be useful in many scenarios, such
as:

When your web application is often used in situations where the user’s
connectivity is intermittent or slow (e.g., a website for hikers), so
running the model directly on the client side is the only way to make
your website reliable.

When you need the model’s responses to be as fast as possible (e.g., for
an online game). Removing the need to query the server to make
predictions will definitely reduce the latency and make the website much
more responsive.

When your web service makes predictions based on some private user
data, and you want to protect the user’s privacy by making the
predictions on the client side so that the private data never has to leave
the user’s machine.

For all these scenarios, you can use the TensorFlow.js (TFJS) JavaScript
library. This library can load a TFLite model and make predictions directly in
the user’s browser. For example, the following JavaScript module imports the
TFJS library, downloads a pretrained MobileNet model, and uses this model
to classify an image and log the predictions. You can play with the code at
https://homl.info/tfjscode, using Glitch.com, a website that lets you build web
apps in your browser for free; click the PREVIEW button in the lower-right
corner of the page to see the code in action:

import "https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest";
import "https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet@1.0.0";

const image = document.getElementById("image");

mobilenet.load().then(model => {

    model.classify(image).then(predictions => {
        for (var i = 0; i < predictions.length; i++) {
            let className = predictions[i].className
            let proba = (predictions[i].probability * 100).toFixed(1)
            console.log(className + " : " + proba + "%");
        }
    });
});

It’s even possible to turn this website into a progressive web app (PWA): this
8
is a website that respects a number of criteria⁠
 that allow it to be viewed in
any browser, and even installed as a standalone app on a mobile device. For
example, try visiting https://homl.info/tfjswpa on a mobile device: most
modern browsers will ask you whether you would like to add TFJS Demo to
your home screen. If you accept, you will see a new icon in your list of
applications. Clicking this icon will load the TFJS Demo website inside its
own window, just like a regular mobile app. A PWA can even be configured
to work offline, by using a service worker: this is a JavaScript module that
runs in its own separate thread in the browser and intercepts network
requests, allowing it to cache resources so the PWA can run faster, or even
entirely offline. It can also deliver push messages, run tasks in the
background, and more. PWAs allow you to manage a single code base for the
web and for mobile devices. They also make it easier to ensure that all users
run the same version of your application. You can play with this TFJS
Demo’s PWA code on Glitch.com at https://homl.info/wpacode.

Check out many more demos of machine learning models running in your browser at
https://tensorflow.org/js/demos.

TIP

TFJS also supports training a model directly in your web browser! And it’s
actually pretty fast. If your computer has a GPU card, then TFJS can
generally use it, even if it’s not an Nvidia card. Indeed, TFJS will use
WebGL when it’s available, and since modern web browsers generally
support a wide range of GPU cards, TFJS actually supports more GPU cards

than regular TensorFlow (which only supports Nvidia cards).

Training a model in a user’s web browser can be especially useful to
guarantee that this user’s data remains private. A model can be trained
centrally, and then fine-tuned locally, in the browser, based on that user’s
data. If you’re interested in this topic, check out federated learning.

Once again, doing justice to this topic would require a whole book. If you
want to learn more about TensorFlow.js, check out the O’reilly books
Practical Deep Learning for Cloud, Mobile, and Edge, by Anirudh Koul et
al., or Learning TensorFlow.js, by Gant Laborde.

Now that you’ve seen how to deploy TensorFlow models to TF Serving, or to
the cloud with Vertex AI, or to mobile and embedded devices using TFLite,
or to a web browser using TFJS, let’s discuss how to use GPUs to speed up
computations.

Using GPUs to Speed Up Computations

In Chapter 11 we looked at several techniques that can considerably speed up
training: better weight initialization, sophisticated optimizers, and so on. But
even with all of these techniques, training a large neural network on a single
machine with a single CPU can take hours, days, or even weeks, depending
on the task. Thanks to GPUs, this training time can be reduced down to
minutes or hours. Not only does this save an enormous amount of time, but it
also means that you can experiment with various models much more easily,
and frequently retrain your models on fresh data.

In the previous chapters, we used GPU-enabled runtimes on Google Colab.
All you have to do for this is select “Change runtime type” from the Runtime
menu, and choose the GPU accelerator type; TensorFlow automatically
detects the GPU and uses it to speed up computations, and the code is exactly
the same as without a GPU. Then, in this chapter you saw how to deploy your
models to Vertex AI on multiple GPU-enabled compute nodes: it’s just a
matter of selecting the right GPU-enabled Docker image when creating the
Vertex AI model, and selecting the desired GPU type when calling
endpoint.deploy(). But what if you want to buy your own GPU? And what if
you want to distribute the computations across the CPU and multiple GPU
devices on a single machine (see Figure 19-6)? This is what we will discuss
now, then later in this chapter we will discuss how to distribute computations
across multiple servers.

Figure 19-6. Executing a TensorFlow graph across multiple devices in parallel

Getting Your Own GPU

If you know that you’ll be using a GPU heavily and for a long period of time,
then buying your own can make financial sense. You may also want to train
your models locally because you do not want to upload your data to the
cloud. Or perhaps you just want to buy a GPU card for gaming, and you’d
like to use it for deep learning as well.

If you decide to purchase a GPU card, then take some time to make the right
choice. You will need to consider the amount of RAM you will need for your
tasks (e.g., typically at least 10 GB for image processing or NLP), the
bandwidth (i.e., how fast you can send data into and out of the GPU), the
number of cores, the cooling system, etc. Tim Dettmers wrote an excellent
blog post to help you choose: I encourage you to read it carefully. At the time
of this writing, TensorFlow only supports Nvidia cards with CUDA Compute
Capability 3.5+ (as well as Google’s TPUs, of course), but it may extend its
support to other manufacturers, so make sure to check TensorFlow’s
documentation to see what devices are supported today.

9

If you go for an Nvidia GPU card, you will need to install the appropriate
Nvidia drivers and several Nvidia libraries.⁠
 These include the Compute
Unified Device Architecture library (CUDA) Toolkit, which allows
developers to use CUDA-enabled GPUs for all sorts of computations (not just
graphics acceleration), and the CUDA Deep Neural Network library
(cuDNN), a GPU-accelerated library of common DNN computations such as
activation layers, normalization, forward and backward convolutions, and
pooling (see Chapter 14). cuDNN is part of Nvidia’s Deep Learning SDK.
Note that you will need to create an Nvidia developer account in order to
download it. TensorFlow uses CUDA and cuDNN to control the GPU cards
and accelerate computations (see Figure 19-7).

Figure 19-7. TensorFlow uses CUDA and cuDNN to control GPUs and boost DNNs

Once you have installed the GPU card(s) and all the required drivers and
libraries, you can use the nvidia-smi command to check that everything is
properly installed. This command lists the available GPU cards, as well as all
the processes running on each card. In this example, it’s an Nvidia Tesla T4
GPU card with about 15 GB of available RAM, and there are no processes
currently running on it:

$ nvidia-smi
Sun Apr 10 04:52:10 2022
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+================
======|
|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |
| N/A   34C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |

|        ID   ID                                                   Usage      |
|=======================================================================
======|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

To check that TensorFlow actually sees your GPU, run the following
commands and make sure the result is not empty:

>>> physical_gpus = tf.config.list_physical_devices("GPU")
>>> physical_gpus
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]

Managing the GPU RAM

By default TensorFlow automatically grabs almost all the RAM in all
available GPUs the first time you run a computation. It does this to limit GPU
RAM fragmentation. This means that if you try to start a second TensorFlow
program (or any program that requires the GPU), it will quickly run out of
RAM. This does not happen as often as you might think, as you will most
often have a single TensorFlow program running on a machine: usually a
training script, a TF Serving node, or a Jupyter notebook. If you need to run
multiple programs for some reason (e.g., to train two different models in
parallel on the same machine), then you will need to split the GPU RAM
between these processes more evenly.

If you have multiple GPU cards on your machine, a simple solution is to
assign each of them to a single process. To do this, you can set the
CUDA_VISIBLE_DEVICES environment variable so that each process only
sees the appropriate GPU card(s). Also set the CUDA_DEVICE_ORDER
environment variable to PCI_BUS_ID to ensure that each ID always refers to
the same GPU card. For example, if you have four GPU cards, you could
start two programs, assigning two GPUs to each of them, by executing
commands like the following in two separate terminal windows:

$ CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=0,1 python3 
program_1.py
# and in another terminal:
$ CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=3,2 python3 
program_2.py

Program 1 will then only see GPU cards 0 and 1, named "/gpu:0" and
"/gpu:1", respectively, in TensorFlow, and program 2 will only see GPU
cards 2 and 3, named "/gpu:1" and "/gpu:0", respectively (note the order).
Everything will work fine (see Figure 19-8). Of course, you can also define
these environment variables in Python by setting
os.environ["CUDA_DEVICE_ORDER"] and os.environ["CUDA_
VISI⁠ BLE_DEVICES"], as long as you do so before using TensorFlow.

Figure 19-8. Each program gets two GPUs

Another option is to tell TensorFlow to grab only a specific amount of GPU
RAM. This must be done immediately after importing TensorFlow. For
example, to make TensorFlow grab only 2 GiB of RAM on each GPU, you
must create a logical GPU device (sometimes called a virtual GPU device)
for each physical GPU device and set its memory limit to 2 GiB (i.e.,
2,048 MiB):

for gpu in physical_gpus:
    tf.config.set_logical_device_configuration(
        gpu,
        [tf.config.LogicalDeviceConfiguration(memory_limit=2048)]
    )

Let’s suppose you have four GPUs, each with at least 4 GiB of RAM: in this
case, two programs like this one can run in parallel, each using all four GPU
cards (see Figure 19-9). If you run the nvidia-smi command while both
programs are running, you should see that each process holds 2 GiB of RAM
on each card.

Figure 19-9. Each program gets all four GPUs, but with only 2 GiB of RAM on each GPU

Yet another option is to tell TensorFlow to grab memory only when it needs
it. Again, this must be done immediately after importing TensorFlow:

for gpu in physical_gpus:
    tf.config.experimental.set_memory_growth(gpu, True)

Another way to do this is to set the TF_FORCE_GPU_ALLOW_GROWTH
environment variable to true. With this option, TensorFlow will never release
memory once it has grabbed it (again, to avoid memory fragmentation),
except of course when the program ends. It can be harder to guarantee
deterministic behavior using this option (e.g., one program may crash
because another program’s memory usage went through the roof), so in
production you’ll probably want to stick with one of the previous options.
However, there are some cases where it is very useful: for example, when
you use a machine to run multiple Jupyter notebooks, several of which use
TensorFlow. The TF_FORCE_GPU_ALLOW_GROWTH environment
variable is set to true in Colab runtimes.

Lastly, in some cases you may want to split a GPU into two or more logical
devices. For example, this is useful if you only have one physical GPU—like
in a Colab runtime—but you want to test a multi-GPU algorithm. The

following code splits GPU #0 into two logical devices, with 2 GiB of RAM
each (again, this must be done immediately after importing TensorFlow):

tf.config.set_logical_device_configuration(
    physical_gpus[0],
    [tf.config.LogicalDeviceConfiguration(memory_limit=2048),
     tf.config.LogicalDeviceConfiguration(memory_limit=2048)]
)

These two logical devices are called "/gpu:0" and "/gpu:1", and you can use
them as if they were two normal GPUs. You can list all logical devices like
this:

>>> logical_gpus = tf.config.list_logical_devices("GPU")
>>> logical_gpus
[LogicalDevice(name='/device:GPU:0', device_type='GPU'),
 LogicalDevice(name='/device:GPU:1', device_type='GPU')]

Now let’s see how TensorFlow decides which devices it should use to place
variables and execute operations.

Placing Operations and Variables on Devices

Keras and tf.data generally do a good job of placing operations and variables
where they belong, but you can also place operations and variables manually
on each device, if you want more control:

You generally want to place the data preprocessing operations on the
CPU, and place the neural network operations on the GPUs.

GPUs usually have a fairly limited communication bandwidth, so it is
important to avoid unnecessary data transfers into and out of the GPUs.

Adding more CPU RAM to a machine is simple and fairly cheap, so
there’s usually plenty of it, whereas the GPU RAM is baked into the
GPU: it is an expensive and thus limited resource, so if a variable is not
needed in the next few training steps, it should probably be placed on
the CPU (e.g., datasets generally belong on the CPU).

By default, all variables and all operations will be placed on the first GPU
(the one named "/gpu:0"), except for variables and operations that don’t have
a GPU kernel:⁠
tensor or variable’s device attribute tells you which device it was placed
on:⁠

 these are placed on the CPU (always named "/cpu:0"). A

10

11

>>> a = tf.Variable([1., 2., 3.])  # float32 variable goes to the GPU
>>> a.device
'/job:localhost/replica:0/task:0/device:GPU:0'
>>> b = tf.Variable([1, 2, 3])  # int32 variable goes to the CPU
>>> b.device
'/job:localhost/replica:0/task:0/device:CPU:0'

You can safely ignore the prefix /job:localhost/replica:0/task:0 for now; we
will discuss jobs, replicas, and tasks later in this chapter. As you can see, the
first variable was placed on GPU #0, which is the default device. However,
the second variable was placed on the CPU: this is because there are no GPU
kernels for integer variables, or for operations involving integer tensors, so
TensorFlow fell back to the CPU.

If you want to place an operation on a different device than the default one,
use a tf.device() context:

>>> with tf.device("/cpu:0"):
...     c = tf.Variable([1., 2., 3.])
...
>>> c.device
'/job:localhost/replica:0/task:0/device:CPU:0'

NOTE

The CPU is always treated as a single device ("/cpu:0"), even if your machine has multiple
CPU cores. Any operation placed on the CPU may run in parallel across multiple cores if
it has a multithreaded kernel.

If you explicitly try to place an operation or variable on a device that does not
exist or for which there is no kernel, then TensorFlow will silently fall back
to the device it would have chosen by default. This is useful when you want
to be able to run the same code on different machines that don’t have the
same number of GPUs. However, you can run
tf.config.set_soft_device_placement(False) if you prefer to get an exception.

Now, how exactly does TensorFlow execute operations across multiple
devices?

Parallel Execution Across Multiple Devices

As we saw in Chapter 12, one of the benefits of using TF functions is
parallelism. Let’s look at this a bit more closely. When TensorFlow runs a TF
function, it starts by analyzing its graph to find the list of operations that need
to be evaluated, and it counts how many dependencies each of them has.
TensorFlow then adds each operation with zero dependencies (i.e., each
source operation) to the evaluation queue of this operation’s device (see
Figure 19-10). Once an operation has been evaluated, the dependency counter
of each operation that depends on it is decremented. Once an operation’s
dependency counter reaches zero, it is pushed to the evaluation queue of its
device. And once all the outputs have been computed, they are returned.

Figure 19-10. Parallelized execution of a TensorFlow graph

Operations in the CPU’s evaluation queue are dispatched to a thread pool
called the inter-op thread pool. If the CPU has multiple cores, then these
operations will effectively be evaluated in parallel. Some operations have
multithreaded CPU kernels: these kernels split their tasks into multiple
suboperations, which are placed in another evaluation queue and dispatched
to a second thread pool called the intra-op thread pool (shared by all
multithreaded CPU kernels). In short, multiple operations and suboperations
may be evaluated in parallel on different CPU cores.

For the GPU, things are a bit simpler. Operations in a GPU’s evaluation
queue are evaluated sequentially. However, most operations have
multithreaded GPU kernels, typically implemented by libraries that
TensorFlow depends on, such as CUDA and cuDNN. These implementations
have their own thread pools, and they typically exploit as many GPU threads
as they can (which is the reason why there is no need for an inter-op thread
pool in GPUs: each operation already floods most GPU threads).

For example, in Figure 19-10, operations A, B, and C are source ops, so they
can immediately be evaluated. Operations A and B are placed on the CPU, so
they are sent to the CPU’s evaluation queue, then they are dispatched to the
inter-op thread pool and immediately evaluated in parallel. Operation A
happens to have a multithreaded kernel; its computations are split into three
parts, which are executed in parallel by the intra-op thread pool. Operation C
goes to GPU #0’s evaluation queue, and in this example its GPU kernel
happens to use cuDNN, which manages its own intra-op thread pool and runs
the operation across many GPU threads in parallel. Suppose C finishes first.
The dependency counters of D and E are decremented and they reach 0, so
both operations are pushed to GPU #0’s evaluation queue, and they are
executed sequentially. Note that C only gets evaluated once, even though
both D and E depend on it. Suppose B finishes next. Then F’s dependency
counter is decremented from 4 to 3, and since that’s not 0, it does not run yet.
Once A, D, and E are finished, then F’s dependency counter reaches 0, and it
is pushed to the CPU’s evaluation queue and evaluated. Finally, TensorFlow
returns the requested outputs.

An extra bit of magic that TensorFlow performs is when the TF function
modifies a stateful resource, such as a variable: it ensures that the order of
execution matches the order in the code, even if there is no explicit
dependency between the statements. For example, if your TF function
contains v.assign_add(1) followed by v.assign(v * 2), TensorFlow will ensure
that these operations are executed in that order.

TIP

You can control the number of threads in the inter-op thread pool by calling
tf.config.threading.set_inter_op_parallelism_threads(). To set the number of intra-op
threads, use tf.config.threading.set_intra_op_parallelism_threads(). This is useful if you do
not want TensorFlow to use all the CPU cores or if you want it to be single-threaded.⁠

12

With that, you have all you need to run any operation on any device, and
exploit the power of your GPUs! Here are some of the things you could do:

You could train several models in parallel, each on its own GPU: just
write a training script for each model and run them in parallel, setting
CUDA_DEVICE_ORDER and CUDA_VISIBLE_DEVICES so that
each script only sees a single GPU device. This is great for
hyperparameter tuning, as you can train in parallel multiple models with
different hyperparameters. If you have a single machine with two GPUs,
and it takes one hour to train one model on one GPU, then training two
models in parallel, each on its own dedicated GPU, will take just one
hour. Simple!

You could train a model on a single GPU and perform all the
preprocessing in parallel on the CPU, using the dataset’s prefetch()
method⁠
ready when the GPU needs them (see Chapter 13).

 to prepare the next few batches in advance so that they are

13

If your model takes two images as input and processes them using two
CNNs before joining their outputs,⁠
 then it will probably run much
faster if you place each CNN on a different GPU.

14

You can create an efficient ensemble: just place a different trained
model on each GPU so that you can get all the predictions much faster
to produce the ensemble’s final prediction.

But what if you want to speed up training by using multiple GPUs?

Training Models Across Multiple Devices

There are two main approaches to training a single model across multiple
devices: model parallelism, where the model is split across the devices, and
data parallelism, where the model is replicated across every device, and each
replica is trained on a different subset of the data. Let’s look at these two
options.

Model Parallelism

So far we have trained each neural network on a single device. What if we
want to train a single neural network across multiple devices? This requires
chopping the model into separate chunks and running each chunk on a
different device. Unfortunately, such model parallelism turns out to be pretty
tricky, and its effectiveness really depends on the architecture of your neural
network. For fully connected networks, there is generally not much to be
gained from this approach (see Figure 19-11). Intuitively, it may seem that an
easy way to split the model is to place each layer on a different device, but
this does not work because each layer needs to wait for the output of the
previous layer before it can do anything. So perhaps you can slice it vertically
—for example, with the left half of each layer on one device, and the right
part on another device? This is slightly better, since both halves of each layer
can indeed work in parallel, but the problem is that each half of the next layer
requires the output of both halves, so there will be a lot of cross-device
communication (represented by the dashed arrows). This is likely to
completely cancel out the benefit of the parallel computation, since cross-
device communication is slow (and even more so when the devices are
located on different machines).

Figure 19-11. Splitting a fully connected neural network

Some neural network architectures, such as convolutional neural networks
(see Chapter 14), contain layers that are only partially connected to the lower
layers, so it is much easier to distribute chunks across devices in an efficient
way (Figure 19-12).

Figure 19-12. Splitting a partially connected neural network

Deep recurrent neural networks (see Chapter 15) can be split a bit more
efficiently across multiple GPUs. If you split the network horizontally by
placing each layer on a different device, and feed the network with an input
sequence to process, then at the first time step only one device will be active
(working on the sequence’s first value), at the second step two will be active
(the second layer will be handling the output of the first layer for the first
value, while the first layer will be handling the second value), and by the time
the signal propagates to the output layer, all devices will be active
simultaneously (Figure 19-13). There is still a lot of cross-device
communication going on, but since each cell may be fairly complex, the
benefit of running multiple cells in parallel may (in theory) outweigh the
communication penalty. However, in practice a regular stack of LSTM layers
running on a single GPU actually runs much faster.

Figure 19-13. Splitting a deep recurrent neural network

In short, model parallelism may speed up running or training some types of
neural networks, but not all, and it requires special care and tuning, such as
making sure that devices that need to communicate the most run on the same
machine.⁠
 Next we’ll look at a much simpler and generally more efficient
option: data parallelism.

15

Data Parallelism

Another way to parallelize the training of a neural network is to replicate it on
every device and run each training step simultaneously on all replicas, using a
different mini-batch for each. The gradients computed by each replica are
then averaged, and the result is used to update the model parameters. This is
called data parallelism, or sometimes single program, multiple data (SPMD).
There are many variants of this idea, so let’s look at the most important ones.

Data parallelism using the mirrored strategy

Arguably the simplest approach is to completely mirror all the model
parameters across all the GPUs and always apply the exact same parameter
updates on every GPU. This way, all replicas always remain perfectly
identical. This is called the mirrored strategy, and it turns out to be quite
efficient, especially when using a single machine (see Figure 19-14).

Figure 19-14. Data parallelism using the mirrored strategy

The tricky part when using this approach is to efficiently compute the mean
of all the gradients from all the GPUs and distribute the result across all the
GPUs. This can be done using an AllReduce algorithm, a class of algorithms
where multiple nodes collaborate to efficiently perform a reduce operation
(such as computing the mean, sum, and max), while ensuring that all nodes
obtain the same final result. Fortunately, there are off-the-shelf
implementations of such algorithms, as you will see.

Data parallelism with centralized parameters

Another approach is to store the model parameters outside of the GPU

devices performing the computations (called workers); for example, on the
CPU (see Figure 19-15). In a distributed setup, you may place all the
parameters on one or more CPU-only servers called parameter servers,
whose only role is to host and update the parameters.

Figure 19-15. Data parallelism with centralized parameters

Whereas the mirrored strategy imposes synchronous weight updates across
all GPUs, this centralized approach allows either synchronous or
asynchronous updates. Let’s take a look at the pros and cons of both options.

Synchronous updates

With synchronous updates, the aggregator waits until all gradients are
available before it computes the average gradients and passes them to the
optimizer, which will update the model parameters. Once a replica has
finished computing its gradients, it must wait for the parameters to be
updated before it can proceed to the next mini-batch. The downside is that
some devices may be slower than others, so the fast devices will have to wait
for the slow ones at every step, making the whole process as slow as the

slowest device. Moreover, the parameters will be copied to every device
almost at the same time (immediately after the gradients are applied), which
may saturate the parameter servers’ bandwidth.

TIP

To reduce the waiting time at each step, you could ignore the gradients from the slowest
few replicas (typically ~10%). For example, you could run 20 replicas, but only aggregate
the gradients from the fastest 18 replicas at each step, and just ignore the gradients from
the last 2. As soon as the parameters are updated, the first 18 replicas can start working
again immediately, without having to wait for the 2 slowest replicas. This setup is
generally described as having 18 replicas plus 2 spare replicas.⁠

16

Asynchronous updates

With asynchronous updates, whenever a replica has finished computing the
gradients, the gradients are immediately used to update the model parameters.
There is no aggregation (it removes the “mean” step in Figure 19-15) and no
synchronization. Replicas work independently of the other replicas. Since
there is no waiting for the other replicas, this approach runs more training
steps per minute. Moreover, although the parameters still need to be copied to
every device at every step, this happens at different times for each replica, so
the risk of bandwidth saturation is reduced.

Data parallelism with asynchronous updates is an attractive choice because of
its simplicity, the absence of synchronization delay, and its better use of the
bandwidth. However, although it works reasonably well in practice, it is
almost surprising that it works at all! Indeed, by the time a replica has
finished computing the gradients based on some parameter values, these
parameters will have been updated several times by other replicas (on
average N – 1 times, if there are N replicas), and there is no guarantee that the
computed gradients will still be pointing in the right direction (see Figure 19-
16). When gradients are severely out of date, they are called stale gradients:
they can slow down convergence, introducing noise and wobble effects (the
learning curve may contain temporary oscillations), or they can even make
the training algorithm diverge.

Figure 19-16. Stale gradients when using asynchronous updates

There are a few ways you can reduce the effect of stale gradients:

Reduce the learning rate.

Drop stale gradients or scale them down.

Adjust the mini-batch size.

Start the first few epochs using just one replica (this is called the
warmup phase). Stale gradients tend to be more damaging at the
beginning of training, when gradients are typically large and the
parameters have not settled into a valley of the cost function yet, so
different replicas may push the parameters in quite different directions.

A paper published by the Google Brain team in 2016⁠
various approaches and found that using synchronous updates with a few
spare replicas was more efficient than using asynchronous updates, not only
converging faster but also producing a better model. However, this is still an
active area of research, so you should not rule out asynchronous updates just
yet.

 benchmarked

17

Bandwidth saturation

Whether you use synchronous or asynchronous updates, data parallelism with
centralized parameters still requires communicating the model parameters
from the parameter servers to every replica at the beginning of each training
step, and the gradients in the other direction at the end of each training step.
Similarly, when using the mirrored strategy, the gradients produced by each
GPU will need to be shared with every other GPU. Unfortunately, there often
comes a point where adding an extra GPU will not improve performance at
all because the time spent moving the data into and out of GPU RAM (and
across the network in a distributed setup) will outweigh the speedup obtained
by splitting the computation load. At that point, adding more GPUs will just
worsen the bandwidth saturation and actually slow down training.

Saturation is more severe for large dense models, since they have a lot of
parameters and gradients to transfer. It is less severe for small models (but the
parallelization gain is limited) and for large sparse models, where the
gradients are typically mostly zeros and so can be communicated efficiently.
Jeff Dean, initiator and lead of the Google Brain project, reported typical
speedups of 25–40× when distributing computations across 50 GPUs for
dense models, and a 300× speedup for sparser models trained across 500
GPUs. As you can see, sparse models really do scale better. Here are a few
concrete examples:

Neural machine translation: 6× speedup on 8 GPUs

Inception/ImageNet: 32× speedup on 50 GPUs

RankBrain: 300× speedup on 500 GPUs

There is plenty of research going on to alleviate the bandwidth saturation
issue, with the goal of allowing training to scale linearly with the number of
GPUs available. For example, a 2018 paper⁠
 by a team of researchers from
Carnegie Mellon University, Stanford University, and Microsoft Research
proposed a system called PipeDream that managed to reduce network
communications by over 90%, making it possible to train large models across
many machines. They achieved this using a new technique called pipeline

18

parallelism, which combines model parallelism and data parallelism: the
model is chopped into consecutive parts, called stages, each of which is
trained on a different machine. This results in an asynchronous pipeline in
which all machines work in parallel with very little idle time. During training,
each stage alternates one round of forward propagation and one round of
backpropagation (see Figure 19-17): it pulls a mini-batch from its input
queue, processes it, and sends the outputs to the next stage’s input queue,
then it pulls one mini-batch of gradients from its gradient queue,
backpropagates these gradients and updates its own model parameters, and
pushes the backpropagated gradients to the previous stage’s gradient queue. It
then repeats the whole process again and again. Each stage can also use
regular data parallelism (e.g., using the mirrored strategy), independently
from the other stages.

Figure 19-17. PipeDream’s pipeline parallelism

However, as it’s presented here, PipeDream would not work so well. To
understand why, consider mini-batch #5 in Figure 19-17: when it went
through stage 1 during the forward pass, the gradients from mini-batch #4
had not yet been backpropagated through that stage, but by the time #5’s
gradients flow back to stage 1, #4’s gradients will have been used to update
the model parameters, so #5’s gradients will be a bit stale. As we have seen,
this can degrade training speed and accuracy, and even make it diverge: the
more stages there are, the worse this problem becomes. The paper’s authors
proposed methods to mitigate this issue, though: for example, each stage
saves weights during forward propagation and restores them during
backpropagation, to ensure that the same weights are used for both the
forward pass and the backward pass. This is called weight stashing. Thanks
to this, PipeDream demonstrates impressive scaling capability, well beyond
simple data parallelism.

The latest breakthrough in this field of research was published in a 2022

19

19

paper⁠
 by Google researchers: they developed a system called Pathways that
uses automated model parallelism, asynchronous gang scheduling, and other
techniques to reach close to 100% hardware utilization across thousands of
TPUs! Scheduling means organizing when and where each task must run, and
gang scheduling means running related tasks at the same time in parallel and
close to each other to reduce the time tasks have to wait for the others’
outputs. As we saw in Chapter 16, this system was used to train a massive
language model across over 6,000 TPUs, with close to 100% hardware
utilization: that’s a mindblowing engineering feat.

At the time of writing, Pathways is not public yet, but it’s likely that in the
near future you will be able to train huge models on Vertex AI using
Pathways or a similar system. In the meantime, to reduce the saturation
problem, you’ll probably want to use a few powerful GPUs rather than plenty
of weak GPUs, and if you need to train a model across multiple servers, you
should group your GPUs on few and very well interconnected servers. You
can also try dropping the float precision from 32 bits (tf.float32) to 16 bits
(tf.bfloat16). This will cut in half the amount of data to transfer, often without
much impact on the convergence rate or the model’s performance. Lastly, if
you are using centralized parameters, you can shard (split) the parameters
across multiple parameter servers: adding more parameter servers will reduce
the network load on each server and limit the risk of bandwidth saturation.

OK, now that we’ve gone through all the theory, let’s actually train a model
across multiple GPUs!

Training at Scale Using the Distribution Strategies API

Luckily, TensorFlow comes with a very nice API that takes care of all the
complexity of distributing your model across multiple devices and machines:
the distribution strategies API. To train a Keras model across all available
GPUs (on a single machine, for now) using data parallelism with the mirrored
strategy, just create a MirroredStrategy object, call its scope() method to get a
distribution context, and wrap the creation and compilation of your model
inside that context. Then call the model’s fit() method normally:

strategy = tf.distribute.MirroredStrategy()

with strategy.scope():
    model = tf.keras.Sequential([...])  # create a Keras model normally
    model.compile([...])  # compile the model normally

batch_size = 100  # preferably divisible by the number of replicas
model.fit(X_train, y_train, epochs=10,
          validation_data=(X_valid, y_valid), batch_size=batch_size)

Under the hood, Keras is distribution-aware, so in this MirroredStrategy
context it knows that it must replicate all variables and operations across all
available GPU devices. If you look at the model’s weights, they are of type
MirroredVariable:

>>> type(model.weights[0])
tensorflow.python.distribute.values.MirroredVariable

Note that the fit() method will automatically split each training batch across
all the replicas, so it’s preferable to ensure that the batch size is divisible by
the number of replicas (i.e., the number of available GPUs) so that all replicas
get batches of the same size. And that’s all! Training will generally be
significantly faster than using a single device, and the code change was really
minimal.

Once you have finished training your model, you can use it to make
predictions efficiently: call the predict() method, and it will automatically

split the batch across all replicas, making predictions in parallel. Again, the
batch size must be divisible by the number of replicas. If you call the model’s
save() method, it will be saved as a regular model, not as a mirrored model
with multiple replicas. So when you load it, it will run like a regular model,
on a single device: by default on GPU #0, or on the CPU if there are no
GPUs. If you want to load a model and run it on all available devices, you
must call tf.keras.models.load_model() within a distribution context:

with strategy.scope():
    model = tf.keras.models.load_model("my_mirrored_model")

If you only want to use a subset of all the available GPU devices, you can
pass the list to the MirroredStrategy’s constructor:

strategy = tf.distribute.MirroredStrategy(devices=["/gpu:0", "/gpu:1"])

By default, the MirroredStrategy class uses the NVIDIA Collective
Communications Library (NCCL) for the AllReduce mean operation, but you
can change it by setting the cross_device_ops argument to an instance of the
tf.distribute.HierarchicalCopyAllReduce class, or an instance of the
tf.distribute.ReductionToOneDevice class. The default NCCL option is based
on the tf.distribute.NcclAllReduce class, which is usually faster, but this
depends on the number and types of GPUs, so you may want to give the
alternatives a try.⁠

20

If you want to try using data parallelism with centralized parameters, replace
the MirroredStrategy with the CentralStorageStrategy:

strategy = tf.distribute.experimental.CentralStorageStrategy()

You can optionally set the compute_devices argument to specify the list of
devices you want to use as workers—by default it will use all available GPUs
—and you can optionally set the parameter_device argument to specify the
device you want to store the parameters on. By default it will use the CPU, or
the GPU if there is just one.

Now let’s see how to train a model across a cluster of TensorFlow servers!

Training a Model on a TensorFlow Cluster

A TensorFlow cluster is a group of TensorFlow processes running in parallel,
usually on different machines, and talking to each other to complete some
work—for example, training or executing a neural network model. Each TF
process in the cluster is called a task, or a TF server. It has an IP address, a
port, and a type (also called its role or its job). The type can be either
"worker", "chief", "ps" (parameter server), or "evaluator":

Each worker performs computations, usually on a machine with one or
more GPUs.

The chief performs computations as well (it is a worker), but it also
handles extra work such as writing TensorBoard logs or saving
checkpoints. There is a single chief in a cluster. If no chief is specified
explicitly, then by convention the first worker is the chief.

A parameter server only keeps track of variable values, and it is usually
on a CPU-only machine. This type of task is only used with the
ParameterServerStrategy.

An evaluator obviously takes care of evaluation. This type is not used
often, and when it’s used, there’s usually just one evaluator.

To start a TensorFlow cluster, you must first define its specification. This
means defining each task’s IP address, TCP port, and type. For example, the
following cluster specification defines a cluster with three tasks (two workers
and one parameter server; see Figure 19-18). The cluster spec is a dictionary
with one key per job, and the values are lists of task addresses (IP:port):

cluster_spec = {
    "worker": [
        "machine-a.example.com:2222",     # /job:worker/task:0
        "machine-b.example.com:2222"      # /job:worker/task:1
    ],
    "ps": ["machine-a.example.com:2221"]  # /job:ps/task:0
}

In general there will be a single task per machine, but as this example shows,
you can configure multiple tasks on the same machine if you want. In this
case, if they share the same GPUs, make sure the RAM is split appropriately,
as discussed earlier.

WARNING

By default, every task in the cluster may communicate with every other task, so make sure
to configure your firewall to authorize all communications between these machines on
these ports (it’s usually simpler if you use the same port on every machine).

Figure 19-18. An example TensorFlow cluster

When you start a task, you must give it the cluster spec, and you must also
tell it what its type and index are (e.g., worker #0). The simplest way to
specify everything at once (both the cluster spec and the current task’s type
and index) is to set the TF_CONFIG environment variable before starting
TensorFlow. It must be a JSON-encoded dictionary containing a cluster
specification (under the "cluster" key) and the type and index of the current

task (under the "task" key). For example, the following TF_CONFIG
environment variable uses the cluster we just defined and specifies that the
task to start is worker #0:

os.environ["TF_CONFIG"] = json.dumps({
    "cluster": cluster_spec,
    "task": {"type": "worker", "index": 0}
})

TIP

In general you want to define the TF_CONFIG environment variable outside of Python, so
the code does not need to include the current task’s type and index (this makes it possible
to use the same code across all workers).

Now let’s train a model on a cluster! We will start with the mirrored strategy.
First, you need to set the TF_CONFIG environment variable appropriately
for each task. There should be no parameter server (remove the "ps" key in
the cluster spec), and in general you will want a single worker per machine.
Make extra sure you set a different task index for each task. Finally, run the
following script on every worker:

import tempfile
import tensorflow as tf

strategy = tf.distribute.MultiWorkerMirroredStrategy()  # at the start!
resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()
print(f"Starting task {resolver.task_type} #{resolver.task_id}")
[...] # load and split the MNIST dataset

with strategy.scope():
    model = tf.keras.Sequential([...])  # build the Keras model
    model.compile([...])  # compile the model

model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=10)

if resolver.task_id == 0:  # the chief saves the model to the right location
    model.save("my_mnist_multiworker_model", save_format="tf")
else:
    tmpdir = tempfile.mkdtemp()  # other workers save to a temporary directory

    model.save(tmpdir, save_format="tf")
    tf.io.gfile.rmtree(tmpdir)  # and we can delete this directory at the end!

That’s almost the same code you used earlier, except this time you are using
the MultiWorkerMirroredStrategy. When you start this script on the first
workers, they will remain blocked at the AllReduce step, but training will
begin as soon as the last worker starts up, and you will see them all
advancing at exactly the same rate since they synchronize at each step.

WARNING

When using the MultiWorkerMirroredStrategy, it’s important to ensure that all workers do
the same thing, including saving model checkpoints or writing TensorBoard logs, even
though you will only keep what the chief writes. This is because these operations may
need to run the AllReduce operations, so all workers must be in sync.

There are two AllReduce implementations for this distribution strategy: a ring
AllReduce algorithm based on gRPC for the network communications, and
NCCL’s implementation. The best algorithm to use depends on the number
of workers, the number and types of GPUs, and the network. By default,
TensorFlow will apply some heuristics to select the right algorithm for you,
but you can force NCCL (or RING) like this:

strategy = tf.distribute.MultiWorkerMirroredStrategy(
    communication_options=tf.distribute.experimental.CommunicationOptions(
        implementation=tf.distribute.experimental.CollectiveCommunication.NCCL))

If you prefer to implement asynchronous data parallelism with parameter
servers, change the strategy to ParameterServerStrategy, add one or more
parameter servers, and configure TF_CONFIG appropriately for each task.
Note that although the workers will work asynchronously, the replicas on
each worker will work synchronously.

Lastly, if you have access to TPUs on Google Cloud—for example, if you
use Colab and you set the accelerator type to TPU—then you can create a
TPUStrategy like this:

resolver = tf.distribute.cluster_resolver.TPUClusterResolver()
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)

This needs to be run right after importing TensorFlow. You can then use this
strategy normally.

If you are a researcher, you may be eligible to use TPUs for free; see
https://tensorflow.org/tfrc for more details.

TIP

You can now train models across multiple GPUs and multiple servers: give
yourself a pat on the back! If you want to train a very large model, however,
you will need many GPUs, across many servers, which will require either
buying a lot of hardware or managing a lot of cloud virtual machines. In
many cases, it’s less hassle and less expensive to use a cloud service that
takes care of provisioning and managing all this infrastructure for you, just
when you need it. Let’s see how to do that using Vertex AI.

Running Large Training Jobs on Vertex AI

Vertex AI allows you to create custom training jobs with your own training
code. In fact, you can use almost the same training code as you would use on
your own TF cluster. The main thing you must change is where the chief
should save the model, the checkpoints, and the TensorBoard logs. Instead of
saving the model to a local directory, the chief must save it to GCS, using the
path provided by Vertex AI in the AIP_MODEL_DIR environment variable.
For the model checkpoints and TensorBoard logs, you should use the paths
contained in the AIP_CHECKPOINT_DIR and
AIP_TENSORBOARD_LOG_DIR environment variables, respectively. Of
course, you must also make sure that the training data can be accessed from
the virtual machines, such as on GCS, or another GCP service like BigQuery,
or directly from the web. Lastly, Vertex AI sets the "chief" task type
explicitly, so you should identify the chief using resolved.task_type ==
"chief" instead of resolved.task_id == 0:

import os
[...]  # other imports, create MultiWorkerMirroredStrategy, and resolver

if resolver.task_type == "chief":
    model_dir = os.getenv("AIP_MODEL_DIR")  # paths provided by Vertex AI
    tensorboard_log_dir = os.getenv("AIP_TENSORBOARD_LOG_DIR")
    checkpoint_dir = os.getenv("AIP_CHECKPOINT_DIR")
else:
    tmp_dir = Path(tempfile.mkdtemp())  # other workers use temporary dirs
    model_dir = tmp_dir / "model"
    tensorboard_log_dir = tmp_dir / "logs"
    checkpoint_dir = tmp_dir / "ckpt"

callbacks = [tf.keras.callbacks.TensorBoard(tensorboard_log_dir),
             tf.keras.callbacks.ModelCheckpoint(checkpoint_dir)]
[...]  # build and  compile using the strategy scope, just like earlier
model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=10,
          callbacks=callbacks)
model.save(model_dir, save_format="tf")

TIP

If you place the training data on GCS, you can create a tf.data.TextLineDataset or
tf.data.TFRecordDataset to access it: just use the GCS paths as the filenames (e.g.,
gs://my_bucket/data/001.csv). These datasets rely on the tf.io.gfile package to access files:
it supports both local files and GCS files.

Now you can create a custom training job on Vertex AI, based on this script.
You’ll need to specify the job name, the path to your training script, the
Docker image to use for training, the one to use for predictions (after
training), any additional Python libraries you may need, and lastly the bucket
that Vertex AI should use as a staging directory to store the training script.
By default, that’s also where the training script will save the trained model, as
well as the TensorBoard logs and model checkpoints (if any). Let’s create the
job:

custom_training_job = aiplatform.CustomTrainingJob(
    display_name="my_custom_training_job",
    script_path="my_vertex_ai_training_task.py",
    container_uri="gcr.io/cloud-aiplatform/training/tf-gpu.2-4:latest",
    model_serving_container_image_uri=server_image,
    requirements=["gcsfs==2022.3.0"],  # not needed, this is just an example
    staging_bucket=f"gs://{bucket_name}/staging"
)

And now let’s run it on two workers, each with two GPUs:

mnist_model2 = custom_training_job.run(
    machine_type="n1-standard-4",
    replica_count=2,
    accelerator_type="NVIDIA_TESLA_K80",
    accelerator_count=2,
)

And that’s it: Vertex AI will provision the compute nodes you requested
(within your quotas), and it will run your training script across them. Once
the job is complete, the run() method will return a trained model that you can
use exactly like the one you created earlier: you can deploy it to an endpoint,
or use it to make batch predictions. If anything goes wrong during training,
you can view the logs in the GCP console: in the ☰ navigation menu, select

Vertex AI → Training, click on your training job, and click VIEW LOGS.
Alternatively, you can click the CUSTOM JOBS tab and copy the job’s ID
(e.g., 1234), then select Logging from the ☰ navigation menu and query
resource.labels.job_id=1234.

TIP

To visualize the training progress, just start TensorBoard and point its --logdir to the GCS
path of the logs. It will use application default credentials, which you can set up using
gcloud auth application-default login. Vertex AI also offers hosted TensorBoard servers if
you prefer.

If you want to try out a few hyperparameter values, one option is to run
multiple jobs. You can pass the hyperparameter values to your script as
command-line arguments by setting the args parameter when calling the run()
method, or you can pass them as environment variables using the
environment_variables parameter.

However, if you want to run a large hyperparameter tuning job on the cloud,
a much better option is to use Vertex AI’s hyperparameter tuning service.
Let’s see how.

Hyperparameter Tuning on Vertex AI

Vertex AI’s hyperparameter tuning service is based on a Bayesian
optimization algorithm, capable of quickly finding optimal combinations of
hyperparameters. To use it, you first need to create a training script that
accepts hyperparameter values as command-line arguments. For example,
your script could use the argparse standard library like this:

import argparse

parser = argparse.ArgumentParser()
parser.add_argument("--n_hidden", type=int, default=2)
parser.add_argument("--n_neurons", type=int, default=256)
parser.add_argument("--learning_rate", type=float, default=1e-2)
parser.add_argument("--optimizer", default="adam")
args = parser.parse_args()

The hyperparameter tuning service will call your script multiple times, each
time with different hyperparameter values: each run is called a trial, and the
set of trials is called a study. Your training script must then use the given
hyperparameter values to build and compile a model. You can use a mirrored
distribution strategy if you want, in case each trial runs on a multi-GPU
machine. Then the script can load the dataset and train the model. For
example:

import tensorflow as tf

def build_model(args):
    with tf.distribute.MirroredStrategy().scope():
        model = tf.keras.Sequential()
        model.add(tf.keras.layers.Flatten(input_shape=[28, 28], dtype=tf.uint8))
        for _ in range(args.n_hidden):
            model.add(tf.keras.layers.Dense(args.n_neurons, activation="relu"))
        model.add(tf.keras.layers.Dense(10, activation="softmax"))
        opt = tf.keras.optimizers.get(args.optimizer)
        opt.learning_rate = args.learning_rate
        model.compile(loss="sparse_categorical_crossentropy", optimizer=opt,
                      metrics=["accuracy"])
        return model

[...]  # load the dataset
model = build_model(args)
history = model.fit([...])

You can use the AIP_* environment variables we mentioned earlier to determine where to
save the checkpoints, the TensorBoard logs, and the final model.

TIP

Lastly, the script must report the model’s performance back to Vertex AI’s
hyperparameter tuning service, so it can decide which hyperparameters to try
next. For this, you must use the hypertune library, which is automatically
installed on Vertex AI training VMs:

import hypertune

hypertune = hypertune.HyperTune()
hypertune.report_hyperparameter_tuning_metric(
    hyperparameter_metric_tag="accuracy",  # name of the reported metric
    metric_value=max(history.history["val_accuracy"]),  # metric value
    global_step=model.optimizer.iterations.numpy(),
)

Now that your training script is ready, you need to define the type of machine
you would like to run it on. For this, you must define a custom job, which
Vertex AI will use as a template for each trial:

trial_job = aiplatform.CustomJob.from_local_script(
    display_name="my_search_trial_job",
    script_path="my_vertex_ai_trial.py",  # path to your training script
    container_uri="gcr.io/cloud-aiplatform/training/tf-gpu.2-4:latest",
    staging_bucket=f"gs://{bucket_name}/staging",
    accelerator_type="NVIDIA_TESLA_K80",
    accelerator_count=2,  # in this example, each trial will have 2 GPUs
)

Finally, you’re ready to create and run the hyperparameter tuning job:

from google.cloud.aiplatform import hyperparameter_tuning as hpt

hp_job = aiplatform.HyperparameterTuningJob(
    display_name="my_hp_search_job",
    custom_job=trial_job,
    metric_spec={"accuracy": "maximize"},
    parameter_spec={
        "learning_rate": hpt.DoubleParameterSpec(min=1e-3, max=10, scale="log"),
        "n_neurons": hpt.IntegerParameterSpec(min=1, max=300, scale="linear"),
        "n_hidden": hpt.IntegerParameterSpec(min=1, max=10, scale="linear"),
        "optimizer": hpt.CategoricalParameterSpec(["sgd", "adam"]),
    },
    max_trial_count=100,
    parallel_trial_count=20,
)
hp_job.run()

Here, we tell Vertex AI to maximize the metric named "accuracy": this name
must match the name of the metric reported by the training script. We also
define the search space, using a log scale for the learning rate and a linear
(i.e., uniform) scale for the other hyperparameters. The hyperparameter
names must match the command-line arguments of the training script. Then
we set the maximum number of trials to 100, and the maximum number of
trials running in parallel to 20. If you increase the number of parallel trials to
(say) 60, the total search time will be reduced significantly, by a factor of up
to 3. But the first 60 trials will be started in parallel, so they will not benefit
from the other trials’ feedback. Therefore, you should increase the max
number of trials to compensate—for example, up to about 140.

This will take quite a while. Once the job is completed, you can fetch the trial
results using hp_job.trials. Each trial result is represented as a protobuf
object, containing the hyperparameter values and the resulting metrics. Let’s
find the best trial:

def get_final_metric(trial, metric_id):
    for metric in trial.final_measurement.metrics:
        if metric.metric_id == metric_id:
            return metric.value

trials = hp_job.trials
trial_accuracies = [get_final_metric(trial, "accuracy") for trial in trials]
best_trial = trials[np.argmax(trial_accuracies)]

Now let’s look at this trial’s accuracy, and its hyperparameter values:

>>> max(trial_accuracies)
0.977400004863739
>>> best_trial.id
'98'
>>> best_trial.parameters
[parameter_id: "learning_rate" value { number_value: 0.001 },
 parameter_id: "n_hidden" value { number_value: 8.0 },
 parameter_id: "n_neurons" value { number_value: 216.0 },
 parameter_id: "optimizer" value { string_value: "adam" }
]

That’s it! Now you can get this trial’s SavedModel, optionally train it a bit
more, and deploy it to production.

TIP

Vertex AI also includes an AutoML service, which completely takes care of finding the
right model architecture and training it for you. All you need to do is upload your dataset
to Vertex AI using a special format that depends on the type of dataset (images, text,
tabular, video, etc.), then create an AutoML training job, pointing to the dataset and
specifying the maximum number of compute hours you’re willing to spend. See the
notebook for an example.

HYPERPARAMETER TUNING USING KERAS TUNER ON
VERTEX AI

Instead of using Vertex AI’s hyperparameter tuning service, you can use
Keras Tuner (introduced in Chapter 10) and run it on Vertex AI VMs.
Keras Tuner provides a simple way to scale hyperparameter search by
distributing it across multiple machines: it only requires setting three
environment variables on each machine, then running your regular Keras
Tuner code on each machine. You can use the exact same script on all
machines. One of the machines acts as the chief (i.e., the oracle), and the
others act as workers. Each worker asks the chief which hyperparameter
values to try, then the worker trains the model using these

hyperparameter values, and finally it reports the model’s performance
back to the chief, which can then decide which hyperparameter values the
worker should try next.

The three environment variables you need to set on each machine are:

KERASTUNER_TUNER_ID

This is equal to "chief" on the chief machine, or a unique identifier on
each worker machine, such as "worker0", "worker1", etc.

KERASTUNER_ORACLE_IP

This is the IP address or hostname of the chief machine. The chief
itself should generally use "0.0.0.0" to listen on every IP address on
the machine.

KERASTUNER_ORACLE_PORT

This is the TCP port that the chief will be listening on.

You can distribute Keras Tuner across any set of machines. If you want
to run it on Vertex AI machines, then you can spawn a regular training
job, and just modify the training script to set the environment variables
properly before using Keras Tuner. See the notebook for an example.

Now you have all the tools and knowledge you need to create state-of-the-art
neural net architectures and train them at scale using various distribution
strategies, on your own infrastructure or on the cloud, and then deploy them
anywhere. In other words, you now have superpowers: use them well!

Exercises

1.  What does a SavedModel contain? How do you inspect its content?

2.  When should you use TF Serving? What are its main features? What are

some tools you can use to deploy it?

3.  How do you deploy a model across multiple TF Serving instances?

4.  When should you use the gRPC API rather than the REST API to query

a model served by TF Serving?

5.  What are the different ways TFLite reduces a model’s size to make it

run on a mobile or embedded device?

6.  What is quantization-aware training, and why would you need it?

7.  What are model parallelism and data parallelism? Why is the latter

generally recommended?

8.  When training a model across multiple servers, what distribution
strategies can you use? How do you choose which one to use?

9.  Train a model (any model you like) and deploy it to TF Serving or

Google Vertex AI. Write the client code to query it using the REST API
or the gRPC API. Update the model and deploy the new version. Your
client code will now query the new version. Roll back to the first
version.

10.  Train any model across multiple GPUs on the same machine using the
MirroredStrategy (if you do not have access to GPUs, you can use
Google Colab with a GPU runtime and create two logical GPUs). Train
the model again using the CentralStorageStrategy and compare the
training time.

11.  Fine-tune a model of your choice on Vertex AI, using either Keras

Tuner or Vertex AI’s hyperparameter tuning service.

Solutions to these exercises are available at the end of this chapter’s
notebook, at https://homl.info/colab3.

Thank You!

Before we close the last chapter of this book, I would like to thank you for
reading it up to the last paragraph. I truly hope that you had as much fun
reading this book as I had writing it, and that it will be useful for your
projects, big or small.

If you find errors, please send feedback. More generally, I would love to
know what you think, so please don’t hesitate to contact me via O’Reilly,
through the ageron/handson-ml3 GitHub project, or on Twitter at
@aureliengeron.

Going forward, my best advice to you is to practice and practice: try going
through all the exercises (if you have not done so already), play with the
notebooks, join Kaggle or some other ML community, watch ML courses,
read papers, attend conferences, and meet experts. Things move fast, so try to
keep up to date. Several YouTube channels regularly present deep learning
papers in great detail, in a very approachable way. I particularly recommend
the channels by Yannic Kilcher, Letitia Parcalabescu, and Xander
Steenbrugge. For fascinating ML discussions and higher-level insights, make
sure to check out ML Street Talk, and Lex Fridman’s channel. It also helps
tremendously to have a concrete project to work on, whether it is for work or
for fun (ideally for both), so if there’s anything you have always dreamed of
building, give it a shot! Work incrementally; don’t shoot for the moon right
away, but stay focused on your project and build it piece by piece. It will
require patience and perseverance, but when you have a walking robot, or a
working chatbot, or whatever else you fancy building, it will be immensely
rewarding!

My greatest hope is that this book will inspire you to build a wonderful ML
application that will benefit all of us. What will it be?
—Aurélien Géron

1  An A/B experiment consists in testing two different versions of your product on different

subsets of users in order to check which version works best and get other insights.

2  Google AI Platform (formerly known as Google ML Engine) and Google AutoML merged in

2021 to form Google Vertex AI.

3  A REST (or RESTful) API is an API that uses standard HTTP verbs, such as GET, POST, PUT,
and DELETE, and uses JSON inputs and outputs. The gRPC protocol is more complex but more
efficient; data is exchanged using protocol buffers (see Chapter 13).

4  If you are not familiar with Docker, it allows you to easily download a set of applications

packaged in a Docker image (including all their dependencies and usually some good default
configuration) and then run them on your system using a Docker engine. When you run an
image, the engine creates a Docker container that keeps the applications well isolated from your
own system—but you can give it some limited access if you want. It is similar to a virtual
machine, but much faster and lighter, as the container relies directly on the host’s kernel. This
means that the image does not need to include or run its own kernel.

5  There are also GPU images available, and other installation options. For more details, please

check out the official installation instructions.

6  To be fair, this can be mitigated by serializing the data first and encoding it to Base64 before
creating the REST request. Moreover, REST requests can be compressed using gzip, which
reduces the payload size significantly.

7  Also check out TensorFlow’s Graph Transform Tool for modifying and optimizing

computational graphs.

8  For example, a PWA must include icons of various sizes for different mobile devices, it must be
served via HTTPS, it must include a manifest file containing metadata such as the name of the
app and the background color.

9  Please check the TensorFlow docs for detailed and up-to-date installation instructions, as they

change quite often.

10  As we saw in Chapter 12, a kernel is an operation’s implementation for a specific data type and
device type. For example, there is a GPU kernel for the float32 tf.matmul() operation, but there is
no GPU kernel for int32 tf.matmul(), only a CPU kernel.

11  You can also use tf.debugging.set_log_device_placement(True) to log all device placements.

12  This can be useful if you want to guarantee perfect reproducibility, as I explain in this video,

based on TF 1.

13  At the time of writing, it only prefetches the data to the CPU RAM, but use

tf.data.experimental.pre⁠
of your choice so that the GPU does not waste time waiting for the data to be transferred.

fetch_to_device() to make it prefetch the data and push it to the device

14  If the two CNNs are identical, then it is called a Siamese neural network.

15  If you are interested in going further with model parallelism, check out Mesh TensorFlow.

16  This name is slightly confusing because it sounds like some replicas are special, doing nothing.
In reality, all replicas are equivalent: they all work hard to be among the fastest at each training
step, and the losers vary at every step (unless some devices are really slower than others).

However, it does mean that if one or two servers crash, training will continue just fine.

17  Jianmin Chen et al., “Revisiting Distributed Synchronous SGD”, arXiv preprint

arXiv:1604.00981 (2016).

18  Aaron Harlap et al., “PipeDream: Fast and Efficient Pipeline Parallel DNN Training”, arXiv

preprint arXiv:1806.03377 (2018).

19  Paul Barham et al., “Pathways: Asynchronous Distributed Dataflow for ML”, arXiv preprint

arXiv:2203.12533 (2022).

20  For more details on AllReduce algorithms, read Yuichiro Ueno’s post on the technologies

behind deep learning and Sylvain Jeaugey’s post on massively scaling deep learning training
with NCCL.

Appendix A. Machine Learning
Project Checklist

This checklist can guide you through your machine learning projects. There
are eight main steps:

1.  Frame the problem and look at the big picture.

2.  Get the data.

3.  Explore the data to gain insights.

4.  Prepare the data to better expose the underlying data patterns to machine

learning algorithms.

5.  Explore many different models and shortlist the best ones.

6.  Fine-tune your models and combine them into a great solution.

7.  Present your solution.

8.  Launch, monitor, and maintain your system.

Obviously, you should feel free to adapt this checklist to your needs.

Frame the Problem and Look at the Big Picture

1.  Define the objective in business terms.

2.  How will your solution be used?

3.  What are the current solutions/workarounds (if any)?

4.  How should you frame this problem (supervised/unsupervised,

online/offline, etc.)?

5.  How should performance be measured?

6.  Is the performance measure aligned with the business objective?

7.  What would be the minimum performance needed to reach the business

objective?

8.  What are comparable problems? Can you reuse experience or tools?

9.  Is human expertise available?

10.  How would you solve the problem manually?

11.  List the assumptions you (or others) have made so far.

12.  Verify assumptions if possible.

Get the Data

Note: automate as much as possible so you can easily get fresh data.

1.  List the data you need and how much you need.

2.  Find and document where you can get that data.

3.  Check how much space it will take.

4.  Check legal obligations, and get authorization if necessary.

5.  Get access authorizations.

6.  Create a workspace (with enough storage space).

7.  Get the data.

8.  Convert the data to a format you can easily manipulate (without

changing the data itself).

9.  Ensure sensitive information is deleted or protected (e.g., anonymized).

10.  Check the size and type of data (time series, sample, geographical, etc.).

11.  Sample a test set, put it aside, and never look at it (no data snooping!).

Explore the Data

Note: try to get insights from a field expert for these steps.

1.  Create a copy of the data for exploration (sampling it down to a

manageable size if necessary).

2.  Create a Jupyter notebook to keep a record of your data exploration.

3.  Study each attribute and its characteristics:

Name

Type (categorical, int/float, bounded/unbounded, text, structured,
etc.)

% of missing values

Noisiness and type of noise (stochastic, outliers, rounding errors,
etc.)

Usefulness for the task

Type of distribution (Gaussian, uniform, logarithmic, etc.)

4.  For supervised learning tasks, identify the target attribute(s).

5.  Visualize the data.

6.  Study the correlations between attributes.

7.  Study how you would solve the problem manually.

8.  Identify the promising transformations you may want to apply.

9.  Identify extra data that would be useful (go back to “Get the Data”).

10.  Document what you have learned.

Prepare the Data

Notes:

Work on copies of the data (keep the original dataset intact).

Write functions for all data transformations you apply, for five reasons:

So you can easily prepare the data the next time you get a fresh
dataset

So you can apply these transformations in future projects

To clean and prepare the test set

To clean and prepare new data instances once your solution is live

To make it easy to treat your preparation choices as
hyperparameters

1.  Clean the data:

Fix or remove outliers (optional).

Fill in missing values (e.g., with zero, mean, median…) or drop
their rows (or columns).

2.  Perform feature selection (optional):

Drop the attributes that provide no useful information for the task.

3.  Perform feature engineering, where appropriate:

Discretize continuous features.

Decompose features (e.g., categorical, date/time, etc.).

2
Add promising transformations of features (e.g., log(x), sqrt(x), x ,
etc.).

Aggregate features into promising new features.

4.  Perform feature scaling:

Standardize or normalize features.

Shortlist Promising Models

Notes:

If the data is huge, you may want to sample smaller training sets so you
can train many different models in a reasonable time (be aware that this
penalizes complex models such as large neural nets or random forests).

Once again, try to automate these steps as much as possible.

1.  Train many quick-and-dirty models from different categories

(e.g., linear, naive Bayes, SVM, random forest, neural net, etc.) using
standard parameters.

2.  Measure and compare their performance:

For each model, use N-fold cross-validation and compute the mean
and standard deviation of the performance measure on the N folds.

3.  Analyze the most significant variables for each algorithm.

4.  Analyze the types of errors the models make:

What data would a human have used to avoid these errors?

5.  Perform a quick round of feature selection and engineering.

6.  Perform one or two more quick iterations of the five previous steps.

7.  Shortlist the top three to five most promising models, preferring models

that make different types of errors.

Fine-Tune the System

Notes:

You will want to use as much data as possible for this step, especially as
you move toward the end of fine-tuning.

As always, automate what you can.

1.  Fine-tune the hyperparameters using cross-validation:

Treat your data transformation choices as hyperparameters,
especially when you are not sure about them (e.g., if you’re not
sure whether to replace missing values with zeros or with the
median value, or to just drop the rows).

Unless there are very few hyperparameter values to explore, prefer
random search over grid search. If training is very long, you may
prefer a Bayesian optimization approach (e.g., using Gaussian
process priors, as described by Jasper Snoek et al. ).

1

2.  Try ensemble methods. Combining your best models will often produce

better performance than running them individually.

3.  Once you are confident about your final model, measure its performance

on the test set to estimate the generalization error.

WARNING

Don’t tweak your model after measuring the generalization error: you would just start
overfitting the test set.

Present Your Solution

1.  Document what you have done.

2.  Create a nice presentation:

Make sure you highlight the big picture first.

3.  Explain why your solution achieves the business objective.

4.  Don’t forget to present interesting points you noticed along the way:

Describe what worked and what did not.

List your assumptions and your system’s limitations.

5.  Ensure your key findings are communicated through beautiful

visualizations or easy-to-remember statements (e.g., “the median income
is the number-one predictor of housing prices”).

Launch!

1.  Get your solution ready for production (plug into production data inputs,

write unit tests, etc.).

2.  Write monitoring code to check your system’s live performance at

regular intervals and trigger alerts when it drops:

Beware of slow degradation: models tend to “rot” as data evolves.

Measuring performance may require a human pipeline (e.g., via a
crowdsourcing service).

Also monitor your inputs’ quality (e.g., a malfunctioning sensor
sending random values, or another team’s output becoming stale).
This is particularly important for online learning systems.

3.  Retrain your models on a regular basis on fresh data (automate as much

as possible).

1  Jasper Snoek et al., “Practical Bayesian Optimization of Machine Learning Algorithms”,

Proceedings of the 25th International Conference on Neural Information Processing Systems 2
(2012): 2951–2959.

Appendix B. Autodiff

This appendix explains how TensorFlow’s autodifferentiation (autodiff)
feature works, and how it compares to other solutions.

2

Suppose you define a function f(x, y) = x y + y + 2, and you need its partial
derivatives ∂f/∂x and ∂f/∂y, typically to perform gradient descent (or some
other optimization algorithm). Your main options are manual differentiation,
finite difference approximation, forward-mode autodiff, and reverse-mode
autodiff. TensorFlow implements reverse-mode autodiff, but to understand it,
it’s useful to look at the other options first. So let’s go through each of them,
starting with manual differentiation.

Manual Differentiation

The first approach to compute derivatives is to pick up a pencil and a piece of
paper and use your calculus knowledge to derive the appropriate equation.
For the function f(x, y) just defined, it is not too hard; you just need to use
five rules:

The derivative of a constant is 0.

The derivative of λx is λ (where λ is a constant).

The derivative of x  is λx

λ

λ – 1

, so the derivative of x  is 2x.

2

The derivative of a sum of functions is the sum of these functions’
derivatives.

The derivative of λ times a function is λ times its derivative.

From these rules, you can derive Equation B-1.

Equation B-1. Partial derivatives of f(x, y)

∂f ∂x = ∂(x 2 y) ∂x + ∂y ∂x + ∂2 ∂x = y ∂(x 2 ) ∂x + 0 + 0 = 2 x y ∂f ∂y = ∂(x
2 y) ∂y + ∂y ∂y + ∂2 ∂y = x 2 + 1 + 0 = x 2 + 1

This approach can become very tedious for more complex functions, and you
run the risk of making mistakes. Fortunately, there are other options. Let’s
look at finite difference approximation now.

Finite Difference Approximation

Recall that the derivative h′(x ) of a function h(x) at a point x  is the slope of
the function at that point. More precisely, the derivative is defined as the limit
of the slope of a straight line going through this point x  and another point x
on the function, as x gets infinitely close to x  (see Equation B-2).

0

0

0

0

Equation B-2. Definition of the derivative of a function h(x) at point x
0

h ' ( x 0 ) = lim x→x 0 h(x)-h(x 0 ) x-x 0 = lim ε→0 h(x 0 +ε)-h(x 0 ) ε

So, if we wanted to calculate the partial derivative of f(x, y) with regard to x
at x = 3 and y = 4, we could compute f(3 + ε, 4) – f(3, 4) and divide the result
by ε, using a very small value for ε. This type of numerical approximation of
the derivative is called a finite difference approximation, and this specific
equation is called Newton’s difference quotient. That’s exactly what the
following code does:

def f(x, y):
    return x**2*y + y + 2

def derivative(f, x, y, x_eps, y_eps):
    return (f(x + x_eps, y + y_eps) - f(x, y)) / (x_eps + y_eps)

df_dx = derivative(f, 3, 4, 0.00001, 0)
df_dy = derivative(f, 3, 4, 0, 0.00001)

Unfortunately, the result is imprecise (and it gets worse for more complicated
functions). The correct results are respectively 24 and 10, but instead we get:

>>> df_dx
24.000039999805264
>>> df_dy
10.000000000331966

Notice that to compute both partial derivatives, we have to call f() at least
three times (we called it four times in the preceding code, but it could be
optimized). If there were 1,000 parameters, we would need to call f() at least

1,001 times. When you are dealing with large neural networks, this makes
finite difference approximation way too inefficient.

However, this method is so simple to implement that it is a great tool to
check that the other methods are implemented correctly. For example, if it
disagrees with your manually derived function, then your function probably
contains a mistake.

So far, we have considered two ways to compute gradients: using manual
differentiation and using finite difference approximation. Unfortunately, both
are fatally flawed for training a large-scale neural network. So let’s turn to
autodiff, starting with forward mode.

Forward-Mode Autodiff

Figure B-1 shows how forward-mode autodiff works on an even simpler
function, g(x, y) = 5 + xy. The graph for that function is represented on the
left. After forward-mode autodiff, we get the graph on the right, which
represents the partial derivative ∂g/∂x = 0 + (0 × x + y × 1) = y (we could
similarly obtain the partial derivative with regard to y).

The algorithm will go through the computation graph from the inputs to the
outputs (hence the name “forward mode”). It starts by getting the partial
derivatives of the leaf nodes. The constant node (5) returns the constant 0,
since the derivative of a constant is always 0. The variable x returns the
constant 1 since ∂x/∂x = 1, and the variable y returns the constant 0 since ∂y/
∂x = 0 (if we were looking for the partial derivative with regard to y, it would
be the reverse).

Now we have all we need to move up the graph to the multiplication node in
function g. Calculus tells us that the derivative of the product of two
functions u and v is ∂(u × v)/∂x = ∂v/∂x × u + v × ∂u/∂x. We can therefore
construct a large part of the graph on the right, representing 0 × x + y × 1.

Finally, we can go up to the addition node in function g. As mentioned, the
derivative of a sum of functions is the sum of these functions’ derivatives, so
we just need to create an addition node and connect it to the parts of the
graph we have already computed. We get the correct partial derivative: ∂g/∂x
= 0 + (0 × x + y × 1).

Figure B-1. Forward-mode autodiff

However, this equation can be simplified (a lot). By applying a few pruning
steps to the computation graph to get rid of all the unnecessary operations, we
get a much smaller graph with just one node: ∂g/∂x = y. In this case
simplification is fairly easy, but for a more complex function forward-mode
autodiff can produce a huge graph that may be tough to simplify and lead to
suboptimal performance.

Note that we started with a computation graph, and forward-mode autodiff
produced another computation graph. This is called symbolic differentiation,
and it has two nice features: first, once the computation graph of the
derivative has been produced, we can use it as many times as we want to
compute the derivatives of the given function for any value of x and y;

second, we can run forward-mode autodiff again on the resulting graph to get
second-order derivatives if we ever need to (i.e., derivatives of derivatives).
We could even compute third-order derivatives, and so on.

But it is also possible to run forward-mode autodiff without constructing a
graph (i.e., numerically, not symbolically), just by computing intermediate
results on the fly. One way to do this is to use dual numbers, which are weird
but fascinating numbers of the form a + bε, where a and b are real numbers
and ε is an infinitesimal number such that ε  = 0 (but ε ≠ 0). You can think of
the dual number 42 + 24ε as something akin to 42.0000⋯000024 with an
infinite number of 0s (but of course this is simplified just to give you some
idea of what dual numbers are). A dual number is represented in memory as a
pair of floats. For example, 42 + 24ε is represented by the pair (42.0, 24.0).

2

Dual numbers can be added, multiplied, and so on, as shown in Equation B-3.

Equation B-3. A few operations with dual numbers

λ ( a + b ε ) = λ a + λ b ε ( a + b ε ) + ( c + d ε ) = ( a + c ) + ( b + d ) ε ( a + b
ε ) × ( c + d ε ) = a c + ( a d + b c ) ε + ( b d ) ε 2 = a c + ( a d + b c ) ε

Most importantly, it can be shown that h(a + bε) = h(a) + b × h′(a)ε, so
computing h(a + ε) gives you both h(a) and the derivative h′(a) in just one
shot. Figure B-2 shows that the partial derivative of f(x, y) with regard to x at
x = 3 and y = 4 (which I will write ∂f/∂x (3, 4)) can be computed using dual
numbers. All we need to do is compute f(3 + ε, 4); this will output a dual
number whose first component is equal to f(3, 4) and whose second
component is equal to ∂f/∂x (3, 4).

Figure B-2. Forward-mode autodiff using dual numbers

To compute ∂f/∂y (3, 4) we would have to go through the graph again, but
this time with x = 3 and y = 4 + ε.

So, forward-mode autodiff is much more accurate than finite difference

approximation, but it suffers from the same major flaw, at least when there
are many inputs and few outputs (as is the case when dealing with neural
networks): if there were 1,000 parameters, it would require 1,000 passes
through the graph to compute all the partial derivatives. This is where
reverse-mode autodiff shines: it can compute all of them in just two passes
through the graph. Let’s see how.

Reverse-Mode Autodiff

Reverse-mode autodiff is the solution implemented by TensorFlow. It first
goes through the graph in the forward direction (i.e., from the inputs to the
output) to compute the value of each node. Then it does a second pass, this
time in the reverse direction (i.e., from the output to the inputs), to compute
all the partial derivatives. The name “reverse mode” comes from this second
pass through the graph, where gradients flow in the reverse direction.
Figure B-3 represents the second pass. During the first pass, all the node
values were computed, starting from x = 3 and y = 4. You can see those
values at the bottom right of each node (e.g., x × x = 9). The nodes are labeled
n  to n  for clarity. The output node is n : f(3, 4) = n  = 42.
1

7

7

7

Figure B-3. Reverse-mode autodiff

The idea is to gradually go down the graph, computing the partial derivative
of f(x, y) with regard to each consecutive node, until we reach the variable
nodes. For this, reverse-mode autodiff relies heavily on the chain rule, shown

in Equation B-4.

Equation B-4. Chain rule

∂f ∂x = ∂f ∂n i × ∂n i ∂x

Since n  is the output node, f = n  so ∂f / ∂n  = 1.

7

7

7

Let’s continue down the graph to n : how much does f vary when n  varies?
The answer is ∂f / ∂n  = ∂f / ∂n  × ∂n  / ∂n . We already know that ∂f / ∂n  =
7
7
1, so all we need is ∂n  / ∂n . Since n  simply performs the sum n  + n , we
7
7
find that ∂n  / ∂n  = 1, so ∂f / ∂n  = 1 × 1 = 1.

5

5

6

5

5

7

5

5

7

5

5

Now we can proceed to node n : how much does f vary when n  varies? The
answer is ∂f / ∂n  = ∂f / ∂n  × ∂n  / ∂n . Since n  = n  × n , we find that ∂n  /
4
5
4
∂n  = n , so ∂f / ∂n  = 1 × n  = 4.

4

4

5

2

4

5

5

4

2

4

2

The process continues until we reach the bottom of the graph. At that point
we will have calculated all the partial derivatives of f(x, y) at the point x = 3
and y = 4. In this example, we find ∂f / ∂x = 24 and ∂f / ∂y = 10. Sounds about
right!

Reverse-mode autodiff is a very powerful and accurate technique, especially
when there are many inputs and few outputs, since it requires only one
forward pass plus one reverse pass per output to compute all the partial
derivatives for all outputs with regard to all the inputs. When training neural
networks, we generally want to minimize the loss, so there is a single output
(the loss), and hence only two passes through the graph are needed to
compute the gradients. Reverse-mode autodiff can also handle functions that
are not entirely differentiable, as long as you ask it to compute the partial
derivatives at points that are differentiable.

In Figure B-3, the numerical results are computed on the fly, at each node.
However, that’s not exactly what TensorFlow does: instead, it creates a new
computation graph. In other words, it implements symbolic reverse-mode
autodiff. This way, the computation graph to compute the gradients of the
loss with regard to all the parameters in the neural network only needs to be
generated once, and then it can be executed over and over again, whenever
the optimizer needs to compute the gradients. Moreover, this makes it

possible to compute higher-order derivatives if needed.

TIP

If you ever want to implement a new type of low-level TensorFlow operation in C++, and
you want to make it compatible with autodiff, then you will need to provide a function that
returns the partial derivatives of the function’s outputs with regard to its inputs. For
example, suppose you implement a function that computes the square of its input: f(x) =
2
x . In that case you would need to provide the corresponding derivative function: f′(x) =
2x.

Appendix C. Special Data
Structures

In this appendix we will take a very quick look at the data structures
supported by TensorFlow, beyond regular float or integer tensors. This
includes strings, ragged tensors, sparse tensors, tensor arrays, sets, and
queues.

Strings

Tensors can hold byte strings, which is useful in particular for natural
language processing (see Chapter 16):

>>> tf.constant(b"hello world")
<tf.Tensor: shape=(), dtype=string, numpy=b'hello world'>

If you try to build a tensor with a Unicode string, TensorFlow automatically
encodes it to UTF-8:

>>> tf.constant("café")
<tf.Tensor: shape=(), dtype=string, numpy=b'caf\xc3\xa9'>

It is also possible to create tensors representing Unicode strings. Just create
an array of 32-bit integers, each representing a single Unicode code point:⁠

1

>>> u = tf.constant([ord(c) for c in "café"])
>>> u
<tf.Tensor: shape=(4,), [...], numpy=array([ 99,  97, 102, 233], dtype=int32)>

NOTE

In tensors of type tf.string, the string length is not part of the tensor’s shape. In other
words, strings are considered as atomic values. However, in a Unicode string tensor (i.e.,
an int32 tensor), the length of the string is part of the tensor’s shape.

The tf.strings package contains several functions to manipulate string tensors,
such as length() to count the number of bytes in a byte string (or the number
of code points if you set unit="UTF8_CHAR"), unicode_encode() to convert
a Unicode string tensor (i.e., int32 tensor) to a byte string tensor, and
unicode_decode() to do the reverse:

>>> b = tf.strings.unicode_encode(u, "UTF-8")
>>> b

<tf.Tensor: shape=(), dtype=string, numpy=b'caf\xc3\xa9'>
>>> tf.strings.length(b, unit="UTF8_CHAR")
<tf.Tensor: shape=(), dtype=int32, numpy=4>
>>> tf.strings.unicode_decode(b, "UTF-8")
<tf.Tensor: shape=(4,), [...], numpy=array([ 99,  97, 102, 233], dtype=int32)>

You can also manipulate tensors containing multiple strings:

>>> p = tf.constant(["Café", "Coffee", "caffè", "咖啡"])
>>> tf.strings.length(p, unit="UTF8_CHAR")
<tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 6, 5, 2], dtype=int32)>
>>> r = tf.strings.unicode_decode(p, "UTF8")
>>> r
<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97,
102, 102, 232], [21654, 21857]]>

Notice that the decoded strings are stored in a RaggedTensor. What is that?

Ragged Tensors

A ragged tensor is a special kind of tensor that represents a list of arrays of
different sizes. More generally, it is a tensor with one or more ragged
dimensions, meaning dimensions whose slices may have different lengths. In
the ragged tensor r, the second dimension is a ragged dimension. In all ragged
tensors, the first dimension is always a regular dimension (also called a
uniform dimension).

All the elements of the ragged tensor r are regular tensors. For example, let’s
look at the second element of the ragged tensor:

>>> r[1]
<tf.Tensor: [...], numpy=array([ 67, 111, 102, 102, 101, 101], dtype=int32)>

The tf.ragged package contains several functions to create and manipulate
ragged tensors. Let’s create a second ragged tensor using tf.ragged.constant()
and concatenate it with the first ragged tensor, along axis 0:

>>> r2 = tf.ragged.constant([[65, 66], [], [67]])
>>> tf.concat([r, r2], axis=0)
<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97,
102, 102, 232], [21654, 21857], [65, 66], [], [67]]>

The result is not too surprising: the tensors in r2 were appended after the
tensors in r along axis 0. But what if we concatenate r and another ragged
tensor along axis 1?

>>> r3 = tf.ragged.constant([[68, 69, 70], [71], [], [72, 73]])
>>> print(tf.concat([r, r3], axis=1))
<tf.RaggedTensor [[67, 97, 102, 233, 68, 69, 70], [67, 111, 102, 102, 101, 101,
71], [99, 97, 102, 102, 232], [21654, 21857, 72, 73]]>

This time, notice that the i
 tensor in r and the i
concatenated. Now that’s more unusual, since all of these tensors can have
different lengths.

 tensor in r3 were

th

th

If you call the to_tensor() method, the ragged tensor gets converted to a
regular tensor, padding shorter tensors with zeros to get tensors of equal
lengths (you can change the default value by setting the default_value
argument):

>>> r.to_tensor()
<tf.Tensor: shape=(4, 6), dtype=int32, numpy=
array([[   67,    97,   102,   233,     0,     0],
       [   67,   111,   102,   102,   101,   101],
       [   99,    97,   102,   102,   232,     0],
       [21654, 21857,     0,     0,     0,     0]], dtype=int32)>

Many TF operations support ragged tensors. For the full list, see the
documentation of the tf.RaggedTensor class.

Sparse Tensors

TensorFlow can also efficiently represent sparse tensors (i.e., tensors
containing mostly zeros). Just create a tf.SparseTensor, specifying the indices
and values of the nonzero elements and the tensor’s shape. The indices must
be listed in “reading order” (from left to right, and top to bottom). If you are
unsure, just use tf.sparse.reorder(). You can convert a sparse tensor to a dense
tensor (i.e., a regular tensor) using tf.sparse.to_dense():

>>> s = tf.SparseTensor(indices=[[0, 1], [1, 0], [2, 3]],
...                     values=[1., 2., 3.],
...                     dense_shape=[3, 4])
...
>>> tf.sparse.to_dense(s)
<tf.Tensor: shape=(3, 4), dtype=float32, numpy=
array([[0., 1., 0., 0.],
       [2., 0., 0., 0.],
       [0., 0., 0., 3.]], dtype=float32)>

Note that sparse tensors do not support as many operations as dense tensors.
For example, you can multiply a sparse tensor by any scalar value, and you
get a new sparse tensor, but you cannot add a scalar value to a sparse tensor,
as this would not return a sparse tensor:

>>> s * 42.0
<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f84a6749f10>
>>> s + 42.0
[...] TypeError: unsupported operand type(s) for +: 'SparseTensor' and 'float'

Tensor Arrays

A tf.TensorArray represents a list of tensors. This can be handy in dynamic
models containing loops, to accumulate results and later compute some
statistics. You can read or write tensors at any location in the array:

array = tf.TensorArray(dtype=tf.float32, size=3)
array = array.write(0, tf.constant([1., 2.]))
array = array.write(1, tf.constant([3., 10.]))
array = array.write(2, tf.constant([5., 7.]))
tensor1 = array.read(1)  # => returns (and zeros out!) tf.constant([3., 10.])

By default, reading an item also replaces it with a tensor of the same shape
but full of zeros. You can set clear_after_read to False if you don’t want this.

WARNING

When you write to the array, you must assign the output back to the array, as shown in this
code example. If you don’t, although your code will work fine in eager mode, it will break
in graph mode (these modes are discussed in Chapter 12).

By default, a TensorArray has a fixed size that is set upon creation.
Alternatively, you can set size=0 and dynamic_size=True to let the array
grow automatically when needed. However, this will hinder performance, so
if you know the size in advance, it’s better to use a fixed-size array. You must
also specify the dtype, and all elements must have the same shape as the first
one written to the array.

You can stack all the items into a regular tensor by calling the stack()
method:

>>> array.stack()
<tf.Tensor: shape=(3, 2), dtype=float32, numpy=
array([[1., 2.],
       [0., 0.],
       [5., 7.]], dtype=float32)>

Sets

TensorFlow supports sets of integers or strings (but not floats). It represents
sets using regular tensors. For example, the set {1, 5, 9} is just represented as
the tensor [[1, 5, 9]]. Note that the tensor must have at least two dimensions,
and the sets must be in the last dimension. For example, [[1, 5, 9], [2, 5, 11]]
is a tensor holding two independent sets: {1, 5, 9} and {2, 5, 11}.

The tf.sets package contains several functions to manipulate sets. For
example, let’s create two sets and compute their union (the result is a sparse
tensor, so we call to_dense() to display it):

>>> a = tf.constant([[1, 5, 9]])
>>> b = tf.constant([[5, 6, 9, 11]])
>>> u = tf.sets.union(a, b)
>>> u
<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x132b60d30>
>>> tf.sparse.to_dense(u)
<tf.Tensor: [...], numpy=array([[ 1,  5,  6,  9, 11]], dtype=int32)>

You can also compute the union of multiple pairs of sets simultaneously. If
some sets are shorter than others, you must pad them with a padding value,
such as 0:

>>> a = tf.constant([[1, 5, 9], [10, 0, 0]])
>>> b = tf.constant([[5, 6, 9, 11], [13, 0, 0, 0]])
>>> u = tf.sets.union(a, b)
>>> tf.sparse.to_dense(u)
<tf.Tensor: [...] numpy=array([[ 1,  5,  6,  9, 11],
                               [ 0, 10, 13,  0,  0]], dtype=int32)>

If you prefer to use a different padding value, such as –1, then you must set
default_value=-1 (or your preferred value) when calling to_dense().

The default default_value is 0, so when dealing with string sets, you must set this

WARNING

parameter (e.g., to an empty string).

Other functions available in tf.sets include difference(), intersection(), and
size(), which are self-explanatory. If you want to check whether or not a set
contains some given values, you can compute the intersection of that set and
the values. If you want to add some values to a set, you can compute the
union of the set and the values.

Queues

A queue is a data structure to which you can push data records, and later pull
them out. TensorFlow implements several types of queues in the tf.queue
package. They used to be very important when implementing efficient data
loading and preprocessing pipelines, but the tf.data API has essentially
rendered them useless (except perhaps in some rare cases) because it is much
simpler to use and provides all the tools you need to build efficient pipelines.
For the sake of completeness, though, let’s take a quick look at them.

The simplest kind of queue is the first-in, first-out (FIFO) queue. To build it,
you need to specify the maximum number of records it can contain.
Moreover, each record is a tuple of tensors, so you must specify the type of
each tensor, and optionally their shapes. For example, the following code
example creates a FIFO queue with a maximum of three records, each
containing a tuple with a 32-bit integer and a string. Then it pushes two
records to it, looks at the size (which is 2 at this point), and pulls a record out:

>>> q = tf.queue.FIFOQueue(3, [tf.int32, tf.string], shapes=[(), ()])
>>> q.enqueue([10, b"windy"])
>>> q.enqueue([15, b"sunny"])
>>> q.size()
<tf.Tensor: shape=(), dtype=int32, numpy=2>
>>> q.dequeue()
[<tf.Tensor: shape=(), dtype=int32, numpy=10>,
 <tf.Tensor: shape=(), dtype=string, numpy=b'windy'>]

It is also possible to enqueue and dequeue multiple records at once using
enqueue_many() and dequeue_many() (to use dequeue_many(), you must
specify the shapes argument when you create the queue, as we did
previously):

>>> q.enqueue_many([[13, 16], [b'cloudy', b'rainy']])
>>> q.dequeue_many(3)
[<tf.Tensor: [...], numpy=array([15, 13, 16], dtype=int32)>,
 <tf.Tensor: [...], numpy=array([b'sunny', b'cloudy', b'rainy'], dtype=object)>]

Other queue types include:

PaddingFIFOQueue

Same as FIFOQueue, but its dequeue_many() method supports
dequeueing multiple records of different shapes. It automatically pads the
shortest records to ensure all the records in the batch have the same
shape.

PriorityQueue

A queue that dequeues records in a prioritized order. The priority must be
a 64-bit integer included as the first element of each record. Surprisingly,
records with a lower priority will be dequeued first. Records with the
same priority will be dequeued in FIFO order.

RandomShuffleQueue

A queue whose records are dequeued in random order. This was useful to
implement a shuffle buffer before tf.data existed.

If a queue is already full and you try to enqueue another record, the enqueue*
() method will freeze until a record is dequeued by another thread. Similarly,
if a queue is empty and you try to dequeue a record, the dequeue*() method
will freeze until records are pushed to the queue by another thread.

1  If you are not familiar with Unicode code points, please check out https://homl.info/unicode.

Appendix D. TensorFlow Graphs

In this appendix, we will explore the graphs generated by TF functions (see
Chapter 12).

TF Functions and Concrete Functions

TF functions are polymorphic, meaning they support inputs of different types
(and shapes). For example, consider the following tf_cube() function:

@tf.function
def tf_cube(x):
    return x ** 3

Every time you call a TF function with a new combination of input types or
shapes, it generates a new concrete function, with its own graph specialized
for this particular combination. Such a combination of argument types and
shapes is called an input signature. If you call the TF function with an input
signature it has already seen before, it will reuse the concrete function it
generated earlier. For example, if you call tf_cube(tf.constant(3.0)), the TF
function will reuse the same concrete function it used for
tf_cube(tf.constant(2.0)) (for float32 scalar tensors). But it will generate a
new concrete function if you call tf_cube(tf.constant([2.0])) or
tf_cube(tf.constant([3.0])) (for float32 tensors of shape [1]), and yet another
for tf_cube(tf.constant([[1.0, 2.0], [3.0, 4.0]])) (for float32 tensors of shape
[2, 2]). You can get the concrete function for a particular combination of
inputs by calling the TF function’s get_concrete_function() method. It can
then be called like a regular function, but it will only support one input
signature (in this example, float32 scalar tensors):

>>> concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))
>>> concrete_function
<ConcreteFunction tf_cube(x) at 0x7F84411F4250>
>>> concrete_function(tf.constant(2.0))
<tf.Tensor: shape=(), dtype=float32, numpy=8.0>

Figure D-1 shows the tf_cube() TF function, after we called tf_cube(2) and
tf_cube(tf.constant(2.0)): two concrete functions were generated, one for each
signature, each with its own optimized function graph (FuncGraph) and its
own function definition (FunctionDef). A function definition points to the

parts of the graph that correspond to the function’s inputs and outputs. In
each FuncGraph, the nodes (ovals) represent operations (e.g., power,
constants, or placeholders for arguments like x), while the edges (the solid
arrows between the operations) represent the tensors that will flow through
the graph. The concrete function on the left is specialized for x=2, so
TensorFlow managed to simplify it to just output 8 all the time (note that the
function definition does not even have an input). The concrete function on the
right is specialized for float32 scalar tensors, and it could not be simplified. If
we call tf_cube(tf.constant(5.0)), the second concrete function will be called,
the placeholder operation for x will output 5.0, then the power operation will
compute 5.0 ** 3, so the output will be 125.0.

Figure D-1. The tf_cube() TF function, with its ConcreteFunctions and their FuncGraphs

The tensors in these graphs are symbolic tensors, meaning they don’t have an
actual value, just a data type, a shape, and a name. They represent the future
tensors that will flow through the graph once an actual value is fed to the
placeholder x and the graph is executed. Symbolic tensors make it possible to
specify ahead of time how to connect operations, and they also allow
TensorFlow to recursively infer the data types and shapes of all tensors, given
the data types and shapes of their inputs.

Now let’s continue to peek under the hood, and see how to access function
definitions and function graphs and how to explore a graph’s operations and
tensors.

Exploring Function Definitions and Graphs

You can access a concrete function’s computation graph using the graph
attribute, and get the list of its operations by calling the graph’s
get_operations() method:

>>> concrete_function.graph
<tensorflow.python.framework.func_graph.FuncGraph at 0x7f84411f4790>
>>> ops = concrete_function.graph.get_operations()
>>> ops
[<tf.Operation 'x' type=Placeholder>,
 <tf.Operation 'pow/y' type=Const>,
 <tf.Operation 'pow' type=Pow>,
 <tf.Operation 'Identity' type=Identity>]

In this example, the first operation represents the input argument x (it is
called a placeholder), the second “operation” represents the constant 3, the
third operation represents the power operation (**), and the final operation
represents the output of this function (it is an identity operation, meaning it
will do nothing more than copy the output of the power operation⁠
). Each
operation has a list of input and output tensors that you can easily access
using the operation’s inputs and outputs attributes. For example, let’s get the
list of inputs and outputs of the power operation:

1

>>> pow_op = ops[2]
>>> list(pow_op.inputs)
[<tf.Tensor 'x:0' shape=() dtype=float32>,
 <tf.Tensor 'pow/y:0' shape=() dtype=float32>]
>>> pow_op.outputs
[<tf.Tensor 'pow:0' shape=() dtype=float32>]

This computation graph is represented in Figure D-2.

Figure D-2. Example of a computation graph

Note that each operation has a name. It defaults to the name of the operation
(e.g., "pow"), but you can define it manually when calling the operation (e.g.,
tf.pow(x, 3, name="other_name")). If a name already exists, TensorFlow
automatically adds a unique index (e.g., "pow_1", "pow_2", etc.). Each tensor
also has a unique name: it is always the name of the operation that outputs
this tensor, plus :0 if it is the operation’s first output, or :1 if it is the second
output, and so on. You can fetch an operation or a tensor by name using the
graph’s get_operation_by_name() or get_tensor_by_name() methods:

>>> concrete_function.graph.get_operation_by_name('x')
<tf.Operation 'x' type=Placeholder>
>>> concrete_function.graph.get_tensor_by_name('Identity:0')
<tf.Tensor 'Identity:0' shape=() dtype=float32>

The concrete function also contains the function definition (represented as a
protocol buffer⁠
), which includes the function’s signature. This signature
allows the concrete function to know which placeholders to feed with the
input values, and which tensors to return:

2

>>> concrete_function.function_def.signature
name: "__inference_tf_cube_3515903"
input_arg {
  name: "x"
  type: DT_FLOAT
}
output_arg {
  name: "identity"

  type: DT_FLOAT
}

Now let’s look more closely at tracing.

A Closer Look at Tracing

Let’s tweak the tf_cube() function to print its input:

@tf.function
def tf_cube(x):
    print(f"x = {x}")
    return x ** 3

Now let’s call it:

>>> result = tf_cube(tf.constant(2.0))
x = Tensor("x:0", shape=(), dtype=float32)
>>> result
<tf.Tensor: shape=(), dtype=float32, numpy=8.0>

The result looks good, but look at what was printed: x is a symbolic tensor! It
has a shape and a data type, but no value. Plus it has a name ("x:0"). This is
because the print() function is not a TensorFlow operation, so it will only run
when the Python function is traced, which happens in graph mode, with
arguments replaced with symbolic tensors (same type and shape, but no
value). Since the print() function was not captured into the graph, the next
times we call tf_cube() with float32 scalar tensors, nothing is printed:

>>> result = tf_cube(tf.constant(3.0))
>>> result = tf_cube(tf.constant(4.0))

But if we call tf_cube() with a tensor of a different type or shape, or with a
new Python value, the function will be traced again, so the print() function
will be called:

>>> result = tf_cube(2)  # new Python value: trace!
x = 2
>>> result = tf_cube(3)  # new Python value: trace!
x = 3
>>> result = tf_cube(tf.constant([[1., 2.]]))  # new shape: trace!
x = Tensor("x:0", shape=(1, 2), dtype=float32)
>>> result = tf_cube(tf.constant([[3., 4.], [5., 6.]]))  # new shape: trace!

x = Tensor("x:0", shape=(None, 2), dtype=float32)
>>> result = tf_cube(tf.constant([[7., 8.], [9., 10.]]))  # same shape: no trace

WARNING

If your function has Python side effects (e.g., it saves some logs to disk), be aware that this
code will only run when the function is traced (i.e., every time the TF function is called
with a new input signature). It’s best to assume that the function may be traced (or not)
any time the TF function is called.

In some cases, you may want to restrict a TF function to a specific input
signature. For example, suppose you know that you will only ever call a TF
function with batches of 28 × 28–pixel images, but the batches will have very
different sizes. You may not want TensorFlow to generate a different
concrete function for each batch size, or count on it to figure out on its own
when to use None. In this case, you can specify the input signature like this:

@tf.function(input_signature=[tf.TensorSpec([None, 28, 28], tf.float32)])
def shrink(images):
    return images[:, ::2, ::2]  # drop half the rows and columns

This TF function will accept any float32 tensor of shape [*, 28, 28], and it
will reuse the same concrete function every time:

img_batch_1 = tf.random.uniform(shape=[100, 28, 28])
img_batch_2 = tf.random.uniform(shape=[50, 28, 28])
preprocessed_images = shrink(img_batch_1)  # works fine, traces the function
preprocessed_images = shrink(img_batch_2)  # works fine, same concrete function

However, if you try to call this TF function with a Python value, or a tensor
of an unexpected data type or shape, you will get an exception:

img_batch_3 = tf.random.uniform(shape=[2, 2, 2])
preprocessed_images = shrink(img_batch_3)  # ValueError! Incompatible inputs

Using AutoGraph to Capture Control Flow

If your function contains a simple for loop, what do you expect will happen?
For example, let’s write a function that will add 10 to its input, by just adding
1 10 times:

@tf.function
def add_10(x):
    for i in range(10):
        x += 1
    return x

It works fine, but when we look at its graph, we find that it does not contain a
loop: it just contains 10 addition operations!

>>> add_10(tf.constant(0))
<tf.Tensor: shape=(), dtype=int32, numpy=15>
>>> add_10.get_concrete_function(tf.constant(0)).graph.get_operations()
[<tf.Operation 'x' type=Placeholder>, [...],
 <tf.Operation 'add' type=AddV2>, [...],
 <tf.Operation 'add_1' type=AddV2>, [...],
 <tf.Operation 'add_2' type=AddV2>, [...],
 [...]
 <tf.Operation 'add_9' type=AddV2>, [...],
 <tf.Operation 'Identity' type=Identity>]

This actually makes sense: when the function got traced, the loop ran 10
times, so the x += 1 operation was run 10 times, and since it was in graph
mode, it recorded this operation 10 times in the graph. You can think of this
for loop as a “static” loop that gets unrolled when the graph is created.

If you want the graph to contain a “dynamic” loop instead (i.e., one that runs
when the graph is executed), you can create one manually using the
tf.while_loop() operation, but it is not very intuitive (see the “Using
AutoGraph to Capture Control Flow” section of the Chapter 12 notebook for
an example). Instead, it is much simpler to use TensorFlow’s AutoGraph
feature, discussed in Chapter 12. AutoGraph is actually activated by default
(if you ever need to turn it off, you can pass autograph=False to tf.function()).

So if it is on, why didn’t it capture the for loop in the add_10() function? It
only captures for loops that iterate over tensors of tf.data.Dataset objects, so
you should use tf.range(), not range(). This is to give you the choice:

If you use range(), the for loop will be static, meaning it will only be
executed when the function is traced. The loop will be “unrolled” into a
set of operations for each iteration, as we saw.

If you use tf.range(), the loop will be dynamic, meaning that it will be
included in the graph itself (but it will not run during tracing).

Let’s look at the graph that gets generated if we just replace range() with
tf.range() in the add_10() function:

>>> add_10.get_concrete_function(tf.constant(0)).graph.get_operations()
[<tf.Operation 'x' type=Placeholder>, [...],
 <tf.Operation 'while' type=StatelessWhile>, [...]]

As you can see, the graph now contains a While loop operation, as if we had
called the tf.while_loop() function.

Handling Variables and Other Resources in TF
Functions

In TensorFlow, variables and other stateful objects, such as queues or
datasets, are called resources. TF functions treat them with special care: any
operation that reads or updates a resource is considered stateful, and TF
functions ensure that stateful operations are executed in the order they appear
(as opposed to stateless operations, which may be run in parallel, so their
order of execution is not guaranteed). Moreover, when you pass a resource as
an argument to a TF function, it gets passed by reference, so the function may
modify it. For example:

counter = tf.Variable(0)

@tf.function
def increment(counter, c=1):
    return counter.assign_add(c)

increment(counter)  # counter is now equal to 1
increment(counter)  # counter is now equal to 2

If you peek at the function definition, the first argument is marked as a
resource:

>>> function_def = increment.get_concrete_function(counter).function_def
>>> function_def.signature.input_arg[0]
name: "counter"
type: DT_RESOURCE

It is also possible to use a tf.Variable defined outside of the function, without
explicitly passing it as an argument:

counter = tf.Variable(0)

@tf.function
def increment(c=1):
    return counter.assign_add(c)

The TF function will treat this as an implicit first argument, so it will actually
end up with the same signature (except for the name of the argument).
However, using global variables can quickly become messy, so you should
generally wrap variables (and other resources) inside classes. The good news
is @tf.function works fine with methods too:

class Counter:
    def __init__(self):
        self.counter = tf.Variable(0)

    @tf.function
    def increment(self, c=1):
        return self.counter.assign_add(c)

WARNING

Do not use =, +=, -=, or any other Python assignment operator with TF variables. Instead,
you must use the assign(), assign_add(), or assign_sub() methods. If you try to use a
Python assignment operator, you will get an exception when you call the method.

A good example of this object-oriented approach is, of course, Keras. Let’s
see how to use TF functions with Keras.

Using TF Functions with Keras (or Not)

By default, any custom function, layer, or model you use with Keras will
automatically be converted to a TF function; you do not need to do anything
at all! However, in some cases you may want to deactivate this automatic
conversion—for example, if your custom code cannot be turned into a TF
function, or if you just want to debug your code (which is much easier in
eager mode). To do this, you can simply pass dynamic=True when creating
the model or any of its layers:

model = MyModel(dynamic=True)

If your custom model or layer will always be dynamic, you can instead call
the base class’s constructor with dynamic=True:

class MyDense(tf.keras.layers.Layer):
    def __init__(self, units, **kwargs):
        super().__init__(dynamic=True, **kwargs)
        [...]

Alternatively, you can pass run_eagerly=True when calling the compile()
method:

model.compile(loss=my_mse, optimizer="nadam", metrics=[my_mae],
              run_eagerly=True)

Now you know how TF functions handle polymorphism (with multiple
concrete functions), how graphs are automatically generated using
AutoGraph and tracing, what graphs look like, how to explore their symbolic
operations and tensors, how to handle variables and resources, and how to
use TF functions with Keras.

1  You can safely ignore it—it is only here for technical reasons, to ensure that TF functions don’t

leak internal structures.

2  A popular binary format discussed in Chapter 13.

Index

Symbols

@ operator (matrix multiplication), The Normal Equation

β (momentum), Momentum

γ (gamma) value, Gaussian RBF Kernel

ε (tolerance), Batch Gradient Descent, SVM Classes and Computational
Complexity

ε greedy policy, Exploration Policies

ε neighborhood, DBSCAN

ε sensitive, SVM Regression

χ² test, Regularization Hyperparameters

ℓ₀ norm, Select a Performance Measure

ℓ₁ norm, Select a Performance Measure

ℓ₂ norm, Select a Performance Measure

ℓₖ norm, Select a Performance Measure

A

A/B experiments, Training and Deploying TensorFlow Models at Scale

accelerated k-means, Accelerated k-means and mini-batch k-means

accelerated linear algebra (XLA), TensorFlow Functions and Graphs

accuracy performance measure, What Is Machine Learning?, Measuring

Accuracy Using Cross-Validation

ACF (autocorrelation function), The ARMA Model Family

action advantage, reinforcement learning, Evaluating Actions: The Credit
Assignment Problem

action potentials (APs), Biological Neurons

actions, in reinforcement learning, Learning to Optimize Rewards, Evaluating
Actions: The Credit Assignment Problem-Evaluating Actions: The Credit
Assignment Problem

activation functions, The Perceptron, The Multilayer Perceptron and
Backpropagation-The Multilayer Perceptron and Backpropagation

for Conv2D layer, Implementing Convolutional Layers with Keras

custom models, Custom Activation Functions, Initializers, Regularizers,
and Constraints

ELU, ELU and SELU-GELU, Swish, and Mish

GELU, GELU, Swish, and Mish-GELU, Swish, and Mish

hyperbolic tangent (htan), The Multilayer Perceptron and
Backpropagation, Fighting the Unstable Gradients Problem

hyperparameters, Learning Rate, Batch Size, and Other
Hyperparameters

initialization parameters, Glorot and He Initialization

leakyReLU, Leaky ReLU-Leaky ReLU

Mish, GELU, Swish, and Mish

PReLU, Leaky ReLU

ReLU (see ReLU)

RReLU, Leaky ReLU

SELU, ELU and SELU, Dropout

sigmoid, Estimating Probabilities, The Multilayer Perceptron and
Backpropagation, The Vanishing/Exploding Gradients Problems, Sparse
Autoencoders

SiLU, GELU, Swish, and Mish

softmax, Softmax Regression, Classification MLPs, Creating the model
using the sequential API, An Encoder–Decoder Network for Neural
Machine Translation

softplus, Regression MLPs

Swish, GELU, Swish, and Mish

active learning, Using Clustering for Semi-Supervised Learning

actor-critic, Overview of Some Popular RL Algorithms

actual class, Confusion Matrices

actual versus estimated probabilities, The ROC Curve

AdaBoost, AdaBoost-AdaBoost

AdaGrad, AdaGrad

Adam optimization, Adam, ℓ1 and ℓ2 Regularization

AdaMax, AdaMax

AdamW, AdamW, ℓ1 and ℓ2 Regularization

adaptive boosting (AdaBoost), Boosting-AdaBoost

adaptive instance normalization (AdaIN), StyleGANs

adaptive learning rate algorithms, AdaGrad-AdamW

adaptive moment estimation (Adam), Adam

additive attention, Attention Mechanisms

advantage actor-critic (A2C), Overview of Some Popular RL Algorithms

adversarial learning, Semantic Segmentation, Autoencoders, GANs, and
Diffusion Models

affine transformations, StyleGANs

affinity function, Clustering Algorithms: k-means and DBSCAN

affinity propagation, Other Clustering Algorithms

agents, reinforcement learning, Reinforcement learning, Learning to
Optimize Rewards, Policy Gradients, Q-Learning

agglomerative clustering, Other Clustering Algorithms

Akaike information criterion (AIC), Selecting the Number of Clusters

AlexNet, AlexNet

algorithms, preparing data for, Prepare the Data for Machine Learning
Algorithms-Transformation Pipelines

alignment model, Attention Mechanisms

AllReduce algorithm, Data parallelism using the mirrored strategy

alpha dropout, Dropout

AlphaGo, Reinforcement learning, Reinforcement Learning, Overview of
Some Popular RL Algorithms

anchor priors, You Only Look Once

ANNs (see artificial neural networks)

anomaly detection, Examples of Applications, Unsupervised learning

clustering for, Clustering Algorithms: k-means and DBSCAN

GMM, Using Gaussian Mixtures for Anomaly Detection-Using
Gaussian Mixtures for Anomaly Detection

isolation forest, Other Algorithms for Anomaly and Novelty Detection

AP (average precision), You Only Look Once

APs (action potentials), Biological Neurons

area under the curve (AUC), The ROC Curve

argmax(), Softmax Regression

ARIMA model, The ARMA Model Family-The ARMA Model Family

ARMA model family, The ARMA Model Family-The ARMA Model Family

artificial neural networks (ANNs), Introduction to Artificial Neural Networks
with Keras-Learning Rate, Batch Size, and Other Hyperparameters

autoencoders (see autoencoders)

backpropagation, The Multilayer Perceptron and Backpropagation-The
Multilayer Perceptron and Backpropagation

biological neurons as background to, Biological Neurons-Biological
Neurons

evolution of, From Biological to Artificial Neurons-From Biological to
Artificial Neurons

hyperparameter fine-tuning, Fine-Tuning Neural Network
Hyperparameters-Learning Rate, Batch Size, and Other
Hyperparameters

implementing MLPs with Keras, Implementing MLPs with Keras-Using
TensorBoard for Visualization

logical computations with neurons, Logical Computations with

Neurons-Logical Computations with Neurons

perceptrons (see multilayer perceptrons)

reinforcement learning policies, Neural Network Policies

artificial neuron, Logical Computations with Neurons

association rule learning, Unsupervised learning

assumptions, checking in model building, Data Mismatch, Check the
Assumptions

asynchronous advantage actor-critic (A3C), Overview of Some Popular RL
Algorithms

asynchronous gang scheduling, Bandwidth saturation

asynchronous updates, with centralized parameters, Asynchronous updates

à-trous convolutional layer, Semantic Segmentation

attention mechanisms, Natural Language Processing with RNNs and
Attention, Attention Mechanisms-Multi-head attention, Vision Transformers

(see also transformer models)

attributes, Take a Quick Look at the Data Structure-Take a Quick Look at the
Data Structure

categorical, Handling Text and Categorical Attributes, Handling Text
and Categorical Attributes

combinations of, Experiment with Attribute Combinations-Experiment
with Attribute Combinations

preprocessed, Take a Quick Look at the Data Structure

target, Take a Quick Look at the Data Structure

unsupervised learning, Supervised learning

AUC (area under the curve), The ROC Curve

autocorrelated time series, Forecasting a Time Series

autocorrelation function (ACF), The ARMA Model Family

autodiff (automatic differentiation), Autodiff-Reverse-Mode Autodiff

for computing gradients, Computing Gradients Using Autodiff-
Computing Gradients Using Autodiff

finite difference approximation, Finite Difference Approximation

forward-mode, Forward-Mode Autodiff-Forward-Mode Autodiff

manual differentiation, Manual Differentiation

reverse-mode, Reverse-Mode Autodiff-Reverse-Mode Autodiff

autoencoders, Autoencoders, GANs, and Diffusion Models-Generating
Fashion MNIST Images

convolutional, Convolutional Autoencoders-Convolutional
Autoencoders

denoising, Denoising Autoencoders-Denoising Autoencoders

efficient data representations, Efficient Data Representations-Efficient
Data Representations

overcomplete, Convolutional Autoencoders

PCA with undercomplete linear autoencoder, Performing PCA with an
Undercomplete Linear Autoencoder-Performing PCA with an
Undercomplete Linear Autoencoder

sparse, Sparse Autoencoders-Sparse Autoencoders

stacked, Stacked Autoencoders-Training One Autoencoder at a Time

training one at a time, Training One Autoencoder at a Time-Training

One Autoencoder at a Time

undercomplete, Efficient Data Representations

variational, Variational Autoencoders-Variational Autoencoders

Autograph, AutoGraph and Tracing

AutoGraph, Using AutoGraph to Capture Control Flow

AutoML service, Fine-Tuning Neural Network Hyperparameters,
Hyperparameter Tuning on Vertex AI

autoregressive integrated moving average (ARIMA) model, The ARMA
Model Family-The ARMA Model Family

autoregressive model, The ARMA Model Family

autoregressive moving average (ARMA) model family, The ARMA Model
Family-The ARMA Model Family

auxiliary task, pretraining on, Pretraining on an Auxiliary Task

average absolute deviation, Select a Performance Measure

average pooling layer, Implementing Pooling Layers with Keras

average precision (AP), You Only Look Once

B

backbone, model, GoogLeNet

backpropagation, The Multilayer Perceptron and Backpropagation-The
Multilayer Perceptron and Backpropagation, The Vanishing/Exploding
Gradients Problems, Computing Gradients Using Autodiff, Generative
Adversarial Networks

backpropagation through time (BPTT), Training RNNs

bagging (bootstrap aggregating), Bagging and Pasting-Random Patches and

Random Subspaces

Bahdanau attention, Attention Mechanisms

balanced iterative reducing and clustering using hierarchies (BIRCH), Other
Clustering Algorithms

bandwidth saturation, Bandwidth saturation-Bandwidth saturation

BaseEstimator, Custom Transformers

batch gradient descent, Batch Gradient Descent-Batch Gradient Descent,
Ridge Regression

batch learning, Batch learning-Batch learning

batch normalization (BN), Batch Normalization-Implementing batch
normalization with Keras, Fighting the Unstable Gradients Problem

batch predictions, Deploying a new model version, Creating a Prediction
Service on Vertex AI, Running Batch Prediction Jobs on Vertex AI

Bayesian Gaussian mixtures, Bayesian Gaussian Mixture Models

Bayesian information criterion (BIC), Selecting the Number of Clusters

beam search, Beam Search-Beam Search

Bellman optimality equation, Markov Decision Processes

bias, Learning Curves

bias and fairness, NLP transformers, Hugging Face’s Transformers Library

bias term constant, Linear Regression, The Normal Equation

bias/variance trade-off, Learning Curves

BIC (Bayesian information criterion), Selecting the Number of Clusters

bidirectional recurrent layer, Bidirectional RNNs

binary classifiers, Training a Binary Classifier, Logistic Regression

binary logarithm, Computational Complexity

binary trees, Making Predictions, Other Clustering Algorithms

biological neural networks (BNNs), Biological Neurons-Biological Neurons

BIRCH (balanced iterative reducing and clustering using hierarchies), Other
Clustering Algorithms

black box models, Making Predictions

blending, in stacking, Stacking

BN (batch normalization), Batch Normalization, Fighting the Unstable
Gradients Problem

BNNs (biological neural networks), Biological Neurons-Biological Neurons

boosting, Boosting-Histogram-Based Gradient Boosting

bootstrap aggregating (bagging), Bagging and Pasting-Random Patches and
Random Subspaces

bootstrapping, Bagging and Pasting

bottleneck layers, GoogLeNet

bounding boxes, image identification, Classification and Localization-You
Only Look Once

BPTT (backpropagation through time), Training RNNs

bucketizing a feature, Feature Scaling and Transformation

byte pair encoding (BPE), Sentiment Analysis

C

California Housing Prices dataset, Working with Real Data-Check the

Assumptions

callbacks, Using Callbacks-Using Callbacks

CART (Classification and Regression Tree) algorithm, Making Predictions,
The CART Training Algorithm, Regression

catastrophic forgetting, Implementing Deep Q-Learning

categorical attributes, Handling Text and Categorical Attributes, Handling
Text and Categorical Attributes

categorical features, encoding, The Hashing Layer-Encoding Categorical
Features Using Embeddings

CategoryEncoding layer, The CategoryEncoding Layer

causal model, Forecasting Using a Sequence-to-Sequence Model,
Bidirectional RNNs

centralized parameters, Data parallelism with centralized parameters-
Asynchronous updates

centroid, cluster, Clustering Algorithms: k-means and DBSCAN, k-means,
The k-means algorithm-Centroid initialization methods

chain rule, The Multilayer Perceptron and Backpropagation

chain-of-thought prompting, An Avalanche of Transformer Models

ChainClassifier, Multilabel Classification

chaining transformations, Chaining Transformations-Chaining
Transformations

char-RNN model, Generating Shakespearean Text Using a Character RNN-
Stateful RNN

chatbot or personal assistant, Examples of Applications

check_estimator(), Custom Transformers

chi-squared (χ²) test, Regularization Hyperparameters

classification, Classification-Multioutput Classification

application examples of, Examples of Applications-Examples of
Applications

binary classifier, Training a Binary Classifier, Logistic Regression

CNNs, Classification and Localization-You Only Look Once

error analysis, Error Analysis-Error Analysis

hard margin, Soft Margin Classification, Under the Hood of Linear
SVM Classifiers

hard voting classifiers, Voting Classifiers

image (see images)

logistic regression (see logistic regression)

MLPs for, Classification MLPs-Classification MLPs

MNIST dataset, MNIST-MNIST

multiclass, Multiclass Classification-Multiclass Classification,
Classification MLPs-Classification MLPs

multilabel, Multilabel Classification-Multilabel Classification

multioutput, Multioutput Classification-Multioutput Classification

performance measures, Performance Measures-The ROC Curve

and regression, Supervised learning, Multioutput Classification

soft margin, Soft Margin Classification-Soft Margin Classification

softmax regression, Softmax Regression-Softmax Regression

SVMs (see support vector machines)

text, Sentiment Analysis-Reusing Pretrained Embeddings and Language
Models

voting classifiers, Voting Classifiers-Voting Classifiers

Classification and Regression Tree (CART) algorithm, Making Predictions,
The CART Training Algorithm, Regression

clone(), Early Stopping

closed-form equation/solution, Training Models, The Normal Equation,
Ridge Regression, Training and Cost Function

cloud platform deployment with Vertex AI, Creating a Prediction Service on
Vertex AI-Creating a Prediction Service on Vertex AI

clustering algorithms, Examples of Applications, Unsupervised learning,
Unsupervised Learning Techniques-Other Clustering Algorithms

affinity propagation, Other Clustering Algorithms

agglomerative clustering, Other Clustering Algorithms

applications for, Clustering Algorithms: k-means and DBSCAN-
Clustering Algorithms: k-means and DBSCAN

BIRCH, Other Clustering Algorithms

DBSCAN, DBSCAN-DBSCAN

GMM, Gaussian Mixtures-Other Algorithms for Anomaly and Novelty
Detection

image segmentation, Clustering Algorithms: k-means and DBSCAN,
Using Clustering for Image Segmentation-Using Clustering for Image
Segmentation

k-means (see k-means algorithm)

mean-shift, Other Clustering Algorithms

responsibilities of clusters for instances, Gaussian Mixtures

semi-supervised learning with, Using Clustering for Semi-Supervised
Learning-Using Clustering for Semi-Supervised Learning

spectral clustering, Other Clustering Algorithms

CNNs (see convolutional neural networks)

Colab, Running the Code Examples Using Google Colab-Running the Code
Examples Using Google Colab

color channels, Stacking Multiple Feature Maps

color segmentation, images, Using Clustering for Image Segmentation

column vectors, Linear Regression

ColumnTransformer, Transformation Pipelines

complex models with functional API, Building Complex Models Using the
Functional API-Building Complex Models Using the Functional API

compound scaling, Other Noteworthy Architectures

compressed TFRecord files, Compressed TFRecord Files

compression and decompression, PCA, PCA for Compression-PCA for
Compression

computation graphs, A Quick Tour of TensorFlow

computational complexity

DBSCAN, DBSCAN

decision trees, Computational Complexity

Gaussian mixture model, Gaussian Mixtures

histogram-based gradient boosting, Histogram-Based Gradient Boosting

k-means algorithm, The k-means algorithm

Normal equation, Computational Complexity

and SVM classes, SVM Classes and Computational Complexity

concatenative attention, Attention Mechanisms

concrete function, TF Functions and Concrete Functions-Exploring Function
Definitions and Graphs

conditional GAN, Deep Convolutional GANs

conditional probability, Beam Search

confidence interval, Evaluate Your System on the Test Set

confusion matrix (CM), Confusion Matrices-Confusion Matrices, Error
Analysis-Error Analysis

ConfusionMatrixDisplay, Error Analysis

connectionism, From Biological to Artificial Neurons

constrained optimization, Under the Hood of Linear SVM Classifiers

constraints, custom models, Custom Activation Functions, Initializers,
Regularizers, and Constraints

convergence rate, Batch Gradient Descent

convex function, Gradient Descent

convex quadratic optimization, Under the Hood of Linear SVM Classifiers

convolution kernels (kernels), Filters, CNN Architectures

convolutional neural networks (CNNs), Deep Computer Vision Using
Convolutional Neural Networks-Semantic Segmentation

architectures, CNN Architectures-Choosing the Right CNN Architecture

autoencoders, Convolutional Autoencoders-Convolutional Autoencoders

classification and localization, Classification and Localization-You Only
Look Once

convolutional layers, Convolutional Layers-Memory Requirements,
Semantic Segmentation-Semantic Segmentation, Using 1D
convolutional layers to process sequences, WaveNet-WaveNet, Masking

evolution of, Deep Computer Vision Using Convolutional Neural
Networks

GANs, Deep Convolutional GANs-Deep Convolutional GANs

object detection, Object Detection-You Only Look Once

object tracking, Object Tracking

pooling layers, Pooling Layers-Implementing Pooling Layers with Keras

pretrained models from Keras, Using Pretrained Models from Keras-
Using Pretrained Models from Keras

ResNet-34 CNN using Keras, Implementing a ResNet-34 CNN Using
Keras

semantic segmentation, Examples of Applications, Using Clustering for
Image Segmentation, Semantic Segmentation-Semantic Segmentation

splitting across devices, Model Parallelism

transfer learning pretrained models, Pretrained Models for Transfer
Learning-Pretrained Models for Transfer Learning

U-Net, Diffusion Models

and vision transformers, Vision Transformers

visual cortex architecture, The Architecture of the Visual Cortex

WaveNet, WaveNet-WaveNet

copy.deepcopy(), Early Stopping

core instance, DBSCAN

correlation coefficient, Look for Correlations-Look for Correlations

cost function, Model-based learning and a typical machine learning
workflow, Select a Performance Measure

in AdaBoost, AdaBoost

in autoencoders, Performing PCA with an Undercomplete Linear
Autoencoder

in bounding box prediction model, Classification and Localization

in CART training algorithm, The CART Training Algorithm,
Regression

in elastic net, Elastic Net Regression

in gradient descent, Training Models, Gradient Descent-Gradient
Descent, Stochastic Gradient Descent-Stochastic Gradient Descent, The
Vanishing/Exploding Gradients Problems

in lasso regression, Lasso Regression-Lasso Regression

in Nesterov accelerated gradient, Nesterov Accelerated Gradient

in linear regression, Linear Regression

in logistic regression, Training and Cost Function-Training and Cost
Function

in momentum optimization, Momentum

in ridge regression, Ridge Regression

in variational autoencoders, Variational Autoencoders

credit assignment problem, Evaluating Actions: The Credit Assignment

Problem-Evaluating Actions: The Credit Assignment Problem

cross entropy, Softmax Regression

cross-validation, Hyperparameter Tuning and Model Selection, Better
Evaluation Using Cross-Validation-Better Evaluation Using Cross-
Validation, Evaluate Your System on the Test Set, Measuring Accuracy
Using Cross-Validation-Measuring Accuracy Using Cross-Validation,
Learning Curves-Learning Curves

cross_val_predict(), Confusion Matrices, The Precision/Recall Trade-off, The
ROC Curve, Error Analysis, Stacking

cross_val_score(), Better Evaluation Using Cross-Validation, Measuring
Accuracy Using Cross-Validation

CUDA library, Getting Your Own GPU

curiosity-based exploration, Overview of Some Popular RL Algorithms

curriculum learning, Overview of Some Popular RL Algorithms

custom models and training algorithms, Customizing Models and Training
Algorithms-Custom Training Loops

activation functions, Custom Activation Functions, Initializers,
Regularizers, and Constraints

autodiff for computing gradients, Computing Gradients Using Autodiff-
Computing Gradients Using Autodiff

constraints, Custom Activation Functions, Initializers, Regularizers, and
Constraints

initializers, Custom Activation Functions, Initializers, Regularizers, and
Constraints

layers, Custom Layers-Custom Layers

loss functions, Custom Loss Functions, Losses and Metrics Based on

Model Internals-Losses and Metrics Based on Model Internals

metrics, Custom Metrics-Custom Metrics, Losses and Metrics Based on
Model Internals-Losses and Metrics Based on Model Internals

models, Custom Models-Custom Models

regularizers, Custom Activation Functions, Initializers, Regularizers,
and Constraints

saving and loading models, Saving and Loading Models That Contain
Custom Components-Saving and Loading Models That Contain Custom
Components

training loops, Custom Training Loops-Custom Training Loops

custom transformers, Custom Transformers-Custom Transformers

customer segmentation, Clustering Algorithms: k-means and DBSCAN

D

DALL-E, Vision Transformers

data

downloading, Saving Your Code Changes and Your Data-Saving Your
Code Changes and Your Data

efficient data representations, Efficient Data Representations-Efficient
Data Representations

enqueuing and dequeuing, Queues

finding correlations in, Look for Correlations-Look for Correlations

making assumptions about, Data Mismatch

overfitting (see overfitting of data)

preparing for ML algorithms, Prepare the Data for Machine Learning

Algorithms-Transformation Pipelines

preparing for ML models, Preparing the Data for Machine Learning
Models-Preparing the Data for Machine Learning Models

preprocessing (see loading and preprocessing data)

shuffling of, Shuffling the Data

test data (see test set)

time series (see time series data)

training data (see training set)

underfitting of, Train and Evaluate on the Training Set, Learning
Curves-Learning Curves, Polynomial Kernel

unreasonable effectiveness, Insufficient Quantity of Training Data

visualizing (see visualization)

working with real data, Working with Real Data-Working with Real
Data

data analysis, clustering for, Clustering Algorithms: k-means and DBSCAN

data augmentation, Exercises, AlexNet, Pretrained Models for Transfer
Learning

data cleaning, Clean the Data-Clean the Data

data drift, Batch learning

data mining, Why Use Machine Learning?

data mismatch, Data Mismatch

data parallelism, Data Parallelism-Bandwidth saturation

data pipeline, Frame the Problem

data snooping bias, Create a Test Set

data structure, Take a Quick Look at the Data Structure-Take a Quick Look at
the Data Structure, Special Data Structures-Queues

data-efficient image transformers (DeiT), Vision Transformers

DataFrame, Clean the Data, Handling Text and Categorical Attributes,
Feature Scaling and Transformation

Dataquest, Other Resources

Datasets library, The TensorFlow Datasets Project

DBSCAN, DBSCAN-DBSCAN

DCGANs (deep convolutional GANS), Deep Convolutional GANs-Deep
Convolutional GANs

DDPM (denoising diffusion probabilistic model), Autoencoders, GANs, and
Diffusion Models, Diffusion Models-Diffusion Models

DDQN (dueling DQN), Dueling DQN

decision boundaries, Decision Boundaries-Decision Boundaries, Softmax
Regression, Making Predictions, Sensitivity to Axis Orientation, k-means

decision function, The Precision/Recall Trade-off, Under the Hood of Linear
SVM Classifiers-Under the Hood of Linear SVM Classifiers

decision stumps, AdaBoost

decision threshold, The Precision/Recall Trade-off-The Precision/Recall
Trade-off

decision trees, Decision Trees-Decision Trees Have a High Variance,
Ensemble Learning and Random Forests

(see also ensemble learning)

bagging and pasting, Bagging and Pasting in Scikit-Learn

CART training algorithm, The CART Training Algorithm

class probability estimates, Estimating Class Probabilities

computational complexity, Computational Complexity

and decision boundaries, Making Predictions

GINI impurity or entropy measures, Gini Impurity or Entropy?

high variance with, Decision Trees Have a High Variance

predictions, Making Predictions-The CART Training Algorithm

regression tasks, Regression-Regression

regularization hyperparameters, Regularization Hyperparameters-
Regularization Hyperparameters

sensitivity to axis orientation, Sensitivity to Axis Orientation

training and visualizing, Training and Visualizing a Decision Tree-
Training and Visualizing a Decision Tree

in training the model, Train and Evaluate on the Training Set-Better
Evaluation Using Cross-Validation

DecisionTreeClassifier, Training and Visualizing a Decision Tree, Gini
Impurity or Entropy?, Regularization Hyperparameters, Sensitivity to Axis
Orientation, Random Forests

DecisionTreeRegressor, Train and Evaluate on the Training Set, Decision
Trees, Regression, Gradient Boosting

decision_function(), The Precision/Recall Trade-off

deconvolution layer, Semantic Segmentation

deep autoencoders (see stacked autoencoders)

deep convolutional GANS (DCGANs), Deep Convolutional GANs-Deep

Convolutional GANs

deep Gaussian process, Monte Carlo (MC) Dropout

deep learning, The Machine Learning Tsunami

(see also deep neural networks; reinforcement learning)

deep neural networks (DNNs), Training Deep Neural Networks-Summary
and Practical Guidelines

CNNs (see convolutional neural networks)

default configuration, Summary and Practical Guidelines

faster optimizers for, Faster Optimizers-AdamW

learning rate scheduling, Learning Rate Scheduling-Learning Rate
Scheduling

MLPs (see multilayer perceptrons)

regularization, Avoiding Overfitting Through Regularization-Max-Norm
Regularization

reusing pretrained layers, Reusing Pretrained Layers-Pretraining on an
Auxiliary Task

RNNs (see recurrent neural networks)

and transfer learning, Self-supervised learning

unstable gradients, The Vanishing/Exploding Gradients Problems

vanishing and exploding gradients, The Vanishing/Exploding Gradients
Problems-Gradient Clipping

deep neuroevolution, Fine-Tuning Neural Network Hyperparameters

deep Q-learning, Approximate Q-Learning and Deep Q-Learning-Dueling
DQN

deep Q-networks (DQNs) (see Q-learning algorithm)

deepcopy(), Early Stopping

DeepMind, Reinforcement learning

degrees of freedom, Overfitting the Training Data, Learning Curves

DeiT (data-efficient image transformers), Vision Transformers

denoising autoencoders, Denoising Autoencoders-Denoising Autoencoders

denoising diffusion probabilistic model (DDPM), Autoencoders, GANs, and
Diffusion Models, Diffusion Models-Diffusion Models

Dense layer, The Perceptron, Creating the model using the sequential API,
Creating the model using the sequential API, Building Complex Models
Using the Functional API

dense matrix, Feature Scaling and Transformation, Transformation Pipelines

density estimation, Unsupervised Learning Techniques, DBSCAN-
DBSCAN, Gaussian Mixtures

density threshold, Using Gaussian Mixtures for Anomaly Detection

depth concatenation layer, GoogLeNet

depthwise separable convolution layer, Xception

deque, Implementing Deep Q-Learning

describe(), Take a Quick Look at the Data Structure

development set (dev set), Hyperparameter Tuning and Model Selection

differencing, time series forecasting, Forecasting a Time Series, Forecasting a
Time Series, The ARMA Model Family

diffusion models, Autoencoders, GANs, and Diffusion Models, Diffusion
Models-Diffusion Models

dilated filter, Semantic Segmentation

dilation rate, Semantic Segmentation

dimensionality reduction, Unsupervised learning, Dimensionality Reduction-
Other Dimensionality Reduction Techniques

approaches to, Main Approaches for Dimensionality Reduction-
Manifold Learning

autoencoders, Autoencoders, GANs, and Diffusion Models, Efficient
Data Representations-Performing PCA with an Undercomplete Linear
Autoencoder

choosing the right number of dimensions, Choosing the Right Number
of Dimensions

clustering, Clustering Algorithms: k-means and DBSCAN

curse of dimensionality, The Curse of Dimensionality-The Curse of
Dimensionality

for data visualization, Dimensionality Reduction

information loss from, Dimensionality Reduction

Isomap, Other Dimensionality Reduction Techniques

linear discriminant analysis, Other Dimensionality Reduction
Techniques

LLE, LLE-LLE

multidimensional scaling, Other Dimensionality Reduction Techniques

PCA (see principal component analysis)

random projection algorithm, Random Projection-Random Projection

t-distributed stochastic neighbor embedding, Other Dimensionality
Reduction Techniques, Visualizing the Fashion MNIST Dataset

discount factor γ in reward system, Evaluating Actions: The Credit
Assignment Problem

discounted rewards, Evaluating Actions: The Credit Assignment Problem,
Policy Gradients

Discretization layer, The Discretization Layer

discriminator, GAN, Autoencoders, GANs, and Diffusion Models,
Generative Adversarial Networks-The Difficulties of Training GANs

DistilBERT model, An Avalanche of Transformer Models, Hugging Face’s
Transformers Library-Hugging Face’s Transformers Library

distillation, An Avalanche of Transformer Models

distribution strategies API, Training at Scale Using the Distribution Strategies
API

Docker container, Installing and starting TensorFlow Serving

dot product, Attention Mechanisms

Dota 2, Overview of Some Popular RL Algorithms

Double DQN, Double DQN

downloading data, Saving Your Code Changes and Your Data-Saving Your
Code Changes and Your Data

DQNs (deep Q-networks) (see Q-learning algorithm)

drop(), Prepare the Data for Machine Learning Algorithms

dropna(), Clean the Data

Dropout, Denoising Autoencoders

dropout rate, Dropout

dropout regularization, Dropout-Dropout

dual numbers, Forward-Mode Autodiff

dual problem, The Dual Problem-Kernelized SVMs

dueling DQN (DDQN), Dueling DQN

dummy attributes, Handling Text and Categorical Attributes

dying ReLU problem, Better Activation Functions

dynamic models with subclassing API, Using the Subclassing API to Build
Dynamic Models-Using the Subclassing API to Build Dynamic Models

dynamic programming, Markov Decision Processes

E

eager execution (eager mode), AutoGraph and Tracing

early stopping regularization, Early Stopping-Early Stopping, Gradient
Boosting, Forecasting Using a Linear Model

edge computing, Deploying a Model to a Mobile or Embedded Device

efficient data representations, autoencoders, Efficient Data Representations-
Efficient Data Representations

elastic net, Elastic Net Regression

EllipticEnvelope, Other Algorithms for Anomaly and Novelty Detection

ELMo (Embeddings from Language Models), Reusing Pretrained
Embeddings and Language Models

ELU (exponential linear unit), ELU and SELU-GELU, Swish, and Mish

EM (expectation-maximization), Gaussian Mixtures

embedded device, deploying model to, Deploying a Model to a Mobile or
Embedded Device-Deploying a Model to a Mobile or Embedded Device

embedded Reber grammars, Exercises

embedding matrix, Encoding Categorical Features Using Embeddings, An
Encoder–Decoder Network for Neural Machine Translation

embedding size, An Encoder–Decoder Network for Neural Machine
Translation, Positional encodings

embeddings, Handling Text and Categorical Attributes

encoding categorical features using, Encoding Categorical Features
Using Embeddings-Encoding Categorical Features Using Embeddings

reusing pretrained, Reusing Pretrained Embeddings and Language
Models-Reusing Pretrained Embeddings and Language Models

sentiment analysis, Sentiment Analysis

Embeddings from Language Models (ELMo), Reusing Pretrained
Embeddings and Language Models

encoder, Efficient Data Representations

(see also autoencoders)

encoder–decoder models, Input and Output Sequences, Natural Language
Processing with RNNs and Attention, An Encoder–Decoder Network for
Neural Machine Translation-Beam Search

(see also attention mechanisms)

end-to-end ML project exercise, End-to-End Machine Learning Project-Try It
Out!

building the model, Look at the Big Picture-Check the Assumptions

discovering and visualizing data, Explore and Visualize the Data to Gain
Insights-Experiment with Attribute Combinations

fine-tuning your model, Fine-Tune Your Model-Evaluate Your System

on the Test Set

getting the data, Get the Data-Create a Test Set

preparing data for ML algorithms, Prepare the Data for Machine
Learning Algorithms-Transformation Pipelines

real data, advantages of working with, Working with Real Data-
Working with Real Data

selecting and training a model, Train and Evaluate on the Training Set-
Train and Evaluate on the Training Set

endpoint, deploying model on GCP, Creating a Prediction Service on Vertex
AI

ensemble learning, Ensemble Learning and Random Forests-Stacking

bagging and pasting, Bagging and Pasting-Random Patches and Random
Subspaces

boosting, Boosting-Histogram-Based Gradient Boosting

cross-validation, Better Evaluation Using Cross-Validation

fine-tuning the system, Ensemble Methods

random forests (see random forests)

stacking, Stacking-Stacking

voting classifiers, Voting Classifiers-Voting Classifiers

entailment, An Avalanche of Transformer Models

entropy impurity measure, Gini Impurity or Entropy?

environments, reinforcement learning, Learning to Optimize Rewards,
Introduction to OpenAI Gym-Introduction to OpenAI Gym

epochs, Batch Gradient Descent

equalized learning rate, GAN, Progressive Growing of GANs

equivariance, Pooling Layers

error analysis, classification, Error Analysis-Error Analysis

estimated versus actual probabilities, The ROC Curve

estimators, Clean the Data, Transformation Pipelines, Voting Classifiers

Euclidean norm, Select a Performance Measure

event files, TensorBoard, Using TensorBoard for Visualization

Example protobuf, TensorFlow Protobufs

exclusive or (XOR) problem, The Perceptron

exemplars, affinity propagation, Other Clustering Algorithms

expectation-maximization (EM), Gaussian Mixtures

experience replay, The Difficulties of Training GANs

explainability, attention mechanisms, Vision Transformers

explained variance ratio, Explained Variance Ratio

explained variance, plotting, Choosing the Right Number of Dimensions-
Choosing the Right Number of Dimensions

exploding gradients, The Vanishing/Exploding Gradients Problems

(see also vanishing and exploding gradients)

exploration policies, Temporal Difference Learning, Exploration Policies

exploration/exploitation dilemma, reinforcement learning, Neural Network
Policies

exponential linear unit (ELU), ELU and SELU-GELU, Swish, and Mish

exponential scheduling, Learning Rate Scheduling, Learning Rate Scheduling

export_graphviz(), Training and Visualizing a Decision Tree

extra-trees, random forest, Extra-Trees

extremely randomized trees ensemble (extra-trees), Extra-Trees

F

face-recognition classifier, Multilabel Classification

false negatives, confusion matrix, Confusion Matrices

false positive rate (FPR) or fall-out, The ROC Curve

false positives, confusion matrix, Confusion Matrices

fan-in/fan-out, Glorot and He Initialization

fast-MCD, Other Algorithms for Anomaly and Novelty Detection

FCNs (fully convolutional networks), Fully Convolutional Networks-Fully
Convolutional Networks, Semantic Segmentation

feature engineering, Irrelevant Features, Clustering Algorithms: k-means and
DBSCAN

feature extraction, Unsupervised learning, Irrelevant Features

feature maps, Stacking Multiple Feature Maps-Stacking Multiple Feature
Maps, Implementing Convolutional Layers with Keras, ResNet, SENet

feature scaling, Feature Scaling and Transformation-Feature Scaling and
Transformation, Gradient Descent, Linear SVM Classification

feature selection, Irrelevant Features, Analyzing the Best Models and Their
Errors, Lasso Regression, Feature Importance

feature vectors, Select a Performance Measure, Linear Regression, Under the
Hood of Linear SVM Classifiers

features, Supervised learning

federated learning, Running a Model in a Web Page

feedforward neural network (FNN), The Multilayer Perceptron and
Backpropagation, Recurrent Neurons and Layers

fetch_openml(), MNIST

fillna(), Clean the Data

filters, convolutional layers, Filters, Implementing Convolutional Layers with
Keras, CNN Architectures, Xception

first moment (mean of gradient), Adam

first-order partial derivatives (Jacobians), AdamW

fit()

and custom transformers, Custom Transformers, Transformation
Pipelines

data cleaning, Clean the Data

versus partial_fit(), Stochastic Gradient Descent

using only with training set, Feature Scaling and Transformation

fitness function, Model-based learning and a typical machine learning
workflow

fit_transform(), Clean the Data, Feature Scaling and Transformation, Custom
Transformers, Transformation Pipelines

fixed Q-value targets, Fixed Q-value Targets

flat dataset, Preparing the Data for Machine Learning Models

flowers dataset, Pretrained Models for Transfer Learning-Pretrained Models
for Transfer Learning

FNN (feedforward neural network), The Multilayer Perceptron and

Backpropagation, Recurrent Neurons and Layers

folds, Better Evaluation Using Cross-Validation, MNIST, Measuring
Accuracy Using Cross-Validation, Measuring Accuracy Using Cross-
Validation

forecasting time series (see time series data)

forget gate, LSTM, LSTM cells

forward pass, in backpropagation, The Multilayer Perceptron and
Backpropagation

forward process, diffusion model, Diffusion Models-Diffusion Models

FPR (false positive rate) or fall-out, The ROC Curve

from_predictions(), Error Analysis

full gradient descent, Batch Gradient Descent

fully connected layer, The Perceptron, The Architecture of the Visual Cortex,
Memory Requirements

fully convolutional networks (FCNs), Fully Convolutional Networks-Fully
Convolutional Networks, Semantic Segmentation

function definition (FuncDef), TF Functions and Concrete Functions

function graph (FuncGraph), TF Functions and Concrete Functions

functional API, complex models with, Building Complex Models Using the
Functional API-Building Complex Models Using the Functional API

FunctionTransformer, Custom Transformers

F₁ score, Precision and Recall

G

game play (see reinforcement learning)

gamma (γ) value, Gaussian RBF Kernel

GANs (see generative adversarial networks)

gate controllers, LSTM, LSTM cells

gated activation units, WaveNet

gated recurrent unit (GRU) cell, GRU cells-GRU cells, Masking

Gaussian distribution, Feature Scaling and Transformation, Training and Cost
Function, Variational Autoencoders-Variational Autoencoders

Gaussian mixture model (GMM), Gaussian Mixtures-Other Algorithms for
Anomaly and Novelty Detection

anomaly detection, Using Gaussian Mixtures for Anomaly Detection-
Using Gaussian Mixtures for Anomaly Detection

Bayesian Gaussian mixtures, Bayesian Gaussian Mixture Models

fast-MCD, Other Algorithms for Anomaly and Novelty Detection

inverse_transform() with PCA, Other Algorithms for Anomaly and
Novelty Detection

isolation forest, Other Algorithms for Anomaly and Novelty Detection

and k-means limitations, Limits of k-means

local outlier factor, Other Algorithms for Anomaly and Novelty
Detection

one-class SVM, Other Algorithms for Anomaly and Novelty Detection

selecting number of clusters, Selecting the Number of Clusters-Selecting
the Number of Clusters

Gaussian process, Fine-Tuning Neural Network Hyperparameters

Gaussian RBF kernel, Custom Transformers, Gaussian RBF Kernel-SVM

Classes and Computational Complexity, Kernelized SVMs

GBRT (gradient boosted regression trees), Gradient Boosting, Gradient
Boosting-Histogram-Based Gradient Boosting

GCP (Google Cloud Platform), Creating a Prediction Service on Vertex AI-
Creating a Prediction Service on Vertex AI

GCS (Google Cloud Storage), Creating a Prediction Service on Vertex AI

GD (see gradient descent)

GELU, GELU, Swish, and Mish-GELU, Swish, and Mish

generalization error, Testing and Validating-Hyperparameter Tuning and
Model Selection

generative adversarial networks (GANs), Generative Adversarial Networks-
StyleGANs

deep convolutional, Deep Convolutional GANs-Deep Convolutional
GANs

progressive growing of, Progressive Growing of GANs-Progressive
Growing of GANs

StyleGANs, StyleGANs-StyleGANs

training difficulties, The Difficulties of Training GANs-The Difficulties
of Training GANs

generative autoencoders, Variational Autoencoders

generative models, Autoencoders, GANs, and Diffusion Models

(see also Gaussian mixture model)

generator, GAN, Autoencoders, GANs, and Diffusion Models, Generative
Adversarial Networks-The Difficulties of Training GANs

genetic algorithm, Policy Search

geodesic distance, Other Dimensionality Reduction Techniques

geographic data, visualizing, Visualizing Geographical Data-Visualizing
Geographical Data

get_dummies(), Handling Text and Categorical Attributes

get_feature_names_out(), Custom Transformers

get_params(), Custom Transformers

GINI impurity, Making Predictions, Gini Impurity or Entropy?

global average pooling layer, Implementing Pooling Layers with Keras

global versus local minimum, gradient descent, Gradient Descent

Glorot initialization, Glorot and He Initialization-Glorot and He Initialization

GMM (see Gaussian mixture model)

Google Cloud Platform (GCP), Creating a Prediction Service on Vertex AI-
Creating a Prediction Service on Vertex AI

Google Cloud Storage (GCS), Creating a Prediction Service on Vertex AI

Google Colab, Running the Code Examples Using Google Colab-Running
the Code Examples Using Google Colab

Google Vertex AI (see Vertex AI)

GoogLeNet, GoogLeNet-GoogLeNet, Xception

GPU implementation, Mini-Batch Gradient Descent, Using GPUs to Speed
Up Computations-Parallel Execution Across Multiple Devices, Training at
Scale Using the Distribution Strategies API

getting your own GPU, Getting Your Own GPU-Getting Your Own
GPU

managing RAM, Managing the GPU RAM-Managing the GPU RAM

operations handling, Parallel Execution Across Multiple Devices

parallel execution across multiple devices, Parallel Execution Across
Multiple Devices-Parallel Execution Across Multiple Devices

placing operations and variables on devices, Placing Operations and
Variables on Devices-Placing Operations and Variables on Devices

gradient ascent, Policy Search

gradient boosted regression trees (GBRT), Gradient Boosting, Gradient
Boosting-Histogram-Based Gradient Boosting

gradient boosting, Gradient Boosting-Gradient Boosting

gradient clipping, Gradient Clipping

gradient descent (GD), Training Models, Gradient Descent-Mini-Batch
Gradient Descent

algorithm comparisons, Mini-Batch Gradient Descent

batch gradient descent, Batch Gradient Descent-Batch Gradient Descent,
Ridge Regression

local versus global minimum, Gradient Descent

mini-batch gradient descent, Mini-Batch Gradient Descent-Mini-Batch
Gradient Descent

minimizing hinge loss, Under the Hood of Linear SVM Classifiers

versus momentum optimization, Momentum

with optimizers, Faster Optimizers-AdamW

shuffling data, Shuffling the Data

stochastic gradient descent, Stochastic Gradient Descent-Stochastic
Gradient Descent

gradient tree boosting, Gradient Boosting

gradients

autodiff for computing, Computing Gradients Using Autodiff-
Computing Gradients Using Autodiff

bandwidth saturation issue, Bandwidth saturation

PG algorithm, Policy Search, Policy Gradients-Policy Gradients

stale, Asynchronous updates

unstable (see vanishing and exploding gradients)

graph mode, AutoGraph and Tracing

graphical processing units (see GPU implementation)

graphs and functions, TensorFlow, A Quick Tour of TensorFlow,
TensorFlow Functions and Graphs-TF Function Rules, TensorFlow Graphs-
Using TF Functions with Keras (or Not)

Graphviz, Training and Visualizing a Decision Tree

greedy algorithm, CART as, The CART Training Algorithm

greedy decoding, Generating Fake Shakespearean Text

greedy layer-wise pretraining, Unsupervised Pretraining, Training One
Autoencoder at a Time, Progressive Growing of GANs

grid search, Grid Search-Grid Search

GridSearchCV, Grid Search-Grid Search

gRPC API, querying through, Querying TF Serving through the gRPC API

GRU (gated recurrent unit) cell, GRU cells-GRU cells, Masking

H

hard clustering, k-means

hard margin classification, Soft Margin Classification, Under the Hood of
Linear SVM Classifiers

hard voting classifiers, Voting Classifiers

harmonic mean, Precision and Recall

hashing collision, The StringLookup Layer

Hashing layer, The Hashing Layer

hashing trick, The StringLookup Layer

HDBSCAN (hierarchical DBSCAN), DBSCAN

He initialization, Glorot and He Initialization-Glorot and He Initialization

Heaviside step function, The Perceptron

heavy tail, feature distribution, Feature Scaling and Transformation

Hebb's rule, The Perceptron

Hebbian learning, The Perceptron

Hessians, AdamW

hidden layers

neurons per layer, Number of Neurons per Hidden Layer

number of, Number of Hidden Layers

stacked autoencoders, Stacked Autoencoders-Training One Autoencoder
at a Time

hierarchical clustering, Unsupervised learning

hierarchical DBSCAN (HDBSCAN), DBSCAN

high variance, with decision trees, Decision Trees Have a High Variance

hinge loss function, Under the Hood of Linear SVM Classifiers

histogram-based gradient boosting (HGB), Histogram-Based Gradient
Boosting-Histogram-Based Gradient Boosting

histograms, Take a Quick Look at the Data Structure

hold-out sets, Testing and Validating

holdout validation, Hyperparameter Tuning and Model Selection

housing dataset, Working with Real Data-Check the Assumptions

Huber loss, Regression MLPs, Custom Loss Functions, Custom Metrics,
Forecasting Using a Linear Model

Hugging Face, Hugging Face’s Transformers Library-Hugging Face’s
Transformers Library

Hungarian algorithm, Object Tracking

Hyperband tuner, Fine-Tuning Neural Network Hyperparameters

hyperbolic tangent (htan), The Multilayer Perceptron and Backpropagation,
Fighting the Unstable Gradients Problem

hyperparameters, Overfitting the Training Data, Fine-Tuning Neural Network
Hyperparameters-Learning Rate, Batch Size, and Other Hyperparameters

activation function, Learning Rate, Batch Size, and Other
Hyperparameters

batch size, Learning Rate, Batch Size, and Other Hyperparameters

CART algorithm, The CART Training Algorithm

convolutional layers, Implementing Convolutional Layers with Keras

in custom transformations, Custom Transformers

decision tree, Gradient Boosting

dimensionality reduction, Choosing the Right Number of Dimensions

gamma (γ) value, Gaussian RBF Kernel

GAN challenges, The Difficulties of Training GANs

Keras Tuner, Hyperparameter Tuning on Vertex AI

learning rate, Gradient Descent, Learning Rate, Batch Size, and Other
Hyperparameters

momentum β, Momentum

Monte Carlo samples, Monte Carlo (MC) Dropout

neurons per hidden layer, Number of Neurons per Hidden Layer

and normalization, Feature Scaling and Transformation

number of hidden layers, Number of Hidden Layers

number of iterations, Learning Rate, Batch Size, and Other
Hyperparameters

optimizer, Learning Rate, Batch Size, and Other Hyperparameters

PG algorithms, Policy Gradients

preprocessor and model interaction, Grid Search

randomized search, Fine-Tuning Neural Network Hyperparameters-
Fine-Tuning Neural Network Hyperparameters

saving along with model, Custom Activation Functions, Initializers,
Regularizers, and Constraints

SGDClassifier, SVM Classes and Computational Complexity

subsample, Gradient Boosting

SVM classifiers with polynomial kernel, Polynomial Kernel

tolerance (ε), SVM Classes and Computational Complexity

tuning of, Hyperparameter Tuning and Model Selection-Hyperparameter
Tuning and Model Selection, Grid Search-Grid Search, Evaluate Your
System on the Test Set, Training and evaluating the model,
Hyperparameter Tuning on Vertex AI-Hyperparameter Tuning on
Vertex AI

hypothesis, Select a Performance Measure

hypothesis boosting (see boosting)

hypothesis function, Linear Regression

I

identity matrix, Ridge Regression

IID (see independent and identically distributed)

image generation, Semantic Segmentation, StyleGANs, Diffusion Models

image segmentation, Clustering Algorithms: k-means and DBSCAN, Using
Clustering for Image Segmentation-Using Clustering for Image Segmentation

images, classifying and generating, Examples of Applications

autoencoders (see autoencoders)

CNNs (see convolutional neural networks)

diffusion models, Diffusion Models-Diffusion Models

generating with GANs, Generative Adversarial Networks-StyleGANs

implementing MLPs, Building an Image Classifier Using the Sequential
API-Using the model to make predictions

labels, Classification and Localization

loading and preprocessing data, Image Preprocessing Layers

representative images, Using Clustering for Semi-Supervised Learning

semantic segmentation, Using Clustering for Image Segmentation

tuning hyperparameters, Fine-Tuning Neural Network Hyperparameters

importance sampling (IS), Prioritized Experience Replay

impurity measures, Making Predictions, Gini Impurity or Entropy?

imputation, Clean the Data

incremental learning, Online learning

incremental PCA (IPCA), Incremental PCA-Incremental PCA

independent and identically distributed (IID), training instances as, Stochastic
Gradient Descent

inductive bias, Vision Transformers

inertia, model, Centroid initialization methods, Accelerated k-means and
mini-batch k-means

inference, Model-based learning and a typical machine learning workflow

info(), Take a Quick Look at the Data Structure

information theory, Softmax Regression, Gini Impurity or Entropy?

inliers, Unsupervised Learning Techniques

input and output sequences, RNNs, Input and Output Sequences-Input and
Output Sequences

input gate, LSTM, LSTM cells

input layer, neural network, The Perceptron, Creating the model using the
sequential API, Building Complex Models Using the Functional API

(see also hidden layers)

input signature, TF Functions and Concrete Functions

instance segmentation, Using Clustering for Image Segmentation, Semantic
Segmentation

instance-based learning, Instance-based learning, Model-based learning and a
typical machine learning workflow

inter-op thread pool, Parallel Execution Across Multiple Devices

intercept term constant, Linear Regression

interleaving lines from multiple files, Interleaving Lines from Multiple Files-
Interleaving Lines from Multiple Files

interpretable ML, Making Predictions

invariance, max pooling layer, Pooling Layers

inverse_transform(), Feature Scaling and Transformation, Custom
Transformers, PCA for Compression, Other Algorithms for Anomaly and
Novelty Detection

IPCA (incremental PCA), Incremental PCA-Incremental PCA

iris dataset, Decision Boundaries

irreducible error, Learning Curves

IS (importance sampling), Prioritized Experience Replay

isolation forest, Other Algorithms for Anomaly and Novelty Detection

Isomap, Other Dimensionality Reduction Techniques

isotropic noise, Diffusion Models

IterativeImputer, Clean the Data

J

Jacobians, AdamW

joblib library, Launch, Monitor, and Maintain Your System-Launch, Monitor,
and Maintain Your System

JSON Lines, Running Batch Prediction Jobs on Vertex AI, Running Batch
Prediction Jobs on Vertex AI

Jupyter, Running the Code Examples Using Google Colab

K

k-fold cross-validation, Better Evaluation Using Cross-Validation, Measuring
Accuracy Using Cross-Validation, Measuring Accuracy Using Cross-
Validation

k-means algorithm, Custom Transformers, k-means-Limits of k-means

accelerated k-means, Accelerated k-means and mini-batch k-means

centroid initialization methods, Centroid initialization methods-Centroid
initialization methods

finding optimal number of clusters, Finding the optimal number of
clusters-Finding the optimal number of clusters

limitations of, Limits of k-means

mini-batch k-means, Accelerated k-means and mini-batch k-means

workings of, The k-means algorithm-The k-means algorithm

k-means++, Centroid initialization methods

k-nearest neighbors regression, Model-based learning and a typical machine
learning workflow

Kaiming initialization, Glorot and He Initialization

Kalman Filters, Object Tracking

Keras API, Objective and Approach, A Quick Tour of TensorFlow

(see also artificial neural networks)

and accessing TensorFlow API directly, Image Preprocessing Layers

activation function support, Leaky ReLU, ELU and SELU, GELU,
Swish, and Mish

convolutional layer implementation, Implementing Convolutional
Layers with Keras-Implementing Convolutional Layers with Keras

custom functions in, TensorFlow Functions and Graphs

gradient clipping, Gradient Clipping

image preprocessing layers, Image Preprocessing Layers

implementing MLPs with, Implementing MLPs with Keras-Using
TensorBoard for Visualization

initialization handling, Glorot and He Initialization

initializers, Creating the model using the sequential API

layer preprocessing, Keras Preprocessing Layers-Using Pretrained
Language Model Components

learning rate scheduling, Learning Rate Scheduling-Learning Rate
Scheduling

loading a dataset, Building an Image Classifier Using the Sequential API

PG algorithm, Policy Gradients-Policy Gradients

pool layer implementation, Implementing Pooling Layers with Keras-
Implementing Pooling Layers with Keras

pretrained CNN models, Using Pretrained Models from Keras-Using
Pretrained Models from Keras

ResNet-34 CNN with, Implementing a ResNet-34 CNN Using Keras

saving models, Exporting SavedModels, Deploying a Model to a Mobile
or Embedded Device

stacked encoder implementation, Implementing a Stacked Autoencoder
Using Keras

tf.data API dataset, Using the Dataset with Keras-Using the Dataset with
Keras

tf.keras library, Using Keras to load the dataset

tf.keras.activations.get(), Custom Layers

tf.keras.activations.relu(), Creating the model using the sequential API

tf.keras.applications module, Using Pretrained Models from Keras

tf.keras.applications.xception.preprocess_input(), Pretrained Models for
Transfer Learning

tf.keras.backend module, Tensors and Operations

tf.keras.callbacks.EarlyStopping, Using Callbacks

tf.keras.callbacks.LearningRateScheduler, Learning Rate Scheduling

tf.keras.callbacks.ModelCheckpoint, Using Callbacks

tf.keras.callbacks.TensorBoard, Using TensorBoard for Visualization,
Masking

tf.keras.datasets.imdb.load_data(), Sentiment Analysis

tf.keras.initializers.VarianceScaling, Glorot and He Initialization

tf.keras.layers.ActivityRegularization, Sparse Autoencoders

tf.keras.layers.AdditiveAttention, Attention Mechanisms

tf.keras.layers.Attention, Attention Mechanisms

tf.keras.layers.AvgPool2D, Implementing Pooling Layers with Keras

tf.keras.layers.BatchNormalization, Batch Normalization, Implementing
batch normalization with Keras-Implementing batch normalization with
Keras, Fighting the Unstable Gradients Problem

tf.keras.layers.Bidirectional, Bidirectional RNNs

tf.keras.layers.CategoryEncoding, The CategoryEncoding Layer

tf.keras.layers.CenterCrop, Image Preprocessing Layers

tf.keras.layers.Concatenate, Building Complex Models Using the
Functional API, Building Complex Models Using the Functional API,
GoogLeNet

tf.keras.layers.Conv1D, Semantic Segmentation, Masking

tf.keras.layers.Conv2D, Implementing Convolutional Layers with Keras

tf.keras.layers.Conv2DTranspose, Semantic Segmentation

tf.keras.layers.Conv3D, Semantic Segmentation

tf.keras.layers.Dense, Building Complex Models Using the Functional
API, Building Complex Models Using the Functional API, Custom
Layers-Custom Layers, Encoding Categorical Features Using
Embeddings, Tying Weights, Variational Autoencoders

tf.keras.layers.Discretization, The Discretization Layer

tf.keras.layers.Dropout, Dropout

tf.keras.layers.Embedding, Encoding Categorical Features Using
Embeddings, Building and Training the Char-RNN Model, Sentiment
Analysis, Positional encodings

tf.keras.layers.GlobalAvgPool2D, Implementing Pooling Layers with
Keras

tf.keras.layers.GRU, GRU cells

tf.keras.layers.GRUCell, GRU cells

tf.keras.layers.Hashing, The Hashing Layer

tf.keras.layers.Input, Building Complex Models Using the Functional
API

tf.keras.layers.Lambda, Custom Layers, Building and Training the Char-
RNN Model

tf.keras.layers.LayerNormalization, Fighting the Unstable Gradients
Problem

tf.keras.layers.LeakyReLU, Leaky ReLU

tf.keras.layers.LSTM, LSTM cells

tf.keras.layers.Masking, Masking

tf.keras.layers.MaxPool2D, Implementing Pooling Layers with Keras

tf.keras.layers.MultiHeadAttention, Multi-head attention

tf.keras.layers.Normalization, Building a Regression MLP Using the
Sequential API, Building Complex Models Using the Functional API,
The Normalization Layer-The Normalization Layer

tf.keras.layers.PReLU, Leaky ReLU

tf.keras.layers.Rescaling, Image Preprocessing Layers

tf.keras.layers.Resizing, Image Preprocessing Layers, Using Pretrained
Models from Keras

tf.keras.layers.RNN, LSTM cells

tf.keras.layers.SeparableConv2D, Xception

tf.keras.layers.StringLookup, The StringLookup Layer

tf.keras.layers.TextVectorization, Text Preprocessing-Text
Preprocessing, Creating the Training Dataset, Building and Training the
Char-RNN Model, Sentiment Analysis, Sentiment Analysis-An
Encoder–Decoder Network for Neural Machine Translation

tf.keras.layers.TimeDistributed, Forecasting Using a Sequence-to-
Sequence Model

tf.keras.losses.Huber, Custom Loss Functions

tf.keras.losses.kullback_leibler_divergence(), Sparse Autoencoders

tf.keras.losses.Loss, Saving and Loading Models That Contain Custom
Components

tf.keras.losses.sparse_categorical_crossentropy(), Compiling the model,
CNN Architectures, Building and Training the Char-RNN Model, An
Encoder–Decoder Network for Neural Machine Translation, Hugging
Face’s Transformers Library

tf.keras.metrics.MeanIoU, Classification and Localization

tf.keras.metrics.Metric, Custom Metrics

tf.keras.metrics.Precision, Custom Metrics

tf.keras.Model, Building Complex Models Using the Functional API

tf.keras.models.clone_model(), Using the Subclassing API to Build
Dynamic Models, Transfer Learning with Keras

tf.keras.models.load_model(), Saving and Restoring a Model, Saving
and Loading Models That Contain Custom Components-Saving and
Loading Models That Contain Custom Components, Custom Models,
Training at Scale Using the Distribution Strategies API

tf.keras.optimizers.Adam, Building a Regression MLP Using the
Sequential API, AdamW

tf.keras.optimizers.Adamax, AdamW

tf.keras.optimizers.experimental.AdamW, AdamW

tf.keras.optimizers.Nadam, AdamW

tf.keras.optimizers.schedules, Learning Rate Scheduling

tf.keras.optimizers.SGD, Momentum

tf.keras.preprocessing.image.ImageDataGenerator, Pretrained Models
for Transfer Learning

tf.keras.regularizers.l1_l2(), ℓ1 and ℓ2 Regularization

tf.keras.Sequential, Creating the model using the sequential API,
Building a Regression MLP Using the Sequential API, CNN
Architectures

tf.keras.utils.get_file(), Creating the Training Dataset

tf.keras.utils.set_random_seed(), Creating the model using the sequential
API

tf.keras.utils.timeseries_dataset_from_array(), Preparing the Data for
Machine Learning Models, Preparing the Data for Machine Learning
Models

tf.keras.utils.to_categorical(), Compiling the model

time series forecasting for RNN, Forecasting Using a Simple RNN-
Forecasting Using a Deep RNN

transfer learning with, Transfer Learning with Keras-Transfer Learning
with Keras

using TF functions (or not), Using TF Functions with Keras (or Not)

Keras session, Creating the model using the sequential API

Keras Tuner, Hyperparameter Tuning on Vertex AI

kernel trick, Polynomial Kernel-SVM Classes and Computational
Complexity, Kernelized SVMs-Kernelized SVMs

kernelized SVMs, Kernelized SVMs-Kernelized SVMs

kernels (convolution kernels), Filters, CNN Architectures

kernels (runtimes), Running the Code Examples Using Google Colab

KL (Kullback-Leibler) divergence, Softmax Regression, Sparse
Autoencoders

KLDivergenceRegularizer, Sparse Autoencoders

KMeans, Custom Transformers

KNeighborsClassifier, Multilabel Classification, Multioutput Classification

KNNImputer, Clean the Data

Kullback-Leibler (KL) divergence, Softmax Regression, Sparse
Autoencoders

L

label propagation, Using Clustering for Semi-Supervised Learning-Using
Clustering for Semi-Supervised Learning

labels, Frame the Problem

in clustering, k-means

image classification, Classification and Localization

supervised learning, Supervised learning

unlabeled data issue, Unsupervised Pretraining Using Stacked
Autoencoders

landmarks, Similarity Features

language models, Generating Shakespearean Text Using a Character RNN

(see also natural language processing)

large margin classification, Linear SVM Classification

Lasso, Lasso Regression

lasso regression, Lasso Regression-Lasso Regression

latent diffusion models, Diffusion Models

latent loss, Variational Autoencoders

latent representation of inputs, Vision Transformers, Autoencoders, GANs,
and Diffusion Models, Efficient Data Representations, Deep Convolutional
GANs

latent space, Variational Autoencoders

law of large numbers, Voting Classifiers

layer normalization, Exercises, Processing Sequences Using RNNs and
CNNs, Fighting the Unstable Gradients Problem

LDA (linear discriminant analysis), Other Dimensionality Reduction
Techniques

leaf node, decision tree, Making Predictions, Estimating Class Probabilities,
Regularization Hyperparameters

leakyReLU, Leaky ReLU-Leaky ReLU

learning curves, overfit or underfit analysis, Learning Curves-Learning
Curves

learning rate, Online learning, Gradient Descent, Batch Gradient Descent,
Stochastic Gradient Descent, Learning Rate, Batch Size, and Other
Hyperparameters, Q-Learning

learning rate schedules, Learning Rate Scheduling-Learning Rate Scheduling

learning schedules, Stochastic Gradient Descent

LeCun initialization, Glorot and He Initialization

LeNet-5, The Architecture of the Visual Cortex, LeNet-5

Levenshtein distance, Gaussian RBF Kernel

liblinear library, SVM Classes and Computational Complexity

libsvm library, SVM Classes and Computational Complexity

life satisfaction dataset, Model-based learning and a typical machine learning
workflow

likelihood function, Selecting the Number of Clusters-Selecting the Number
of Clusters

linear discriminant analysis (LDA), Other Dimensionality Reduction
Techniques

linear models

forecasting time series, Forecasting Using a Linear Model

linear regression (see linear regression)

regularized, Regularized Linear Models-Early Stopping

SVM, Linear SVM Classification-Soft Margin Classification

training and running example, Model-based learning and a typical
machine learning workflow

linear regression, Model-based learning and a typical machine learning
workflow-Model-based learning and a typical machine learning workflow,
Linear Regression-Mini-Batch Gradient Descent

comparison of algorithms, Mini-Batch Gradient Descent

computational complexity, Computational Complexity

gradient descent in, Gradient Descent-Mini-Batch Gradient Descent

learning curves in, Learning Curves-Learning Curves

Normal equation, The Normal Equation-The Normal Equation

regularizing models (see regularization)

ridge regression, Ridge Regression-Ridge Regression, Elastic Net
Regression

training set evaluation, Train and Evaluate on the Training Set

using stochastic gradient descent, Stochastic Gradient Descent

linear SVM classification, Linear SVM Classification-Soft Margin
Classification, Under the Hood of Linear SVM Classifiers-Kernelized SVMs

linear threshold units (LTUs), The Perceptron

linearly separable, SVM classes, Linear SVM Classification-Linear SVM
Classification, Similarity Features

LinearRegression, Clean the Data, Feature Scaling and Transformation, Train
and Evaluate on the Training Set, The Normal Equation, Computational
Complexity, Polynomial Regression

LinearSVC, Soft Margin Classification, SVM Classes and Computational
Complexity, Under the Hood of Linear SVM Classifiers

LinearSVR, SVM Regression-SVM Regression

Lipschitz continuous, derivative as, Gradient Descent

LLE (locally linear embedding), LLE-LLE

loading and preprocessing data, Loading and Preprocessing Data with
TensorFlow-The TensorFlow Datasets Project

image preprocessing layers, Image Preprocessing Layers

layer preprocessing in Keras, Loading and Preprocessing Data with
TensorFlow, Keras Preprocessing Layers-Using Pretrained Language
Model Components

tf.data API, Loading and Preprocessing Data with TensorFlow-Using
the Dataset with Keras

TFDS project, The TensorFlow Datasets Project-The TensorFlow
Datasets Project

TFRecord format, Loading and Preprocessing Data with TensorFlow,
The TFRecord Format-Handling Lists of Lists Using the
SequenceExample Protobuf

local outlier factor (LOF), Other Algorithms for Anomaly and Novelty
Detection

local receptive field, The Architecture of the Visual Cortex

local response normalization (LRN), AlexNet

local versus global minimum, gradient descent, Gradient Descent

locality sensitive hashing (LSH), Random Projection

localization, CNNs, Classification and Localization-Object Detection

locally linear embedding (LLE), LLE-LLE

LOF (local outlier factor), Other Algorithms for Anomaly and Novelty
Detection

log loss, Training and Cost Function

log-odds function, Estimating Probabilities

log-transformer, Custom Transformers

logical GPU device, Managing the GPU RAM

logistic function, Estimating Probabilities

logistic regression, Supervised learning, Feature Scaling and Transformation,
Logistic Regression-Softmax Regression

decision boundaries illustration, Decision Boundaries-Decision
Boundaries

estimating probabilities, Estimating Probabilities-Estimating
Probabilities

softmax regression model, Softmax Regression-Softmax Regression

training and cost function, Training and Cost Function-Training and
Cost Function

LogisticRegression, Decision Boundaries, Softmax Regression

logit function, Estimating Probabilities

long sequences, training RNN on, Handling Long Sequences-WaveNet

short-term memory problem, Tackling the Short-Term Memory
Problem-WaveNet

unstable gradients problem, Fighting the Unstable Gradients Problem-
Fighting the Unstable Gradients Problem

long short-term memory (LSTM) cell, LSTM cells-LSTM cells, Masking, An
Encoder–Decoder Network for Neural Machine Translation, Bidirectional
RNNs

loss functions

based on model internals, Losses and Metrics Based on Model Internals-
Losses and Metrics Based on Model Internals

custom, Custom Loss Functions

versus metrics, Custom Metrics

output, Building Complex Models Using the Functional API

LRN (local response normalization), AlexNet

LSH (locality sensitive hashing), Random Projection

LSTM (long short-term memory) cell, LSTM cells-LSTM cells, Masking, An
Encoder–Decoder Network for Neural Machine Translation, Bidirectional
RNNs

LTUs (linear threshold units), The Perceptron

Luong attention, Attention Mechanisms

M

machine learning (ML), What Is Machine Learning?

application/technique examples, Examples of Applications-Examples of
Applications

challenges of, Main Challenges of Machine Learning-Stepping Back

notations, Select a Performance Measure-Select a Performance Measure

project checklist, Look at the Big Picture

(see also end-to-end ML project exercise)

reasons for using, Why Use Machine Learning?-Why Use Machine
Learning?

resources on, Other Resources-Other Resources

spam filter example, The Machine Learning Landscape-Why Use
Machine Learning?

testing and validating, Testing and Validating-Data Mismatch

types of systems, Types of Machine Learning Systems-Model-based
learning and a typical machine learning workflow

MAE (mean absolute error), Select a Performance Measure

majority-vote predictions, Exercises

make_column_selector(), Transformation Pipelines

make_column_transformer(), Transformation Pipelines

make_pipeline(), Transformation Pipelines, Learning Curves

Manhattan norm, Select a Performance Measure

manifold hypothesis, Manifold Learning

manifold learning, dimension reduction, Manifold Learning-Manifold
Learning

MAP (maximum a-posteriori) estimation, Selecting the Number of Clusters

mAP (mean average precision), You Only Look Once

MAPE (mean absolute percentage error), Forecasting a Time Series

mapping network, StyleGANs, StyleGANs

MapReduce, Frame the Problem

margin violations, Soft Margin Classification, Under the Hood of Linear
SVM Classifiers

Markov chains, Markov Decision Processes

Markov decision processes (MDPs), Markov Decision Processes-Markov
Decision Processes, Exploration Policies

mask R-CNN, Semantic Segmentation

mask tensor, Masking

masked language model (MLM), An Avalanche of Transformer Models

masked multi-head attention layer, Attention Is All You Need: The Original
Transformer Architecture

masking, Masking-Masking, Multi-head attention

Matching Engine service, Vertex AI, Creating a Prediction Service on Vertex
AI

Matplotlib, Running the Code Examples Using Google Colab

max pooling layer, Pooling Layers, CNN Architectures

max-norm regularization, Max-Norm Regularization

maximization step, Gaussian mixtures, Gaussian Mixtures

maximum a-posteriori (MAP) estimation, Selecting the Number of Clusters

maximum likelihood estimate (MLE), Selecting the Number of Clusters

MC (Monte Carlo) dropout regularization, Monte Carlo (MC) Dropout-
Monte Carlo (MC) Dropout

MCTS (Monte Carlo tree search), Overview of Some Popular RL Algorithms

MDPs (Markov decision processes), Markov Decision Processes-Markov
Decision Processes, Exploration Policies

MDS (multidimensional scaling), Other Dimensionality Reduction
Techniques

mean absolute error (MAE), Select a Performance Measure

mean absolute percentage error (MAPE), Forecasting a Time Series

mean average precision (mAP), You Only Look Once

mean squared error (MSE), Linear Regression, Variational Autoencoders

mean-shift, clustering algorithms, Other Clustering Algorithms

mean_squared_error(), Train and Evaluate on the Training Set

measure of similarity, Instance-based learning

memory bandwidth, GPU card, Prefetching

memory cells (cells), RNNs, Memory Cells, Tackling the Short-Term
Memory Problem-WaveNet

memory requirements, convolutional layers, Memory Requirements

Mercer's theorem, Kernelized SVMs

meta learner, Stacking

metagraphs, SavedModel, Exporting SavedModels

min-max scaling, Feature Scaling and Transformation

mini-batch discrimination, The Difficulties of Training GANs

mini-batch gradient descent, Mini-Batch Gradient Descent-Mini-Batch
Gradient Descent, Early Stopping

mini-batch k-means, Accelerated k-means and mini-batch k-means

mini-batches, Online learning, Progressive Growing of GANs

MinMaxScaler, Feature Scaling and Transformation

mirrored strategy, data parallelism, Data parallelism using the mirrored
strategy, Training at Scale Using the Distribution Strategies API, Training a
Model on a TensorFlow Cluster

Mish activation function, GELU, Swish, and Mish

mixing regularization, StyleGAN, StyleGANs

ML (see machine learning)

ML Operations (MLOps), Launch, Monitor, and Maintain Your System

MLE (maximum likelihood estimate), Selecting the Number of Clusters

MLM (masked language model), An Avalanche of Transformer Models

MLPs (see multilayer perceptrons)

MNIST dataset, MNIST-MNIST

mobile device, deploying model to, Deploying a Model to a Mobile or
Embedded Device-Deploying a Model to a Mobile or Embedded Device

mode collapse, Vision Transformers, The Difficulties of Training GANs

model parallelism, Model Parallelism-Model Parallelism

model parameters, Model-based learning and a typical machine learning
workflow

early stopping regularization, Training and Cost Function

in gradient descent, Gradient Descent, Batch Gradient Descent

linear SVM classifier mechanics, Under the Hood of Linear SVM
Classifiers

and variable updating, Variables

weight matrix shape, Creating the model using the sequential API

model rot, Batch learning

model selection, Model-based learning and a typical machine learning
workflow, Hyperparameter Tuning and Model Selection-Hyperparameter
Tuning and Model Selection

model server (see TensorFlow Serving)

model warmup, Deploying a new model version

model-based learning, Model-based learning and a typical machine learning
workflow-Model-based learning and a typical machine learning workflow

modes, Feature Scaling and Transformation

momentum optimization, Momentum

momentum β, Momentum

Monte Carlo (MC) dropout, Monte Carlo (MC) Dropout-Monte Carlo (MC)
Dropout

Monte Carlo tree search (MCTS), Overview of Some Popular RL Algorithms

MSE (mean squared error), Linear Regression, Variational Autoencoders

multi-head attention layer, Attention Is All You Need: The Original
Transformer Architecture, Multi-head attention-Multi-head attention

multi-hot encoding, The CategoryEncoding Layer

multiclass (multinomial) classification, Multiclass Classification-Multiclass
Classification, Classification MLPs-Classification MLPs

multidimensional scaling (MDS), Other Dimensionality Reduction
Techniques

multilabel classifiers, Multilabel Classification-Multilabel Classification

multilayer perceptrons (MLPs), Introduction to Artificial Neural Networks
with Keras, The Perceptron-Using TensorBoard for Visualization

and autoencoders, Efficient Data Representations, Performing PCA with
an Undercomplete Linear Autoencoder

and backpropagation, The Multilayer Perceptron and Backpropagation-
The Multilayer Perceptron and Backpropagation

callbacks, Using Callbacks-Using Callbacks

classification MLPs, Classification MLPs-Classification MLPs

complex models, Building Complex Models Using the Functional API-
Building Complex Models Using the Functional API

dynamic models, Using the Subclassing API to Build Dynamic Models-
Using the Subclassing API to Build Dynamic Models

image classifier, Building an Image Classifier Using the Sequential API-
Using the model to make predictions

regression MLPs, Regression MLPs-Regression MLPs, Building a
Regression MLP Using the Sequential API

saving and restoring a model, Saving and Restoring a Model-Saving and
Restoring a Model

visualization with TensorBoard, Using TensorBoard for Visualization-
Using TensorBoard for Visualization

multimodal distribution, Feature Scaling and Transformation

multimodal transformers, Vision Transformers

multinomial logistic regression, Softmax Regression-Softmax Regression

multioutput classifiers, Multioutput Classification-Multioutput Classification

multiple regression, Frame the Problem

multiplicative attention, Attention Mechanisms

multitask classification, Building Complex Models Using the Functional API

multivariate regression, Frame the Problem

multivariate time series, Forecasting a Time Series, Forecasting Multivariate
Time Series-Forecasting Multivariate Time Series

N

Nadam, Nadam

NAG (Nesterov accelerated gradient), Nesterov Accelerated Gradient,
Nadam

naive forecasting, Forecasting a Time Series

Nash equilibrium, The Difficulties of Training GANs

natural language processing (NLP), Natural Language Processing with RNNs
and Attention-Hugging Face’s Transformers Library

char-RNN model to generate text, Generating Shakespearean Text Using
a Character RNN-Stateful RNN

encoder–decoder network for machine translation, An Encoder–Decoder
Network for Neural Machine Translation-An Encoder–Decoder
Network for Neural Machine Translation

machine learning examples, Examples of Applications

sentiment analysis, Sentiment Analysis-Reusing Pretrained Embeddings
and Language Models

text classification, Sentiment Analysis-Reusing Pretrained Embeddings
and Language Models

text encoding, Text Preprocessing-Using Pretrained Language Model
Components

text summarization, Examples of Applications

transformer models (see transformer models)

word embeddings, Encoding Categorical Features Using Embeddings

natural language understanding (NLU), Examples of Applications

NCCL (Nvidia collective communications library), Training at Scale Using
the Distribution Strategies API

NEAT (neuroevolution of augmenting topologies), Policy Search

negative class, Confusion Matrices, Logistic Regression

nested dataset, Preparing the Data for Machine Learning Models

Nesterov accelerated gradient (NAG), Nesterov Accelerated Gradient,
Nadam

Nesterov momentum optimization, Nesterov Accelerated Gradient, Nadam

neural machine translation (NMT), Reusing Pretrained Embeddings and
Language Models-Multi-head attention

and attention mechanisms, Attention Mechanisms-Multi-head attention

with transformers, An Avalanche of Transformer Models-An Avalanche
of Transformer Models

neural networks (see artificial neural networks)

neuroevolution of augmenting topologies (NEAT), Policy Search

next sentence prediction (NSP), An Avalanche of Transformer Models

NLU (natural language understanding), Examples of Applications

NMT (see neural machine translation)

No Free Lunch theorem, Data Mismatch

non-max suppression, bounding boxes, Object Detection

nonlinear dimensionality reduction (NLDR), LLE-LLE

nonlinear SVM classifiers, Nonlinear SVM Classification-SVM Classes and
Computational Complexity

nonparametric models, Regularization Hyperparameters

nonrepresentative training data, Nonrepresentative Training Data

nonresponse bias, Nonrepresentative Training Data

normal distribution, The Vanishing/Exploding Gradients Problems, Glorot
and He Initialization

Normal equation, The Normal Equation-The Normal Equation

normalization, Feature Scaling and Transformation, Batch Normalization-
Implementing batch normalization with Keras, Fighting the Unstable

Gradients Problem

Normalization layer, The Normalization Layer-The Normalization Layer

normalized exponential (softmax function), Softmax Regression

notations, Select a Performance Measure-Select a Performance Measure,
Linear Regression

novelty detection, Unsupervised learning, Using Gaussian Mixtures for
Anomaly Detection

NP-Complete problem, CART as, The CART Training Algorithm

NSP (next sentence prediction), An Avalanche of Transformer Models

nucleus sampling, Generating Fake Shakespearean Text

null hypothesis, Regularization Hyperparameters

number of inputs, Creating the model using the sequential API, Glorot and
He Initialization

number of neurons per hidden layer, Number of Neurons per Hidden Layer

NumPy, Running the Code Examples Using Google Colab

NumPy arrays, Clean the Data, Custom Transformers, Using TensorFlow like
NumPy-Other Data Structures

Nvidia collective communications library (NCCL), Training at Scale Using
the Distribution Strategies API

Nvidia GPU card, Getting Your Own GPU-Getting Your Own GPU

O

OAuth 2.0, Creating a Prediction Service on Vertex AI

object detection, CNNs, Object Detection-You Only Look Once

object tracking, CNNs, Object Tracking

objectness score, Object Detection

observation space, reinforcement learning, Learning to Optimize Rewards,
Neural Network Policies

observations, Introduction to OpenAI Gym-Introduction to OpenAI Gym

OCR (optical character recognition), The Machine Learning Landscape

OEL (open-ended learning), Overview of Some Popular RL Algorithms

off-policy algorithm, Q-Learning

offline learning, Batch learning

on-policy algorithm, Q-Learning

one-class SVM, Other Algorithms for Anomaly and Novelty Detection

one-hot encoding, Handling Text and Categorical Attributes-Handling Text
and Categorical Attributes, The CategoryEncoding Layer, Encoding
Categorical Features Using Embeddings

one-versus-all (OvA) strategy, Multiclass Classification-Multiclass
Classification

one-versus-one (OvO) strategy, Multiclass Classification-Multiclass
Classification

one-versus-the-rest (OvR) strategy, Multiclass Classification-Multiclass
Classification

1cycle scheduling, Learning Rate Scheduling, Learning Rate Scheduling

1D convolutional layers, Semantic Segmentation, Using 1D convolutional
layers to process sequences

OneHotEncoder, Handling Text and Categorical Attributes-Handling Text
and Categorical Attributes, Feature Scaling and Transformation,

Transformation Pipelines

online kernelized SVMs, Kernelized SVMs

online learning, Online learning-Online learning

online model, DQN, Fixed Q-value Targets

OOB (out-of-bag) evaluation, Out-of-Bag Evaluation-Out-of-Bag Evaluation

open-ended learning (OEL), Overview of Some Popular RL Algorithms

OpenAI Gym, Introduction to OpenAI Gym-Introduction to OpenAI Gym

operations (ops) and tensors, A Quick Tour of TensorFlow, Tensors and
Operations-Tensors and Operations

optical character recognition (OCR), The Machine Learning Landscape

optimal state value, MDP, Markov Decision Processes

optimizers, Faster Optimizers-AdamW

AdaGrad, AdaGrad

Adam optimization, Adam

AdaMax, AdaMax

AdamW, AdamW

hyperparameters, Learning Rate, Batch Size, and Other
Hyperparameters

momentum optimization, Momentum

Nadam, Nadam

Nesterov accelerated gradient, Nesterov Accelerated Gradient

output layer, An Encoder–Decoder Network for Neural Machine
Translation

RMSProp, RMSProp

oracle, Fine-Tuning Neural Network Hyperparameters

order of integration (d) hyperparameter, The ARMA Model Family

OrdinalEncoder, Handling Text and Categorical Attributes

orthogonal matrix, An Encoder–Decoder Network for Neural Machine
Translation

out-of-bag (OOB) evaluation, Out-of-Bag Evaluation-Out-of-Bag Evaluation

out-of-core learning, Online learning

out-of-sample error, Testing and Validating

outlier detection (see anomaly detection)

outliers, Unsupervised Learning Techniques

output gate, LSTM, LSTM cells

output layer, neural network, An Encoder–Decoder Network for Neural
Machine Translation

OvA (one-versus-all) strategy, Multiclass Classification-Multiclass
Classification

overcomplete autoencoder, Convolutional Autoencoders

overfitting of data, Overfitting the Training Data-Overfitting the Training
Data, Create a Test Set

avoiding through regularization, Avoiding Overfitting Through
Regularization-Max-Norm Regularization

and decision trees, Regularization Hyperparameters, Regression

and dropout regularization, Dropout

gamma (γ) hyperparameter to adjust, Gaussian RBF Kernel

image classification, Training and evaluating the model

learning curves to assess, Learning Curves-Learning Curves

number of neurons per hidden layer, Number of Neurons per Hidden
Layer

polynomial regression, Training Models

SVM model, Soft Margin Classification

OvO (one-versus-one) strategy, Multiclass Classification-Multiclass
Classification

OvR (one-versus-the-rest) strategy, Multiclass Classification-Multiclass
Classification

P

p-value, Regularization Hyperparameters

PACF (partial autocorrelation function), The ARMA Model Family

padding options, convolutional layer, Implementing Convolutional Layers
with Keras-Implementing Convolutional Layers with Keras

PaLM (Pathways language model), An Avalanche of Transformer Models

Pandas, Running the Code Examples Using Google Colab, Look for
Correlations-Look for Correlations, Handling Text and Categorical
Attributes, Feature Scaling and Transformation

parallelism, training models across devices, Training Models Across Multiple
Devices-Hyperparameter Tuning on Vertex AI

data parallelism, Data Parallelism-Bandwidth saturation

distribution strategies API, Training at Scale Using the Distribution
Strategies API

with GPU, Parallel Execution Across Multiple Devices-Parallel
Execution Across Multiple Devices

hyperparameter tuning, Hyperparameter Tuning on Vertex AI-
Hyperparameter Tuning on Vertex AI

model parallelism, Model Parallelism-Model Parallelism

on TensorFlow cluster, Training a Model on a TensorFlow Cluster-
Training a Model on a TensorFlow Cluster

Vertex AI for running large jobs, Running Large Training Jobs on
Vertex AI-Running Large Training Jobs on Vertex AI

parameter efficiency, Number of Hidden Layers

parameter matrix, Softmax Regression

parameter servers, Data parallelism with centralized parameters

parameter space, Gradient Descent

parameter vector, Linear Regression, Gradient Descent, Training and Cost
Function, Softmax Regression

parametric leaky ReLU (PReLU), Leaky ReLU

parametric models, Regularization Hyperparameters

partial autocorrelation function (PACF), The ARMA Model Family

partial derivative, Batch Gradient Descent

partial_fit(), Stochastic Gradient Descent

Pathways language model (PaLM), An Avalanche of Transformer Models

PCA (see principal component analysis)

PDF (probability density function), Unsupervised Learning Techniques,
Selecting the Number of Clusters

Pearson's r, Look for Correlations

penalties, reinforcement learning, Reinforcement learning

PER (prioritized experience replay), Prioritized Experience Replay

Perceiver, Vision Transformers

percentiles, Take a Quick Look at the Data Structure

perceptrons, Introduction to Artificial Neural Networks with Keras, The
Perceptron-Classification MLPs

(see also multilayer perceptrons)

performance measures, Performance Measures-The ROC Curve

confusion matrix, Confusion Matrices-Confusion Matrices

cross-validation to measure accuracy, Measuring Accuracy Using Cross-
Validation-Measuring Accuracy Using Cross-Validation

precision and recall, Precision and Recall-The Precision/Recall Trade-
off

ROC curve, The ROC Curve-The ROC Curve

selecting, Select a Performance Measure-Select a Performance Measure

performance scheduling, Learning Rate Scheduling, Learning Rate
Scheduling

permutation(), Create a Test Set

PG (policy gradients) algorithm, Policy Search, Policy Gradients-Policy
Gradients

piecewise constant scheduling, Learning Rate Scheduling, Learning Rate
Scheduling

PipeDream, Bandwidth saturation

Pipeline class, Transformation Pipelines

Pipeline constructor, Transformation Pipelines-Transformation Pipelines

pipelines, Frame the Problem, Transformation Pipelines-Transformation
Pipelines, Learning Curves, Soft Margin Classification

pixelwise normalization layer, Progressive Growing of GANs

placeholders, function definitions, Exploring Function Definitions and
Graphs

POET algorithm, Overview of Some Popular RL Algorithms

policy gradients (PG) algorithm, Policy Search, Policy Gradients-Policy
Gradients

policy parameters, Policy Search

policy space, Policy Search

policy, reinforcement learning, Reinforcement learning, Policy Search,
Neural Network Policies

polynomial features, SVM classifiers, Polynomial Kernel

polynomial kernel, Polynomial Kernel, Kernelized SVMs

polynomial regression, Training Models, Polynomial Regression-Polynomial
Regression

polynomial time, The CART Training Algorithm

PolynomialFeatures, Polynomial Regression, Nonlinear SVM Classification

pooling kernel, Pooling Layers

pooling layers, Pooling Layers-Implementing Pooling Layers with Keras

positional encodings, Positional encodings-Positional encodings

positive class, Confusion Matrices, Logistic Regression

post-training quantization, Deploying a Model to a Mobile or Embedded
Device

posterior distribution, Variational Autoencoders

power law distribution, Feature Scaling and Transformation

power scheduling, Learning Rate Scheduling

PPO (proximal policy optimization), Overview of Some Popular RL
Algorithms

precision and recall, classifier metrics, Precision and Recall-The
Precision/Recall Trade-off

precision/recall curve (PR), The Precision/Recall Trade-off, The ROC Curve

precision/recall trade-off, The Precision/Recall Trade-off-The
Precision/Recall Trade-off

predict(), Clean the Data, Custom Transformers, Transformation Pipelines

predicted class, Confusion Matrices

prediction service, on Vertex AI, Creating a Prediction Service on Vertex AI-
Running Batch Prediction Jobs on Vertex AI

predictions

backpropagation, The Multilayer Perceptron and Backpropagation

confusion matrix, Confusion Matrices-Confusion Matrices

cross-validation to measure accuracy, Measuring Accuracy Using Cross-
Validation-Measuring Accuracy Using Cross-Validation

decision trees, Making Predictions-The CART Training Algorithm

with linear SVM classifier, Under the Hood of Linear SVM Classifiers

predictors, Supervised learning

(see also ensemble learning)

predict_log_proba(), Soft Margin Classification

predict_proba(), Soft Margin Classification

prefetching of data, Prefetching-Prefetching

PReLU (parametric leaky ReLU), Leaky ReLU

preprocessed attributes, Take a Quick Look at the Data Structure

preprocessing data (see loading and preprocessing data)

preprocessing mismatch, The Normalization Layer

pretraining and pretrained layers

on auxiliary task, Pretraining on an Auxiliary Task

CNNs, Using Pretrained Models from Keras-Pretrained Models for
Transfer Learning

greedy layer-wise pretraining, Unsupervised Pretraining, Training One
Autoencoder at a Time, Progressive Growing of GANs

language model components, Using Pretrained Language Model
Components

reusing embeddings, Reusing Pretrained Embeddings and Language
Models-Reusing Pretrained Embeddings and Language Models

reusing layers, Reusing Pretrained Layers-Pretraining on an Auxiliary
Task

in unsupervised learning, Unsupervised Pretraining, Reusing Pretrained
Embeddings and Language Models, An Avalanche of Transformer
Models, Unsupervised Pretraining Using Stacked Autoencoders

primal problem, The Dual Problem

principal component (PC), Principal Components-Principal Components

principal component analysis (PCA), PCA-Incremental PCA

choosing number of dimensions, Choosing the Right Number of
Dimensions-Choosing the Right Number of Dimensions

for compression, PCA for Compression-PCA for Compression

explained variance ratio, Explained Variance Ratio

finding principal components, Principal Components

incremental PCA, Incremental PCA-Incremental PCA

preserving variance, Preserving the Variance

projecting down to d dimensions, Projecting Down to d Dimensions

randomized PCA, Randomized PCA

for scaling data in decision trees, Sensitivity to Axis Orientation

with undercomplete linear autoencoder, Performing PCA with an
Undercomplete Linear Autoencoder-Performing PCA with an
Undercomplete Linear Autoencoder

using Scikit_Learn for, Using Scikit-Learn

prior distribution, Variational Autoencoders

prioritized experience replay (PER), Prioritized Experience Replay

probabilistic autoencoders, Variational Autoencoders

probabilities, estimating, Estimating Probabilities-Estimating Probabilities,
Estimating Class Probabilities, Voting Classifiers

probability density function (PDF), Unsupervised Learning Techniques,
Selecting the Number of Clusters

probability versus likelihood, Selecting the Number of Clusters-Selecting the

Number of Clusters

profiling the network, with TensorBoard, Using TensorBoard for
Visualization

progressive web app (PWA), Running a Model in a Web Page

projection, dimensionality reduction, Projection-Projection

propositional logic, From Biological to Artificial Neurons

protocol buffers (protobuf), A Brief Introduction to Protocol Buffers-
TensorFlow Protobufs, Handling Lists of Lists Using the SequenceExample
Protobuf, Querying TF Serving through the gRPC API

proximal policy optimization (PPO), Overview of Some Popular RL
Algorithms

pruning of decision tree nodes, Regularization Hyperparameters

pseudoinverse, The Normal Equation

PWA (progressive web app), Running a Model in a Web Page

Python API, Get the Data

Q

Q-learning algorithm, Q-Learning-Dueling DQN

approximate Q-learning, Approximate Q-Learning and Deep Q-
Learning

exploration policies, Exploration Policies

implementing deep Q-learning, Implementing Deep Q-Learning-
Implementing Deep Q-Learning

variants in deep Q-learning, Deep Q-Learning Variants-Dueling DQN

Q-value iteration algorithm, Markov Decision Processes-Markov Decision

Processes

Q-values, Markov Decision Processes-Markov Decision Processes

quadratic equation, Polynomial Regression

quadratic programming (QP) problems, Under the Hood of Linear SVM
Classifiers

quantization-aware training, Deploying a Model to a Mobile or Embedded
Device

quartiles, Take a Quick Look at the Data Structure

queries per second (QPS), Training and Deploying TensorFlow Models at
Scale, Creating a Prediction Service on Vertex AI

question-answering modules, Examples of Applications

queues, Other Data Structures, Queues

R

radial basis function (RBF), Feature Scaling and Transformation

ragged dimensions, Other Data Structures

Rainbow agent, Dueling DQN

random forests, Better Evaluation Using Cross-Validation, Ensemble
Learning and Random Forests, Random Forests-Feature Importance

analysis of models and their errors, Analyzing the Best Models and
Their Errors

decision trees (see decision trees)

extra-trees, Extra-Trees

feature importance measurement, Feature Importance

random initialization, Gradient Descent, Gradient Descent

random patches, Random Patches and Random Subspaces

random projection algorithm, Random Projection-Random Projection

random subspaces, Random Patches and Random Subspaces

RandomForestClassifier, The ROC Curve-The ROC Curve

RandomForestRegressor, Better Evaluation Using Cross-Validation

randomized leaky ReLU (RReLU), Leaky ReLU

randomized PCA, Randomized PCA

randomized search, Randomized Search-Randomized Search, Fine-Tuning
Neural Network Hyperparameters-Fine-Tuning Neural Network
Hyperparameters

RBF (radial basis function), Feature Scaling and Transformation

rbf_kernel(), Feature Scaling and Transformation, Custom Transformers

recall metric, Precision and Recall

receiver operating characteristic (ROC) curve, The ROC Curve-The ROC
Curve

recognition network, Efficient Data Representations

(see also autoencoders)

recommender system, Examples of Applications

reconstruction error, PCA for Compression, Tying Weights

reconstruction loss, Losses and Metrics Based on Model Internals, Efficient
Data Representations

rectified linear units (ReLU) (see ReLU)

recurrent dropout, Processing Sequences Using RNNs and CNNs

recurrent layer normalization, Processing Sequences Using RNNs and CNNs,
Fighting the Unstable Gradients Problem

recurrent neural networks (RNNs), Processing Sequences Using RNNs and
CNNs-Beam Search

bidirectional, Bidirectional RNNs

deep RNN, Forecasting Using a Deep RNN

forecasting time series (see time series data)

gradient clipping, Gradient Clipping

handling long sequences, Handling Long Sequences-WaveNet

input and output sequences, Input and Output Sequences-Input and
Output Sequences

memory cells, Memory Cells, Tackling the Short-Term Memory
Problem-WaveNet

NLP (see natural language processing)

and Perceiver, Vision Transformers

splitting across devices, Model Parallelism

stateful, Natural Language Processing with RNNs and Attention,
Stateful RNN-Stateful RNN

stateless, Natural Language Processing with RNNs and Attention,
Stateful RNN

training, Training RNNs

and vision transformers, Vision Transformers

recurrent neurons, Recurrent Neurons and Layers

reduce operation, Data parallelism using the mirrored strategy

region proposal network (RPN), You Only Look Once

regression MLPs, Regression MLPs-Regression MLPs

regression models

and classification, Supervised learning, Multioutput Classification

decision tree tasks, Regression-Regression

forecasting example, Examples of Applications

lasso regression, Lasso Regression-Lasso Regression

linear regression (see linear regression)

logistic regression (see logistic regression)

multiple regression, Frame the Problem

multivariate regression, Frame the Problem

polynomial regression, Training Models, Polynomial Regression-
Polynomial Regression

regression MLPs, Building a Regression MLP Using the Sequential API

ridge regression, Ridge Regression-Ridge Regression, Elastic Net
Regression

softmax regression, Softmax Regression-Softmax Regression

SVM, SVM Regression-SVM Regression

univariate regression, Frame the Problem

regression to the mean, Supervised learning

regularization, Overfitting the Training Data, Avoiding Overfitting Through
Regularization-Max-Norm Regularization

custom regularizers, Custom Activation Functions, Initializers,
Regularizers, and Constraints

decision trees, Regularization Hyperparameters

dropout, Dropout-Dropout

early stopping, Early Stopping-Early Stopping, Gradient Boosting,
Forecasting Using a Linear Model

elastic net, Elastic Net Regression

hyperparameters, Regularization Hyperparameters-Regularization
Hyperparameters

lasso regression, Lasso Regression-Lasso Regression

linear models, Regularized Linear Models-Early Stopping

max-norm, Max-Norm Regularization

MC dropout, Monte Carlo (MC) Dropout-Monte Carlo (MC) Dropout

ridge, Ridge Regression

shrinkage, Gradient Boosting

subword, Sentiment Analysis

Tikhonov, Ridge Regression-Ridge Regression

weight decay, AdamW

ℓ₁ and ℓ₂ regularization, ℓ1 and ℓ2 Regularization

REINFORCE algorithms, Policy Gradients

reinforcement learning (RL), Reinforcement learning, Reinforcement
Learning-Overview of Some Popular RL Algorithms

actions, Evaluating Actions: The Credit Assignment Problem-Evaluating
Actions: The Credit Assignment Problem

credit assignment problem, Evaluating Actions: The Credit Assignment
Problem-Evaluating Actions: The Credit Assignment Problem

examples of, Examples of Applications, Learning to Optimize Rewards

learning in order to optimizing rewards, Learning to Optimize Rewards

Markov decision processes, Markov Decision Processes-Markov
Decision Processes

neural network policies, Neural Network Policies

OpenAI Gym, Introduction to OpenAI Gym-Introduction to OpenAI
Gym

PG algorithms, Policy Gradients-Policy Gradients

policy search, Policy Search

Q-learning, Q-Learning-Dueling DQN

TD learning, Temporal Difference Learning

ReLU (rectified linear units)

and backpropagation, The Multilayer Perceptron and Backpropagation

in CNN architectures, CNN Architectures

as default for simple tasks, GELU, Swish, and Mish

leakyReLU, Leaky ReLU-Leaky ReLU

and MLPS, Regression MLPs

RNN unstable gradients problem, Fighting the Unstable Gradients
Problem

RReLU, Leaky ReLU

tuning hyperparameters, Fine-Tuning Neural Network Hyperparameters

replay buffer, Implementing Deep Q-Learning

representation learning, Handling Text and Categorical Attributes

(see also autoencoders)

residual block, Custom Models-Custom Models

residual errors, Gradient Boosting-Gradient Boosting

residual learning, ResNet

residual network (ResNet), ResNet-ResNet

residual units, ResNet

ResNet-152, ResNet

ResNet-34, ResNet, Implementing a ResNet-34 CNN Using Keras

ResNet-50, Using Pretrained Models from Keras

ResNeXt, Other Noteworthy Architectures

REST API, querying through, Querying TF Serving through the REST API

return, in reinforcement learning, Policy Gradients

reverse process, diffusion model, Diffusion Models-Diffusion Models

reverse-mode autodiff, The Multilayer Perceptron and Backpropagation,
Computing Gradients Using Autodiff

rewards, reinforcement learning, Reinforcement learning, Learning to
Optimize Rewards

Ridge, Ridge Regression

ridge regression, Ridge Regression-Ridge Regression, Elastic Net Regression

ridge regularization, Ridge Regression

RidgeCV, Ridge Regression

RL (see reinforcement learning)

RMSProp, RMSProp

ROC (receiver operating characteristic) curve, The ROC Curve-The ROC
Curve

root mean square error (RMSE), Select a Performance Measure-Select a
Performance Measure, Train and Evaluate on the Training Set, Linear
Regression, Early Stopping

root node, decision tree, Making Predictions, Making Predictions

RPN (region proposal network), You Only Look Once

RReLU (randomized leaky ReLU), Leaky ReLU

S

SAC (soft actor-critic), Overview of Some Popular RL Algorithms

“same” padding, computer vision, Implementing Convolutional Layers with
Keras

SAMME, AdaBoost

sample inefficiency, Policy Gradients

sampled softmax, An Encoder–Decoder Network for Neural Machine
Translation

sampling bias, Nonrepresentative Training Data, Create a Test Set

sampling noise, Nonrepresentative Training Data

SARIMA model, The ARMA Model Family-The ARMA Model Family

SavedModel, Exporting SavedModels-Exporting SavedModels

saving, loading, and restoring models, Saving and Restoring a Model-Saving
and Restoring a Model, Saving and Loading Models That Contain Custom

Components-Saving and Loading Models That Contain Custom Components

scaled dot-product attention layer, Multi-head attention

scatter matrix, Look for Correlations-Look for Correlations

Scikit-Learn, Objective and Approach

bagging and pasting in, Bagging and Pasting in Scikit-Learn

CART algorithm, The CART Training Algorithm, Regression

cross-validation, Better Evaluation Using Cross-Validation-Better
Evaluation Using Cross-Validation

design principles, Clean the Data-Clean the Data

PCA implementation, Using Scikit-Learn

Pipeline constructor, Transformation Pipelines-Transformation Pipelines

sklearn.base.BaseEstimator, Custom Transformers

sklearn.base.clone(), Early Stopping

sklearn.base.TransformerMixin, Custom Transformers

sklearn.cluster.DBSCAN, DBSCAN

sklearn.cluster.KMeans, Custom Transformers, k-means

sklearn.cluster.MiniBatchKMeans, Accelerated k-means and mini-batch
k-means

sklearn.compose.ColumnTransformer, Transformation Pipelines

sklearn.compose.TransformedTargetRegressor, Feature Scaling and
Transformation

sklearn.datasets.load_iris(), Decision Boundaries

sklearn.datasets.make_moons(), Nonlinear SVM Classification

sklearn.decomposition.IncrementalPCA, Incremental PCA

sklearn.decomposition.PCA, Using Scikit-Learn

sklearn.ensemble.AdaBoostClassifier, AdaBoost

sklearn.ensemble.BaggingClassifier, Bagging and Pasting in Scikit-
Learn

sklearn.ensemble.GradientBoostingRegressor, Gradient Boosting-
Gradient Boosting

sklearn.ensemble.HistGradientBoostingClassifier, Histogram-Based
Gradient Boosting

sklearn.ensemble.HistGradientBoostingRegressor, Histogram-Based
Gradient Boosting

sklearn.ensemble.RandomForestClassifier, The ROC Curve-The ROC
Curve, Voting Classifiers, Random Forests, Feature Importance,
Choosing the Right Number of Dimensions

sklearn.ensemble.RandomForestRegressor, Better Evaluation Using
Cross-Validation, Random Forests

sklearn.ensemble.StackingClassifier, Stacking

sklearn.ensemble.StackingRegressor, Stacking

sklearn.ensemble.VotingClassifier, Voting Classifiers

sklearn.externals.joblib, Launch, Monitor, and Maintain Your System-
Launch, Monitor, and Maintain Your System

sklearn.feature_selection.SelectFromModel, Analyzing the Best Models
and Their Errors

sklearn.impute.IterativeImputer, Clean the Data

sklearn.impute.KNNImputer, Clean the Data

sklearn.impute.SimpleImputer, Clean the Data

sklearn.linear_model.ElasticNet, Elastic Net Regression

sklearn.linear_model.Lasso, Lasso Regression

sklearn.linear_model.LinearRegression, Model-based learning and a
typical machine learning workflow, Clean the Data, Feature Scaling and
Transformation, The Normal Equation, Computational Complexity,
Polynomial Regression

sklearn.linear_model.LogisticRegression, Decision Boundaries, Softmax
Regression, Using Clustering for Semi-Supervised Learning

sklearn.linear_model.Perceptron, The Perceptron

sklearn.linear_model.Ridge, Ridge Regression

sklearn.linear_model.RidgeCV, Ridge Regression

sklearn.linear_model.SGDClassifier, Training a Binary Classifier, The
Precision/Recall Trade-off, The Precision/Recall Trade-off, The ROC
Curve-The ROC Curve, Multiclass Classification, SVM Classes and
Computational Complexity, Under the Hood of Linear SVM Classifiers,
The Perceptron

sklearn.linear_model.SGDRegressor, Stochastic Gradient Descent, Early
Stopping

sklearn.manifold.LocallyLinearEmbedding, LLE

sklearn.metrics.ConfusionMatrixDisplay, Error Analysis

sklearn.metrics.confusion_matrix(), Confusion Matrices, Error Analysis

sklearn.metrics.f1_score(), Precision and Recall, Multilabel
Classification

sklearn.metrics.mean_squared_error(), Train and Evaluate on the
Training Set

sklearn.metrics.precision_recall_curve(), The Precision/Recall Trade-
off, The ROC Curve

sklearn.metrics.precision_score(), Precision and Recall

sklearn.metrics.recall_score(), Precision and Recall

sklearn.metrics.roc_auc_score(), The ROC Curve

sklearn.metrics.roc_curve(), The ROC Curve

sklearn.metrics.silhouette_score(), Finding the optimal number of
clusters

sklearn.mixture.BayesianGaussianMixture, Bayesian Gaussian Mixture
Models

sklearn.mixture.GaussianMixture, Gaussian Mixtures

sklearn.model_selection.cross_val_predict(), Confusion Matrices, The
Precision/Recall Trade-off, The ROC Curve, Error Analysis, Stacking

sklearn.model_selection.cross_val_score(), Better Evaluation Using
Cross-Validation, Measuring Accuracy Using Cross-Validation

sklearn.model_selection.GridSearchCV, Grid Search-Grid Search

sklearn.model_selection.learning_curve(), Learning Curves

sklearn.model_selection.RandomizedSearchCV, Choosing the Right
Number of Dimensions

sklearn.model_selection.StratifiedKFold, Measuring Accuracy Using
Cross-Validation

sklearn.model_selection.StratifiedShuffleSplit, Create a Test Set

sklearn.model_selection.train_test_split(), Create a Test Set, Create a
Test Set, Better Evaluation Using Cross-Validation

sklearn.multiclass.OneVsOneClassifier, Multiclass Classification

sklearn.multiclass.OneVsRestClassifier, Multiclass Classification

sklearn.multioutput.ChainClassifier, Multilabel Classification

sklearn.neighbors.KNeighborsClassifier, Multilabel Classification,
Multioutput Classification, DBSCAN

sklearn.neighbors.KNeighborsRegressor, Model-based learning and a
typical machine learning workflow

sklearn.neural_network.MLPClassifier, Classification MLPs

sklearn.neural_network.MLPRegressor, Regression MLPs

sklearn.pipeline.make_pipeline(), Learning Curves

sklearn.pipeline.Pipeline, Transformation Pipelines

sklearn.preprocessing.FunctionTransformer, Custom Transformers

sklearn.preprocessing.MinMaxScaler, Feature Scaling and
Transformation

sklearn.preprocessing.OneHotEncoder, Handling Text and Categorical
Attributes-Handling Text and Categorical Attributes, Feature Scaling
and Transformation, Transformation Pipelines

sklearn.preprocessing.OrdinalEncoder, Handling Text and Categorical
Attributes, Histogram-Based Gradient Boosting

sklearn.preprocessing.PolynomialFeatures, Polynomial Regression,
Nonlinear SVM Classification

sklearn.preprocessing.StandardScaler, Feature Scaling and
Transformation, Gradient Descent, Ridge Regression, Nonlinear SVM
Classification

sklearn.random_projection.GaussianRandomProjection, Random
Projection

sklearn.random_projection.SparseRandomProjection, Random
Projection

sklearn.semi_supervised.LabelPropagation, Using Clustering for Semi-
Supervised Learning

sklearn.semi_supervised.LabelSpreading, Using Clustering for Semi-
Supervised Learning

sklearn.semi_supervised.SelfTrainingClassifier, Using Clustering for
Semi-Supervised Learning

sklearn.svm.LinearSVC, Soft Margin Classification, SVM Classes and
Computational Complexity, Under the Hood of Linear SVM Classifiers

sklearn.svm.SVC, Multiclass Classification, Polynomial Kernel, SVM
Classes and Computational Complexity, Under the Hood of Linear SVM
Classifiers

sklearn.svm.SVR, SVM Regression

sklearn.tree.DecisionTreeClassifier, Training and Visualizing a Decision
Tree, Gini Impurity or Entropy?, Regularization Hyperparameters,
Sensitivity to Axis Orientation, Random Forests

sklearn.tree.DecisionTreeRegressor, Train and Evaluate on the Training
Set, Decision Trees, Regression, Gradient Boosting

sklearn.tree.export_graphviz(), Training and Visualizing a Decision Tree

sklearn.tree.ExtraTreesClassifier, Extra-Trees

sklearn.utils.estimator_checks, Custom Transformers

sklearn.utils.validation module, Custom Transformers

SVM classification classes, SVM Classes and Computational
Complexity

score(), Clean the Data

search engines, clustering for, Clustering Algorithms: k-means and DBSCAN

search space, Randomized Search

seasonality, time series modeling, Forecasting a Time Series

second moment (variance of gradient), Adam

second-order partial derivatives (Hessians), AdamW

segment embedding, An Avalanche of Transformer Models

SelectFromModel, Analyzing the Best Models and Their Errors

self-attention layers, Attention Is All You Need: The Original Transformer
Architecture, Multi-head attention, Vision Transformers

self-distillation, Vision Transformers

self-normalization, ELU and SELU, Dropout, Summary and Practical
Guidelines

self-supervised learning, Self-supervised learning-Self-supervised learning

SELU (scaled ELU) activation function, ELU and SELU, Dropout

semantic interpolation, Generating Fashion MNIST Images

semantic segmentation, Examples of Applications, Using Clustering for
Image Segmentation, Semantic Segmentation-Semantic Segmentation

semi-supervised learning, Semi-supervised learning, Clustering Algorithms:
k-means and DBSCAN, Using Clustering for Semi-Supervised Learning-
Using Clustering for Semi-Supervised Learning

SENet, SENet-SENet

sensitivity (recall), ROC curve, The ROC Curve

sensitivity metric, Confusion Matrices

sensors, Learning to Optimize Rewards

sentence encoder, Using Pretrained Language Model Components, Reusing
Pretrained Embeddings and Language Models

SentencePiece project, Sentiment Analysis

sentiment analysis, Sentiment Analysis-Reusing Pretrained Embeddings and
Language Models

sentiment neuron, Stateful RNN

separable convolution layer, Xception

sequence length, Using 1D convolutional layers to process sequences,
Positional encodings

sequence-to-sequence (seq2seq) network, Input and Output Sequences,
Forecasting Using a Sequence-to-Sequence Model-Forecasting Using a
Sequence-to-Sequence Model

sequence-to-vector network, Input and Output Sequences

SequenceExample protobuf, Handling Lists of Lists Using the
SequenceExample Protobuf

sequential API, image classifier with, Building an Image Classifier Using the
Sequential API-Using the model to make predictions

service account, GCP, Creating a Prediction Service on Vertex AI

service worker, Running a Model in a Web Page

sets, Sets

set_params(), Custom Transformers

SGD (see stochastic gradient descent)

SGDClassifier, Training a Binary Classifier, The Precision/Recall Trade-off,
The Precision/Recall Trade-off, The ROC Curve-The ROC Curve, Multiclass
Classification, SVM Classes and Computational Complexity, Under the

Hood of Linear SVM Classifiers, Under the Hood of Linear SVM Classifiers

SGDRegressor, Stochastic Gradient Descent, Early Stopping

sharpening, NLP transformers, Vision Transformers

shrinkage, Gradient Boosting

shuffle_and_split_data(), Create a Test Set, Create a Test Set

shuffling data, Stochastic Gradient Descent, Shuffling the Data-Shuffling the
Data

Siamese neural network, Parallel Execution Across Multiple Devices

sigmoid activation function, Estimating Probabilities, The Multilayer
Perceptron and Backpropagation, The Vanishing/Exploding Gradients
Problems, Sparse Autoencoders

signals, Biological Neurons

silhouette coefficient, Finding the optimal number of clusters

silhouette diagram, Finding the optimal number of clusters

SiLU activation function, GELU, Swish, and Mish

similarity features, SVM, Similarity Features

SimpleImputer, Clean the Data

simulated annealing, Stochastic Gradient Descent

simulated environments, Introduction to OpenAI Gym-Introduction to
OpenAI Gym

single program, multiple data (SPMD), Data Parallelism-Bandwidth
saturation

single-shot learning, Semantic Segmentation

singular value decomposition (SVD), The Normal Equation, Principal

Components, Randomized PCA

skewed datasets, Measuring Accuracy Using Cross-Validation

skewed left/right, Take a Quick Look at the Data Structure

skip connections, ELU and SELU, ResNet

slack variable, Under the Hood of Linear SVM Classifiers

smoothing terms, Batch Normalization, AdaGrad

SMOTE (synthetic minority oversampling technique), AlexNet

soft actor-critic (SAC), Overview of Some Popular RL Algorithms

soft clustering, k-means

soft margin classification, Soft Margin Classification-Soft Margin
Classification, Under the Hood of Linear SVM Classifiers

soft voting, Voting Classifiers

softmax activation function, Softmax Regression, Classification MLPs,
Creating the model using the sequential API, An Encoder–Decoder Network
for Neural Machine Translation

softmax regression, Softmax Regression-Softmax Regression

softplus activation function, Regression MLPs

spam filters, The Machine Learning Landscape-Why Use Machine
Learning?, Types of Machine Learning Systems-Supervised learning

sparse autoencoders, Sparse Autoencoders-Sparse Autoencoders

sparse features, SVC class, SVM Classes and Computational Complexity

sparse matrix, Handling Text and Categorical Attributes, Feature Scaling and
Transformation, Transformation Pipelines

sparse models, Lasso Regression, AdamW

sparse tensors, Sparse Tensors

sparsity loss, Sparse Autoencoders

specificity, ROC curve, The ROC Curve

spectral clustering, Other Clustering Algorithms

speech recognition, Why Use Machine Learning?, Examples of Applications

split node, decision tree, Making Predictions

SPMD (single program, multiple data), Data Parallelism-Bandwidth
saturation

squared hinge loss, Under the Hood of Linear SVM Classifiers

Stable Diffusion, Diffusion Models

stacked autoencoders, Stacked Autoencoders-Training One Autoencoder at a
Time

stacking (stacked generalization), Stacking-Stacking

stale gradients, Asynchronous updates

standard correlation coefficient, Look for Correlations

standard deviation, Take a Quick Look at the Data Structure

standardization, Feature Scaling and Transformation

StandardScaler, Feature Scaling and Transformation, Gradient Descent,
Ridge Regression, Nonlinear SVM Classification

state-action values (Q-Values), Markov Decision Processes-Markov Decision
Processes

stateful metric, Custom Metrics

stateful RNN, Natural Language Processing with RNNs and Attention,
Stateful RNN-Stateful RNN

stateless RNN, Natural Language Processing with RNNs and Attention,
Stateful RNN, Stateful RNN

stationary time series, Forecasting a Time Series

statistical mode, Bagging and Pasting

statistical significance, Regularization Hyperparameters

statsmodels library, The ARMA Model Family

stemming, Exercises

step functions, TLU, The Perceptron

stochastic gradient boosting, Gradient Boosting

stochastic gradient descent (SGD), Stochastic Gradient Descent-Stochastic
Gradient Descent, SVM Classes and Computational Complexity

early stopping, Early Stopping

image classification, Compiling the model

and perceptron learning algorithm, The Perceptron

ridge regularization, Ridge Regression

and TD learning, Temporal Difference Learning

training binary classifier, Training a Binary Classifier

stratified sampling, Create a Test Set-Create a Test Set, Measuring Accuracy
Using Cross-Validation

strat_train_set, Prepare the Data for Machine Learning Algorithms

streaming metric, Custom Metrics

strides, Convolutional Layers, Semantic Segmentation, Using 1D
convolutional layers to process sequences

string kernels, Gaussian RBF Kernel

string tensors, Other Data Structures

StringLookup layer, The StringLookup Layer

strings, Strings-Strings

strong learners, Voting Classifiers

style mixing, StyleGAN, StyleGANs

style transfer, GANs, StyleGANs

StyleGANs, StyleGANs-StyleGANs

subclassing API, Using the Subclassing API to Build Dynamic Models-Using
the Subclassing API to Build Dynamic Models

subgradient vector, Lasso Regression

subsampling, pooling layer, Pooling Layers

subword regularization, Sentiment Analysis

super-convergence, Learning Rate Scheduling

super-resolution, Semantic Segmentation

supervised learning, Supervised learning

support vector machines (SVMs), Support Vector Machines-Kernelized
SVMs

decision function, Under the Hood of Linear SVM Classifiers-Under the
Hood of Linear SVM Classifiers

dual problem, The Dual Problem-Kernelized SVMs

kernelized SVMs, Kernelized SVMs-Kernelized SVMs

linear classification, Linear SVM Classification-Soft Margin

Classification

mechanics of, Under the Hood of Linear SVM Classifiers-Kernelized
SVMs

in multiclass classification, Multiclass Classification

nonlinear classifiers, Nonlinear SVM Classification

one-class SVM, Other Algorithms for Anomaly and Novelty Detection

SVM regression, SVM Regression-SVM Regression

support vectors, Linear SVM Classification

SVC class, Polynomial Kernel, SVM Classes and Computational Complexity

SVD (singular value decomposition), The Normal Equation, Principal
Components, Randomized PCA

SVMs (see support vector machines)

SVR class, SVM Regression

Swish activation function, GELU, Swish, and Mish

Swiss roll dataset, Manifold Learning-Manifold Learning

symbolic differentiation, Forward-Mode Autodiff

symbolic tensors, AutoGraph and Tracing, TF Functions and Concrete
Functions

synchronous updates, with centralized parameters, Synchronous updates

synthetic minority oversampling technique (SMOTE), AlexNet

T

t-distributed stochastic neighbor embedding (t-SNE), Other Dimensionality
Reduction Techniques, Visualizing the Fashion MNIST Dataset

target attributes, Take a Quick Look at the Data Structure

target distribution, transforming, Feature Scaling and Transformation

target model, DQN, Fixed Q-value Targets

TD error, Temporal Difference Learning

TD target, Temporal Difference Learning

TD-Gammon, Reinforcement Learning

teacher forcing, An Encoder–Decoder Network for Neural Machine
Translation

temperature, Char-RNN model, Generating Fake Shakespearean Text

temporal difference (TD) learning, Temporal Difference Learning, Prioritized
Experience Replay

tensor arrays, Tensor Arrays

tensor processing units (TPUs), A Quick Tour of TensorFlow, Deploying a
new model version, Deploying a Model to a Mobile or Embedded Device,
Training a Model on a TensorFlow Cluster

TensorBoard, Using TensorBoard for Visualization-Using TensorBoard for
Visualization, A Quick Tour of TensorFlow, Masking, Running Large
Training Jobs on Vertex AI

TensorFlow, Objective and Approach, Objective and Approach, Custom
Models and Training with TensorFlow-The TensorFlow Datasets Project,
Training and Deploying TensorFlow Models at Scale-Hyperparameter
Tuning on Vertex AI

(see also Keras API)

architecture, A Quick Tour of TensorFlow

creating training function, Using the Dataset with Keras

custom models (see custom models and training algorithms)

deploying model to a mobile device, Deploying a Model to a Mobile or
Embedded Device-Deploying a Model to a Mobile or Embedded Device

functions and graphs, TensorFlow Graphs-Using TF Functions with
Keras (or Not)

GPU management with, Managing the GPU RAM-Managing the GPU
RAM, Parallel Execution Across Multiple Devices-Parallel Execution
Across Multiple Devices

graphs and functions, A Quick Tour of TensorFlow, TensorFlow
Functions and Graphs-TF Function Rules, TensorFlow Graphs-Using
TF Functions with Keras (or Not)

hub.KerasLayer, Using Pretrained Language Model Components

math operations, Tensors and Operations

with NumPy, Using TensorFlow like NumPy-Other Data Structures

operations (ops) and tensors, A Quick Tour of TensorFlow, Tensors and
Operations-Tensors and NumPy

parallelism to train models (see parallelism)

platforms and APIs available, A Quick Tour of TensorFlow

serving a model (see TensorFlow Serving)

special data structures, Special Data Structures-Queues

tf.add(), Tensors and Operations

tf.autograph.to_code(), AutoGraph and Tracing

tf.cast(), Type Conversions

tf.config.set_soft_device_placement, Placing Operations and Variables
on Devices

tf.config.threading.set_inter_op_parallelism_threads(), Parallel
Execution Across Multiple Devices

tf.config.threading.set_intra_op_parallelism_threads(), Parallel
Execution Across Multiple Devices

tf.constant(), Tensors and Operations

tf.data API (see tf.data API)

tf.device(), Placing Operations and Variables on Devices

tf.distribute.experimental.CentralStorageStrategy, Training at Scale
Using the Distribution Strategies API

tf.distribute.experimental.TPUStrategy, Training a Model on a
TensorFlow Cluster

tf.distribute.MirroredStrategy, Training at Scale Using the Distribution
Strategies API, Hyperparameter Tuning on Vertex AI

tf.distribute.MultiWorkerMirroredStrategy, Training a Model on a
TensorFlow Cluster

tf.float32, Tensors and NumPy

tf.float32 data type, Custom Metrics, Preprocessing the Data

tf.function(), TensorFlow Functions and Graphs, TF Function Rules

tf.int32 data type, Other Data Structures

tf.io.decode_base64(), Running Batch Prediction Jobs on Vertex AI

tf.io.decode_csv(), Preprocessing the Data

tf.io.decode_image(), Running Batch Prediction Jobs on Vertex AI

tf.io.decode_png(), Running Batch Prediction Jobs on Vertex AI

tf.io.decode_proto(), A Brief Introduction to Protocol Buffers

tf.io.FixedLenFeature, Loading and Parsing Examples

tf.io.parse_example(), Loading and Parsing Examples

tf.io.parse_sequence_example(), Handling Lists of Lists Using the
SequenceExample Protobuf

tf.io.parse_single_example(), Loading and Parsing Examples

tf.io.parse_single_sequence_example(), Handling Lists of Lists Using
the SequenceExample Protobuf

tf.io.parse_tensor(), Loading and Parsing Examples

tf.io.serialize_tensor(), Loading and Parsing Examples

tf.io.TFRecordOptions, Compressed TFRecord Files

tf.io.TFRecordWriter, The TFRecord Format

tf.io.VarLenFeature, Loading and Parsing Examples

tf.linalg.band_part(), Multi-head attention

tf.lite.TFLiteConverter.from_keras_model(), Deploying a Model to a
Mobile or Embedded Device

tf.make_tensor_proto(), Querying TF Serving through the gRPC API

tf.matmul(), Tensors and Operations, Multi-head attention

tf.nn.conv2d(), Implementing Convolutional Layers with Keras

tf.nn.embedding_lookup(), Image Preprocessing Layers

tf.nn.local_response_normalization(), AlexNet

tf.nn.moments(), Image Preprocessing Layers

tf.nn.sampled_softmax_loss(), An Encoder–Decoder Network for
Neural Machine Translation

tf.py_function(), TF Function Rules, Exporting SavedModels

tf.queue module, Other Data Structures

tf.queue.FIFOQueue, Queues

tf.RaggedTensor, Other Data Structures

tf.random.categorical(), Generating Fake Shakespearean Text

tf.reduce_max(), Implementing Pooling Layers with Keras

tf.reduce_mean(), Custom Training Loops

tf.reduce_sum(), TensorFlow Functions and Graphs

tf.saved_model_cli command, Exporting SavedModels

tf.sets module, Other Data Structures

tf.sort(), TF Function Rules

tf.SparseTensor, Other Data Structures

tf.stack(), Preprocessing the Data, Stateful RNN

tf.string data type, Other Data Structures

tf.strings module, Other Data Structures

tf.Tensor, Tensors and Operations, Variables

tf.TensorArray, Other Data Structures

tf.transpose(), Tensors and Operations

tf.Variable, Variables

tf.Variable.assign(), Variables

type conversions, Type Conversions

variables, Variables

web page, running a model in, Running a Model in a Web Page

TensorFlow cluster, Training a Model on a TensorFlow Cluster-Training a
Model on a TensorFlow Cluster

TensorFlow Datasets (TFDS) project, The TensorFlow Datasets Project-The
TensorFlow Datasets Project

TensorFlow Extended (TFX), A Quick Tour of TensorFlow

TensorFlow Hub, A Quick Tour of TensorFlow, Using Pretrained Language
Model Components, Reusing Pretrained Embeddings and Language Models

TensorFlow Lite, A Quick Tour of TensorFlow

TensorFlow playground, Classification MLPs

TensorFlow Serving (TF Serving), Serving a TensorFlow Model-Running
Batch Prediction Jobs on Vertex AI

batch prediction jobs on Vertex AI, Running Batch Prediction Jobs on
Vertex AI

creating prediction service, Creating a Prediction Service on Vertex AI-
Creating a Prediction Service on Vertex AI

deploying new model version, Deploying a new model version-
Deploying a new model version

Docker container, Installing and starting TensorFlow Serving

exporting SavedModels, Exporting SavedModels-Exporting
SavedModels

gRPC API, querying through, Querying TF Serving through the gRPC
API

installing and starting up, Installing and starting TensorFlow Serving-
Installing and starting TensorFlow Serving

REST API, querying through, Querying TF Serving through the REST
API

TensorFlow Text, Text Preprocessing, Sentiment Analysis

TensorFlow.js (TFJS) JavaScript library, Running a Model in a Web Page

tensors, Tensors and Operations-Tensors and NumPy

term-frequency x inverse-document-frequency (TF-IDF), Text Preprocessing

terminal state, Markov chain, Markov Decision Processes

test set, Testing and Validating, Create a Test Set-Create a Test Set

text attributes, Handling Text and Categorical Attributes

text processing (see natural language processing)

TF Serving (see TensorFlow Serving)

tf.data API, The tf.data API-Using the Dataset with Keras

chaining transformations, Chaining Transformations-Chaining
Transformations

interleaving lines from multiple files, Interleaving Lines from Multiple
Files-Interleaving Lines from Multiple Files

and Keras preprocessing layers, The Normalization Layer

prefetching, Prefetching-Prefetching

preprocessing the data, Preprocessing the Data-Preprocessing the Data

shuffling data, Shuffling the Data-Shuffling the Data

tf.data.AUTOTUNE, Chaining Transformations

tf.data.Dataset.from_tensor_slices(), The tf.data API-Chaining
Transformations

tf.data.TFRecordDataset, The TFRecord Format, The TFRecord Format,
Loading and Parsing Examples

using dataset with Keras, Using the Dataset with Keras-Using the
Dataset with Keras

TFDS (TensorFlow Datasets) project, The TensorFlow Datasets Project-The
TensorFlow Datasets Project

TFJS (TensorFlow.js) JavaScript library, Running a Model in a Web Page

TFLite, Deploying a Model to a Mobile or Embedded Device-Deploying a
Model to a Mobile or Embedded Device

TFRecord format, Loading and Preprocessing Data with TensorFlow, The
TFRecord Format-Handling Lists of Lists Using the SequenceExample
Protobuf

TFX (TensorFlow Extended), A Quick Tour of TensorFlow

theoretical information criterion, Selecting the Number of Clusters

3D convolutional layers, Semantic Segmentation

threshold logic units (TLUs), The Perceptron, The Multilayer Perceptron and
Backpropagation

Tikhonov regularization, Ridge Regression-Ridge Regression, Elastic Net
Regression

time series data, forecasting, Processing Sequences Using RNNs and CNNs,
Forecasting a Time Series-Forecasting Using a Sequence-to-Sequence Model

ARMA model family, The ARMA Model Family-The ARMA Model
Family

data preparation for ML models, Preparing the Data for Machine
Learning Models-Preparing the Data for Machine Learning Models

with deep RNN, Forecasting Using a Deep RNN

with linear model, Forecasting Using a Linear Model

multivariate time series, Forecasting a Time Series, Forecasting
Multivariate Time Series-Forecasting Multivariate Time Series

with sequence-to-sequence model, Input and Output Sequences,
Forecasting Using a Sequence-to-Sequence Model-Forecasting Using a
Sequence-to-Sequence Model

several time steps ahead, Forecasting Several Time Steps Ahead-
Forecasting Several Time Steps Ahead

with simple RNN, Forecasting Using a Simple RNN-Forecasting Using
a Simple RNN

TLUs (threshold logic units), The Perceptron, The Multilayer Perceptron and
Backpropagation

TNR (true negative rate), The ROC Curve

tokenizers library, Sentiment Analysis

tolerance (ε), Batch Gradient Descent, SVM Classes and Computational
Complexity

TPR (true positive rate), Confusion Matrices, The ROC Curve

TPUs (tensor processing units), A Quick Tour of TensorFlow, Deploying a
new model version, Deploying a Model to a Mobile or Embedded Device,
Training a Model on a TensorFlow Cluster

train-dev set, Data Mismatch

training, Model-based learning and a typical machine learning workflow

training instance, What Is Machine Learning?

training loops, Custom Training Loops-Custom Training Loops, Using the
Dataset with Keras

training models, Training Models-Softmax Regression

learning curves in, Learning Curves-Learning Curves

linear regression, Training Models, Linear Regression-Mini-Batch
Gradient Descent

logistic regression, Logistic Regression-Softmax Regression

perceptrons, The Perceptron-The Perceptron

polynomial regression, Training Models, Polynomial Regression-
Polynomial Regression

training set, What Is Machine Learning?, Testing and Validating

cost function of, Training and Cost Function-Training and Cost Function

insufficient quantities, Insufficient Quantity of Training Data

irrelevant features, Irrelevant Features

min-max scaling, Feature Scaling and Transformation

nonrepresentative, Nonrepresentative Training Data

overfitting, Overfitting the Training Data-Overfitting the Training Data

preparing for ML algorithms, Prepare the Data for Machine Learning
Algorithms

training and evaluating on, Train and Evaluate on the Training Set-Train
and Evaluate on the Training Set

transforming data, Feature Scaling and Transformation

underfitting, Underfitting the Training Data

visualizing data, Explore and Visualize the Data to Gain Insights

training set expansion, Exercises, AlexNet, Pretrained Models for Transfer
Learning

training/serving skew, Loading and Preprocessing Data with TensorFlow

train_test_split(), Create a Test Set, Better Evaluation Using Cross-Validation

transfer learning, Self-supervised learning, Reusing Pretrained Layers,
Transfer Learning with Keras-Transfer Learning with Keras, Pretrained
Models for Transfer Learning-Pretrained Models for Transfer Learning

transform(), Clean the Data, Handling Text and Categorical Attributes,
Feature Scaling and Transformation, Custom Transformers

transformation of data

custom transformers, Custom Transformers-Custom Transformers

estimator transformers, Clean the Data

and feature scaling, Feature Scaling and Transformation-Feature Scaling
and Transformation

transformer models (see transformer models)

transformation pipelines, Transformation Pipelines-Transformation Pipelines

TransformedTargetRegressor, Feature Scaling and Transformation

transformer, Attention Is All You Need: The Original Transformer
Architecture

transformer models

attention mechanisms, Attention Is All You Need: The Original
Transformer Architecture-Multi-head attention, Vision Transformers

BERT, An Avalanche of Transformer Models

DistilBERT, An Avalanche of Transformer Models, Hugging Face’s
Transformers Library-Hugging Face’s Transformers Library

Hugging Face library, Hugging Face’s Transformers Library-Hugging
Face’s Transformers Library

Pathways language model, An Avalanche of Transformer Models

vision transformers, Vision Transformers-Vision Transformers

TransformerMixin, Custom Transformers

transformers library, Hugging Face’s Transformers Library-Hugging Face’s
Transformers Library

translation, with RNNs, Natural Language Processing with RNNs and
Attention, An Encoder–Decoder Network for Neural Machine Translation-
Beam Search

(see also transformer models)

transpose operator, Select a Performance Measure

transposed convolutional layer, Semantic Segmentation-Semantic
Segmentation

true negative rate (TNR), The ROC Curve

true negatives, confusion matrix, Confusion Matrices

true positive rate (TPR), Confusion Matrices, The ROC Curve

true positives, confusion matrix, Confusion Matrices

trust region policy optimization (TRPO), Overview of Some Popular RL
Algorithms

2D convolutional layers, Implementing Convolutional Layers with Keras

tying weights, Tying Weights

type I errors, confusion matrix, Confusion Matrices

type II errors, confusion matrix, Confusion Matrices

U

uncertainty sampling, Using Clustering for Semi-Supervised Learning

undercomplete, autoencoder as, Efficient Data Representations-Performing
PCA with an Undercomplete Linear Autoencoder

underfitting of data, Underfitting the Training Data, Train and Evaluate on
the Training Set, Learning Curves-Learning Curves, Gaussian RBF Kernel

univariate regression, Frame the Problem

univariate time series, Forecasting a Time Series

Universal Sentence Encoder, Reusing Pretrained Embeddings and Language
Models-Reusing Pretrained Embeddings and Language Models

unreasonable effectiveness of data, Insufficient Quantity of Training Data

unrolling the network through time, Recurrent Neurons and Layers

unstable gradients problem, The Vanishing/Exploding Gradients Problems,
Fighting the Unstable Gradients Problem

(see also vanishing and exploding gradients)

unsupervised learning, Unsupervised learning-Unsupervised learning,
Unsupervised Learning Techniques-Other Algorithms for Anomaly and
Novelty Detection

anomaly detection, Unsupervised learning

association rule learning, Unsupervised learning

autoencoders (see autoencoders)

clustering (see clustering algorithms)

density estimation, Unsupervised Learning Techniques

diffusion models, Diffusion Models-Diffusion Models

dimensionality reduction (see dimensionality reduction)

GANs (see generative adversarial networks)

GMM, Gaussian Mixtures-Other Algorithms for Anomaly and Novelty
Detection

k-means (see k-means algorithm)

novelty detection, Unsupervised learning

pretraining, Unsupervised Pretraining, Reusing Pretrained Embeddings
and Language Models, An Avalanche of Transformer Models,
Unsupervised Pretraining Using Stacked Autoencoders

stacked autoencoders, Unsupervised Pretraining Using Stacked
Autoencoders

transformer models, An Avalanche of Transformer Models

visualization algorithms, Unsupervised learning-Unsupervised learning

upsampling layer, Semantic Segmentation

utility function, Model-based learning and a typical machine learning
workflow

V

VAEs (variational autoencoders), Variational Autoencoders-Variational
Autoencoders

“valid” padding, computer vision, Implementing Convolutional Layers with
Keras

validation set, Hyperparameter Tuning and Model Selection, Training and
evaluating the model-Training and evaluating the model

value_counts(), Take a Quick Look at the Data Structure

vanishing and exploding gradients, The Vanishing/Exploding Gradients
Problems-Gradient Clipping

activation function improvements, Better Activation Functions-GELU,
Swish, and Mish

batch normalization, Batch Normalization-Implementing batch
normalization with Keras

Glorot and He initialization, Glorot and He Initialization-Glorot and He
Initialization

gradient clipping, Gradient Clipping

unstable gradients problem, Fighting the Unstable Gradients Problem-
Fighting the Unstable Gradients Problem

variables

handling in TF functions, Handling Variables and Other Resources in
TF Functions-Handling Variables and Other Resources in TF Functions

persistence of, Custom Metrics

placing on GPUs, Placing Operations and Variables on Devices

in TensorFlow, Variables

variance

bias/variance trade-off, Learning Curves

explained, Explained Variance Ratio-Choosing the Right Number of
Dimensions

high variance with decision trees, Decision Trees Have a High Variance

preserving, Preserving the Variance

variational autoencoders (VAEs), Variational Autoencoders-Variational
Autoencoders

vector-to-sequence network, Input and Output Sequences

vectors, norms for measuring distance, Select a Performance Measure

Vertex AI, Launch, Monitor, and Maintain Your System, Creating a
Prediction Service on Vertex AI-Creating a Prediction Service on Vertex AI,
Running Large Training Jobs on Vertex AI-Running Large Training Jobs on
Vertex AI

VGGNet, VGGNet

virtual GPU device, Managing the GPU RAM

vision transformers (ViTs), Vision Transformers-Vision Transformers

visual cortex architecture, The Architecture of the Visual Cortex

visualization of data, Examples of Applications, Unsupervised learning-
Unsupervised learning, Explore and Visualize the Data to Gain Insights-
Experiment with Attribute Combinations

decision trees, Training and Visualizing a Decision Tree-Training and
Visualizing a Decision Tree

dimensionality reduction, Dimensionality Reduction, Choosing the
Right Number of Dimensions

end-to-end exercise, Explore and Visualize the Data to Gain Insights-
Experiment with Attribute Combinations

MLPs with TensorBoard, Using TensorBoard for Visualization-Using
TensorBoard for Visualization

stacked autoencoders, Visualizing the Reconstructions-Visualizing the
Reconstructions

t-SNE, Other Dimensionality Reduction Techniques

ViTs (vision transformers), Vision Transformers-Vision Transformers

voting classifiers, Voting Classifiers-Voting Classifiers

W

wall time, Batch Normalization

warmup phase, asynchronous model updates, Asynchronous updates

WaveNet, Processing Sequences Using RNNs and CNNs, WaveNet-
WaveNet

weak learners, Voting Classifiers

web page, running a model in, Running a Model in a Web Page

weight decay, AdamW

weight stashing, Bandwidth saturation

weight-tying, Tying Weights

weights

boosting, AdaBoost-AdaBoost

convolutional layers, Implementing Convolutional Layers with Keras

freezing reused layers, Reusing Pretrained Layers

of hidden layers, Creating the model using the sequential API

in prioritized experience replay, Prioritized Experience Replay

saving instead of whole model, Saving and Restoring a Model

white box models, Making Predictions

Wide & Deep neural network, Building Complex Models Using the
Functional API-Building Complex Models Using the Functional API

window length, Creating the Training Dataset

wisdom of the crowd, Ensemble Learning and Random Forests

word embeddings, Encoding Categorical Features Using Embeddings

neural machine translation, An Encoder–Decoder Network for Neural
Machine Translation-Beam Search

sentiment analysis, Sentiment Analysis-Reusing Pretrained Embeddings
and Language Models

worker task type, Training a Model on a TensorFlow Cluster

workers, Data parallelism with centralized parameters

X

Xavier initialization, Glorot and He Initialization

Xception (Extreme Inception), Xception-Xception, Pretrained Models for
Transfer Learning-Pretrained Models for Transfer Learning

XLA (accelerated linear algebra), TensorFlow Functions and Graphs

XOR (exclusive or) problem, The Perceptron

Y

You Only Look Once (YOLO), You Only Look Once-You Only Look Once

Z

zero padding, Convolutional Layers, Implementing Convolutional Layers
with Keras

zero-shot learning (ZSL), An Avalanche of Transformer Models, Vision
Transformers

ZFNet, AlexNet

About the Author

Aurélien Géron is a machine learning consultant and lecturer. A former
Googler, he led YouTube’s video classification team from 2013 to 2016.
He’s been a founder of and CTO at a few different companies: Wifirst, a
leading wireless ISP in France; Polyconseil, a consulting firm focused on
telecoms, media, and strategy; and Kiwisoft, a consulting firm focused on
machine learning and data privacy.

Before all that Aurélien worked as an engineer in a variety of domains:
finance (JP Morgan and Société Générale), defense (Canada’s DOD), and
healthcare (blood transfusion). He also published a few technical books (on
C++, WiFi, and internet architectures) and lectured about computer science at
a French engineering school.

A few fun facts: he taught his three children to count in binary with their
fingers (up to 1,023), he studied microbiology and evolutionary genetics
before going into software engineering, and his parachute didn’t open on the
second jump.

Colophon

The animal on the cover of Hands-On Machine Learning with Scikit-Learn,
Keras, and TensorFlow is the fire salamander (Salamandra salamandra), an
amphibian found across most of Europe. Its black, glossy skin features large
yellow spots on the head and back, signaling the presence of alkaloid toxins.
This is a possible source of this amphibian’s common name: contact with
these toxins (which they can also spray short distances) causes convulsions
and hyperventilation. Either the painful poisons or the moistness of the
salamander’s skin (or both) led to a misguided belief that these creatures not
only could survive being placed in fire but could extinguish it as well.

Fire salamanders live in shaded forests, hiding in moist crevices and under
logs near the pools or other freshwater bodies that facilitate their breeding.
Though they spend most of their lives on land, they give birth to their young
in water. They subsist mostly on a diet of insects, spiders, slugs, and worms.
Fire salamanders can grow up to a foot in length, and in captivity may live as
long as 50 years.

The fire salamander’s numbers have been reduced by destruction of their
forest habitat and capture for the pet trade, but the greatest threat they face is
the susceptibility of their moisture-permeable skin to pollutants and
microbes. Since 2014, they have become extinct in parts of the Netherlands
and Belgium due to an introduced fungus.

Many of the animals on O’Reilly covers are endangered; all of them are
important to the world. The cover illustration is by Karen Montgomery, based
on an engraving from Wood’s Illustrated Natural History. The cover fonts
are URW Typewriter and Guardian Sans. The text font is Adobe Minion Pro;
the heading font is Adobe Myriad Condensed; and the code font is Dalton
Maag’s Ubuntu Mono.